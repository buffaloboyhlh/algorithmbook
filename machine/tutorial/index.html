
<!doctype html>
<html lang="zh" class="no-js">
  <head>
    
      <meta charset="utf-8">
      <meta name="viewport" content="width=device-width,initial-scale=1">
      
      
        <meta name="author" content="Buffalo">
      
      
        <link rel="canonical" href="https://github.com/buffaloboyhlh/algorithmbook/machine/tutorial/">
      
      
        <link rel="prev" href="../math/">
      
      
        <link rel="next" href="../machinelearning/">
      
      
      <link rel="icon" href="../../assets/images/favicon.png">
      <meta name="generator" content="mkdocs-1.6.1, mkdocs-material-9.6.16">
    
    
      
        <title>机器学习教程 - 算法面试大集</title>
      
    
    
      <link rel="stylesheet" href="../../assets/stylesheets/main.7e37652d.min.css">
      
        
        <link rel="stylesheet" href="../../assets/stylesheets/palette.06af60db.min.css">
      
      


    
    
      
    
    
      
        
        
        <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
        <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Roboto:300,300i,400,400i,700,700i%7CRoboto+Mono:400,400i,700,700i&display=fallback">
        <style>:root{--md-text-font:"Roboto";--md-code-font:"Roboto Mono"}</style>
      
    
    
      <link rel="stylesheet" href="../../styles/extra.css">
    
      <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.4/dist/katex.min.css">
    
    <script>__md_scope=new URL("../..",location),__md_hash=e=>[...e].reduce(((e,_)=>(e<<5)-e+_.charCodeAt(0)),0),__md_get=(e,_=localStorage,t=__md_scope)=>JSON.parse(_.getItem(t.pathname+"."+e)),__md_set=(e,_,t=localStorage,a=__md_scope)=>{try{t.setItem(a.pathname+"."+e,JSON.stringify(_))}catch(e){}}</script>
    
      

    
    
    
  </head>
  
  
    
    
      
    
    
    
    
    <body dir="ltr" data-md-color-scheme="default" data-md-color-primary="teal" data-md-color-accent="amber">
  
    
    <input class="md-toggle" data-md-toggle="drawer" type="checkbox" id="__drawer" autocomplete="off">
    <input class="md-toggle" data-md-toggle="search" type="checkbox" id="__search" autocomplete="off">
    <label class="md-overlay" for="__drawer"></label>
    <div data-md-component="skip">
      
        
        <a href="#_2" class="md-skip">
          跳转至
        </a>
      
    </div>
    <div data-md-component="announce">
      
    </div>
    
    
      

<header class="md-header" data-md-component="header">
  <nav class="md-header__inner md-grid" aria-label="页眉">
    <a href="../.." title="算法面试大集" class="md-header__button md-logo" aria-label="算法面试大集" data-md-component="logo">
      
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 8a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3 3 3 0 0 0 3 3m0 3.54C9.64 9.35 6.5 8 3 8v11c3.5 0 6.64 1.35 9 3.54 2.36-2.19 5.5-3.54 9-3.54V8c-3.5 0-6.64 1.35-9 3.54"/></svg>

    </a>
    <label class="md-header__button md-icon" for="__drawer">
      
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M3 6h18v2H3zm0 5h18v2H3zm0 5h18v2H3z"/></svg>
    </label>
    <div class="md-header__title" data-md-component="header-title">
      <div class="md-header__ellipsis">
        <div class="md-header__topic">
          <span class="md-ellipsis">
            算法面试大集
          </span>
        </div>
        <div class="md-header__topic" data-md-component="header-topic">
          <span class="md-ellipsis">
            
              机器学习教程
            
          </span>
        </div>
      </div>
    </div>
    
      
        <form class="md-header__option" data-md-component="palette">
  
    
    
    
    <input class="md-option" data-md-color-media="(prefers-color-scheme: light)" data-md-color-scheme="default" data-md-color-primary="teal" data-md-color-accent="amber"  aria-label="切换至夜间模式"  type="radio" name="__palette" id="__palette_0">
    
      <label class="md-header__button md-icon" title="切换至夜间模式" for="__palette_1" hidden>
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 8a4 4 0 0 0-4 4 4 4 0 0 0 4 4 4 4 0 0 0 4-4 4 4 0 0 0-4-4m0 10a6 6 0 0 1-6-6 6 6 0 0 1 6-6 6 6 0 0 1 6 6 6 6 0 0 1-6 6m8-9.31V4h-4.69L12 .69 8.69 4H4v4.69L.69 12 4 15.31V20h4.69L12 23.31 15.31 20H20v-4.69L23.31 12z"/></svg>
      </label>
    
  
    
    
    
    <input class="md-option" data-md-color-media="(prefers-color-scheme: dark)" data-md-color-scheme="slate" data-md-color-primary="black" data-md-color-accent="indigo"  aria-label="切换至日间模式"  type="radio" name="__palette" id="__palette_1">
    
      <label class="md-header__button md-icon" title="切换至日间模式" for="__palette_0" hidden>
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 18c-.89 0-1.74-.2-2.5-.55C11.56 16.5 13 14.42 13 12s-1.44-4.5-3.5-5.45C10.26 6.2 11.11 6 12 6a6 6 0 0 1 6 6 6 6 0 0 1-6 6m8-9.31V4h-4.69L12 .69 8.69 4H4v4.69L.69 12 4 15.31V20h4.69L12 23.31 15.31 20H20v-4.69L23.31 12z"/></svg>
      </label>
    
  
</form>
      
    
    
      <script>var palette=__md_get("__palette");if(palette&&palette.color){if("(prefers-color-scheme)"===palette.color.media){var media=matchMedia("(prefers-color-scheme: light)"),input=document.querySelector(media.matches?"[data-md-color-media='(prefers-color-scheme: light)']":"[data-md-color-media='(prefers-color-scheme: dark)']");palette.color.media=input.getAttribute("data-md-color-media"),palette.color.scheme=input.getAttribute("data-md-color-scheme"),palette.color.primary=input.getAttribute("data-md-color-primary"),palette.color.accent=input.getAttribute("data-md-color-accent")}for(var[key,value]of Object.entries(palette.color))document.body.setAttribute("data-md-color-"+key,value)}</script>
    
    
    
      
      
        <label class="md-header__button md-icon" for="__search">
          
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"/></svg>
        </label>
        <div class="md-search" data-md-component="search" role="dialog">
  <label class="md-search__overlay" for="__search"></label>
  <div class="md-search__inner" role="search">
    <form class="md-search__form" name="search">
      <input type="text" class="md-search__input" name="query" aria-label="搜索" placeholder="搜索" autocapitalize="off" autocorrect="off" autocomplete="off" spellcheck="false" data-md-component="search-query" required>
      <label class="md-search__icon md-icon" for="__search">
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"/></svg>
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11z"/></svg>
      </label>
      <nav class="md-search__options" aria-label="查找">
        
        <button type="reset" class="md-search__icon md-icon" title="清空当前内容" aria-label="清空当前内容" tabindex="-1">
          
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M19 6.41 17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12z"/></svg>
        </button>
      </nav>
      
    </form>
    <div class="md-search__output">
      <div class="md-search__scrollwrap" tabindex="0" data-md-scrollfix>
        <div class="md-search-result" data-md-component="search-result">
          <div class="md-search-result__meta">
            正在初始化搜索引擎
          </div>
          <ol class="md-search-result__list" role="presentation"></ol>
        </div>
      </div>
    </div>
  </div>
</div>
      
    
    
  </nav>
  
</header>
    
    <div class="md-container" data-md-component="container">
      
      
        
          
            
<nav class="md-tabs" aria-label="标签" data-md-component="tabs">
  <div class="md-grid">
    <ul class="md-tabs__list">
      
        
  
  
  
  
    
    
      <li class="md-tabs__item">
        <a href="../../math/probability/" class="md-tabs__link">
          
  
  
    
  
  数学

        </a>
      </li>
    
  

      
        
  
  
  
    
  
  
    
    
      <li class="md-tabs__item md-tabs__item--active">
        <a href="../math/" class="md-tabs__link">
          
  
  
    
  
  机器学习

        </a>
      </li>
    
  

      
        
  
  
  
  
    
    
      <li class="md-tabs__item">
        <a href="../../deeplearning/math/" class="md-tabs__link">
          
  
  
    
  
  深度学习

        </a>
      </li>
    
  

      
        
  
  
  
  
    
    
      <li class="md-tabs__item">
        <a href="../../reinforcement/math/" class="md-tabs__link">
          
  
  
    
  
  强化学习

        </a>
      </li>
    
  

      
    </ul>
  </div>
</nav>
          
        
      
      <main class="md-main" data-md-component="main">
        <div class="md-main__inner md-grid">
          
            
              
              <div class="md-sidebar md-sidebar--primary" data-md-component="sidebar" data-md-type="navigation" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    


  


<nav class="md-nav md-nav--primary md-nav--lifted" aria-label="导航栏" data-md-level="0">
  <label class="md-nav__title" for="__drawer">
    <a href="../.." title="算法面试大集" class="md-nav__button md-logo" aria-label="算法面试大集" data-md-component="logo">
      
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 8a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3 3 3 0 0 0 3 3m0 3.54C9.64 9.35 6.5 8 3 8v11c3.5 0 6.64 1.35 9 3.54 2.36-2.19 5.5-3.54 9-3.54V8c-3.5 0-6.64 1.35-9 3.54"/></svg>

    </a>
    算法面试大集
  </label>
  
  <ul class="md-nav__list" data-md-scrollfix>
    
      
      
  
  
  
  
    
    
      
        
      
        
      
        
      
    
    
    
      
      
        
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
          
        
        <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type="checkbox" id="__nav_1" >
        
          
          <label class="md-nav__link" for="__nav_1" id="__nav_1_label" tabindex="0">
            
  
  
  <span class="md-ellipsis">
    数学
    
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_1_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_1">
            <span class="md-nav__icon md-icon"></span>
            数学
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../math/probability/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    概率统计
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../math/linear/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    线性代数
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../math/calculus/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    微积分与优化
    
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
    
  
  
  
    
    
      
        
      
        
      
        
      
    
    
    
      
        
        
      
      
        
      
    
    
    <li class="md-nav__item md-nav__item--active md-nav__item--section md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_2" checked>
        
          
          <label class="md-nav__link" for="__nav_2" id="__nav_2_label" tabindex="">
            
  
  
  <span class="md-ellipsis">
    机器学习
    
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_2_label" aria-expanded="true">
          <label class="md-nav__title" for="__nav_2">
            <span class="md-nav__icon md-icon"></span>
            机器学习
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../math/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    机器学习中的数学
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
    
  
  
  
    <li class="md-nav__item md-nav__item--active">
      
      <input class="md-nav__toggle md-toggle" type="checkbox" id="__toc">
      
      
      
        <label class="md-nav__link md-nav__link--active" for="__toc">
          
  
  
  <span class="md-ellipsis">
    机器学习教程
    
  </span>
  

          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <a href="./" class="md-nav__link md-nav__link--active">
        
  
  
  <span class="md-ellipsis">
    机器学习教程
    
  </span>
  

      </a>
      
        

<nav class="md-nav md-nav--secondary" aria-label="目录">
  
  
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      目录
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#_2" class="md-nav__link">
    <span class="md-ellipsis">
      一、机器学习基础知识
    </span>
  </a>
  
    <nav class="md-nav" aria-label="一、机器学习基础知识">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#11" class="md-nav__link">
    <span class="md-ellipsis">
      1.1 什么是机器学习
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#12" class="md-nav__link">
    <span class="md-ellipsis">
      1.2 机器学习的类型
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#13" class="md-nav__link">
    <span class="md-ellipsis">
      1.3 机器学习的基本流程
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#_3" class="md-nav__link">
    <span class="md-ellipsis">
      二、模型评估方法与准则
    </span>
  </a>
  
    <nav class="md-nav" aria-label="二、模型评估方法与准则">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#21" class="md-nav__link">
    <span class="md-ellipsis">
      2.1 评估指标
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#22" class="md-nav__link">
    <span class="md-ellipsis">
      2.2 交叉验证
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#23" class="md-nav__link">
    <span class="md-ellipsis">
      2.3 模型选择与调优
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#24" class="md-nav__link">
    <span class="md-ellipsis">
      2.4 模型解释性
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#25" class="md-nav__link">
    <span class="md-ellipsis">
      2.5 模型部署
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#knn" class="md-nav__link">
    <span class="md-ellipsis">
      三、KNN算法
    </span>
  </a>
  
    <nav class="md-nav" aria-label="三、KNN算法">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#31-knn" class="md-nav__link">
    <span class="md-ellipsis">
      3.1 KNN算法原理
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#32-knn" class="md-nav__link">
    <span class="md-ellipsis">
      3.2 KNN算法优缺点
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#33-knn" class="md-nav__link">
    <span class="md-ellipsis">
      3.3 KNN算法应用场景
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#34-knn" class="md-nav__link">
    <span class="md-ellipsis">
      3.4 KNN算法实现
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#35-knn" class="md-nav__link">
    <span class="md-ellipsis">
      3.5 KNN算法调优
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#36-knn" class="md-nav__link">
    <span class="md-ellipsis">
      3.6 KNN算法扩展
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#_14" class="md-nav__link">
    <span class="md-ellipsis">
      四、逻辑回归算法
    </span>
  </a>
  
    <nav class="md-nav" aria-label="四、逻辑回归算法">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#41" class="md-nav__link">
    <span class="md-ellipsis">
      4.1 逻辑回归算法原理
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#42" class="md-nav__link">
    <span class="md-ellipsis">
      4.2 逻辑回归算法优缺点
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#43" class="md-nav__link">
    <span class="md-ellipsis">
      4.3 逻辑回归算法应用场景
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#44" class="md-nav__link">
    <span class="md-ellipsis">
      4.4 逻辑回归算法实现
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#45" class="md-nav__link">
    <span class="md-ellipsis">
      4.5 逻辑回归算法调优
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#46" class="md-nav__link">
    <span class="md-ellipsis">
      4.6 逻辑回归算法扩展
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#_17" class="md-nav__link">
    <span class="md-ellipsis">
      五、朴素贝叶斯算法
    </span>
  </a>
  
    <nav class="md-nav" aria-label="五、朴素贝叶斯算法">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#51" class="md-nav__link">
    <span class="md-ellipsis">
      5.1 朴素贝叶斯算法原理
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#52" class="md-nav__link">
    <span class="md-ellipsis">
      5.2 朴素贝叶斯算法优缺点
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#53" class="md-nav__link">
    <span class="md-ellipsis">
      5.3 朴素贝叶斯算法应用场景
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#54" class="md-nav__link">
    <span class="md-ellipsis">
      5.4 朴素贝叶斯算法实现
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#55" class="md-nav__link">
    <span class="md-ellipsis">
      5.5 朴素贝叶斯算法调优
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#56" class="md-nav__link">
    <span class="md-ellipsis">
      5.6 朴素贝叶斯算法扩展
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#_23" class="md-nav__link">
    <span class="md-ellipsis">
      六、决策树模型
    </span>
  </a>
  
    <nav class="md-nav" aria-label="六、决策树模型">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#61" class="md-nav__link">
    <span class="md-ellipsis">
      6.1 决策树模型原理
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#62" class="md-nav__link">
    <span class="md-ellipsis">
      6.2 决策树模型优缺点
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#63" class="md-nav__link">
    <span class="md-ellipsis">
      6.3 决策树模型应用场景
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#64" class="md-nav__link">
    <span class="md-ellipsis">
      6.4 决策树模型实现
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#65" class="md-nav__link">
    <span class="md-ellipsis">
      6.5 决策树模型调优
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#66" class="md-nav__link">
    <span class="md-ellipsis">
      6.6 决策树模型扩展
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#_31" class="md-nav__link">
    <span class="md-ellipsis">
      七、随机森林分类模型
    </span>
  </a>
  
    <nav class="md-nav" aria-label="七、随机森林分类模型">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#71" class="md-nav__link">
    <span class="md-ellipsis">
      7.1 随机森林分类模型原理
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#72" class="md-nav__link">
    <span class="md-ellipsis">
      7.2 随机森林分类模型优缺点
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#73" class="md-nav__link">
    <span class="md-ellipsis">
      7.3 随机森林分类模型应用场景
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#74" class="md-nav__link">
    <span class="md-ellipsis">
      7.4 随机森林分类模型实现
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#75" class="md-nav__link">
    <span class="md-ellipsis">
      7.5 随机森林分类模型调优
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#76" class="md-nav__link">
    <span class="md-ellipsis">
      7.6 随机森林分类模型扩展
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#_34" class="md-nav__link">
    <span class="md-ellipsis">
      八、回归树模型
    </span>
  </a>
  
    <nav class="md-nav" aria-label="八、回归树模型">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#81" class="md-nav__link">
    <span class="md-ellipsis">
      8.1 回归树模型原理
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#82" class="md-nav__link">
    <span class="md-ellipsis">
      8.2 回归树模型优缺点
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#83" class="md-nav__link">
    <span class="md-ellipsis">
      8.3 回归树模型应用场景
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#84" class="md-nav__link">
    <span class="md-ellipsis">
      8.4 回归树模型实现
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#85" class="md-nav__link">
    <span class="md-ellipsis">
      8.5 回归树模型调优
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#86" class="md-nav__link">
    <span class="md-ellipsis">
      8.6 回归树模型扩展
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#gbdt" class="md-nav__link">
    <span class="md-ellipsis">
      九、GBDT模型
    </span>
  </a>
  
    <nav class="md-nav" aria-label="九、GBDT模型">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#91-gbdt" class="md-nav__link">
    <span class="md-ellipsis">
      9.1 GBDT模型原理
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#92-gbdt" class="md-nav__link">
    <span class="md-ellipsis">
      9.2 GBDT模型优缺点
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#93-gbdt" class="md-nav__link">
    <span class="md-ellipsis">
      9.3 GBDT模型应用场景
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#94-gbdt" class="md-nav__link">
    <span class="md-ellipsis">
      9.4 GBDT模型实现
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#95-gbdt" class="md-nav__link">
    <span class="md-ellipsis">
      9.5 GBDT模型调优
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#96-gbdt" class="md-nav__link">
    <span class="md-ellipsis">
      9.6 GBDT模型扩展
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#xgboost" class="md-nav__link">
    <span class="md-ellipsis">
      十、XGBoost模型
    </span>
  </a>
  
    <nav class="md-nav" aria-label="十、XGBoost模型">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#101-xgboost" class="md-nav__link">
    <span class="md-ellipsis">
      10.1 XGBoost模型原理
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#102-xgboost" class="md-nav__link">
    <span class="md-ellipsis">
      10.2 XGBoost模型优缺点
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#103-xgboost" class="md-nav__link">
    <span class="md-ellipsis">
      10.3 XGBoost模型应用场景
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#104-xgboost" class="md-nav__link">
    <span class="md-ellipsis">
      10.4 XGBoost模型实现
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#105-xgboost" class="md-nav__link">
    <span class="md-ellipsis">
      10.5 XGBoost模型调优
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#106-xgboost" class="md-nav__link">
    <span class="md-ellipsis">
      10.6 XGBoost模型扩展
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#lightgbm" class="md-nav__link">
    <span class="md-ellipsis">
      十一、LightGBM模型
    </span>
  </a>
  
    <nav class="md-nav" aria-label="十一、LightGBM模型">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#111-lightgbm" class="md-nav__link">
    <span class="md-ellipsis">
      11.1 LightGBM模型原理
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#112-lightgbm" class="md-nav__link">
    <span class="md-ellipsis">
      11.2 LightGBM模型优缺点
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#113-lightgbm" class="md-nav__link">
    <span class="md-ellipsis">
      11.3 LightGBM模型应用场景
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#114-lightgbm" class="md-nav__link">
    <span class="md-ellipsis">
      11.4 LightGBM模型实现
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#115-lightgbm" class="md-nav__link">
    <span class="md-ellipsis">
      11.5 LightGBM模型调优
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#116-lightgbm" class="md-nav__link">
    <span class="md-ellipsis">
      11.6 LightGBM模型扩展
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#_43" class="md-nav__link">
    <span class="md-ellipsis">
      十二、支持向量机模型
    </span>
  </a>
  
    <nav class="md-nav" aria-label="十二、支持向量机模型">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#121" class="md-nav__link">
    <span class="md-ellipsis">
      12.1 支持向量机模型原理
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#122" class="md-nav__link">
    <span class="md-ellipsis">
      12.2 支持向量机模型优缺点
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#123" class="md-nav__link">
    <span class="md-ellipsis">
      12.3 支持向量机模型应用场景
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#124" class="md-nav__link">
    <span class="md-ellipsis">
      12.4 支持向量机模型实现
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#125" class="md-nav__link">
    <span class="md-ellipsis">
      12.5 支持向量机模型调优
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#126" class="md-nav__link">
    <span class="md-ellipsis">
      12.6 支持向量机模型扩展
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#_46" class="md-nav__link">
    <span class="md-ellipsis">
      十三、聚类算法
    </span>
  </a>
  
    <nav class="md-nav" aria-label="十三、聚类算法">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#131" class="md-nav__link">
    <span class="md-ellipsis">
      13.1 聚类算法原理
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#132" class="md-nav__link">
    <span class="md-ellipsis">
      13.2 聚类算法优缺点
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#133" class="md-nav__link">
    <span class="md-ellipsis">
      13.3 聚类算法应用场景
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#134" class="md-nav__link">
    <span class="md-ellipsis">
      13.4 聚类算法实现
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#135" class="md-nav__link">
    <span class="md-ellipsis">
      13.5 聚类算法调优
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#136" class="md-nav__link">
    <span class="md-ellipsis">
      13.6 聚类算法扩展
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#_49" class="md-nav__link">
    <span class="md-ellipsis">
      十四、降维算法
    </span>
  </a>
  
    <nav class="md-nav" aria-label="十四、降维算法">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#141" class="md-nav__link">
    <span class="md-ellipsis">
      14.1 降维算法原理
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#142" class="md-nav__link">
    <span class="md-ellipsis">
      14.2 降维算法优缺点
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#143" class="md-nav__link">
    <span class="md-ellipsis">
      14.3 降维算法应用场景
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#144" class="md-nav__link">
    <span class="md-ellipsis">
      14.4 降维算法实现
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#145" class="md-nav__link">
    <span class="md-ellipsis">
      14.5 降维算法调优
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#146" class="md-nav__link">
    <span class="md-ellipsis">
      14.6 降维算法扩展
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
    </ul>
  
</nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../machinelearning/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    机器学习教程补充
    
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
  
  
    
    
      
        
      
        
      
    
    
    
      
      
        
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
          
        
        <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type="checkbox" id="__nav_3" >
        
          
          <label class="md-nav__link" for="__nav_3" id="__nav_3_label" tabindex="0">
            
  
  
  <span class="md-ellipsis">
    深度学习
    
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_3_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_3">
            <span class="md-nav__icon md-icon"></span>
            深度学习
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../deeplearning/math/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    深度学习中的数学
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../deeplearning/tutorial/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    深度学习教程
    
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
  
  
    
    
      
        
      
        
      
    
    
    
      
      
        
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
          
        
        <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type="checkbox" id="__nav_4" >
        
          
          <label class="md-nav__link" for="__nav_4" id="__nav_4_label" tabindex="0">
            
  
  
  <span class="md-ellipsis">
    强化学习
    
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_4_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_4">
            <span class="md-nav__icon md-icon"></span>
            强化学习
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../reinforcement/math/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    强化学习中的数学
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../reinforcement/tutorial/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    强化学习教程
    
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
  </ul>
</nav>
                  </div>
                </div>
              </div>
            
            
              
              <div class="md-sidebar md-sidebar--secondary" data-md-component="sidebar" data-md-type="toc" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    

<nav class="md-nav md-nav--secondary" aria-label="目录">
  
  
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      目录
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#_2" class="md-nav__link">
    <span class="md-ellipsis">
      一、机器学习基础知识
    </span>
  </a>
  
    <nav class="md-nav" aria-label="一、机器学习基础知识">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#11" class="md-nav__link">
    <span class="md-ellipsis">
      1.1 什么是机器学习
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#12" class="md-nav__link">
    <span class="md-ellipsis">
      1.2 机器学习的类型
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#13" class="md-nav__link">
    <span class="md-ellipsis">
      1.3 机器学习的基本流程
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#_3" class="md-nav__link">
    <span class="md-ellipsis">
      二、模型评估方法与准则
    </span>
  </a>
  
    <nav class="md-nav" aria-label="二、模型评估方法与准则">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#21" class="md-nav__link">
    <span class="md-ellipsis">
      2.1 评估指标
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#22" class="md-nav__link">
    <span class="md-ellipsis">
      2.2 交叉验证
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#23" class="md-nav__link">
    <span class="md-ellipsis">
      2.3 模型选择与调优
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#24" class="md-nav__link">
    <span class="md-ellipsis">
      2.4 模型解释性
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#25" class="md-nav__link">
    <span class="md-ellipsis">
      2.5 模型部署
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#knn" class="md-nav__link">
    <span class="md-ellipsis">
      三、KNN算法
    </span>
  </a>
  
    <nav class="md-nav" aria-label="三、KNN算法">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#31-knn" class="md-nav__link">
    <span class="md-ellipsis">
      3.1 KNN算法原理
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#32-knn" class="md-nav__link">
    <span class="md-ellipsis">
      3.2 KNN算法优缺点
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#33-knn" class="md-nav__link">
    <span class="md-ellipsis">
      3.3 KNN算法应用场景
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#34-knn" class="md-nav__link">
    <span class="md-ellipsis">
      3.4 KNN算法实现
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#35-knn" class="md-nav__link">
    <span class="md-ellipsis">
      3.5 KNN算法调优
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#36-knn" class="md-nav__link">
    <span class="md-ellipsis">
      3.6 KNN算法扩展
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#_14" class="md-nav__link">
    <span class="md-ellipsis">
      四、逻辑回归算法
    </span>
  </a>
  
    <nav class="md-nav" aria-label="四、逻辑回归算法">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#41" class="md-nav__link">
    <span class="md-ellipsis">
      4.1 逻辑回归算法原理
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#42" class="md-nav__link">
    <span class="md-ellipsis">
      4.2 逻辑回归算法优缺点
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#43" class="md-nav__link">
    <span class="md-ellipsis">
      4.3 逻辑回归算法应用场景
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#44" class="md-nav__link">
    <span class="md-ellipsis">
      4.4 逻辑回归算法实现
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#45" class="md-nav__link">
    <span class="md-ellipsis">
      4.5 逻辑回归算法调优
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#46" class="md-nav__link">
    <span class="md-ellipsis">
      4.6 逻辑回归算法扩展
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#_17" class="md-nav__link">
    <span class="md-ellipsis">
      五、朴素贝叶斯算法
    </span>
  </a>
  
    <nav class="md-nav" aria-label="五、朴素贝叶斯算法">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#51" class="md-nav__link">
    <span class="md-ellipsis">
      5.1 朴素贝叶斯算法原理
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#52" class="md-nav__link">
    <span class="md-ellipsis">
      5.2 朴素贝叶斯算法优缺点
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#53" class="md-nav__link">
    <span class="md-ellipsis">
      5.3 朴素贝叶斯算法应用场景
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#54" class="md-nav__link">
    <span class="md-ellipsis">
      5.4 朴素贝叶斯算法实现
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#55" class="md-nav__link">
    <span class="md-ellipsis">
      5.5 朴素贝叶斯算法调优
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#56" class="md-nav__link">
    <span class="md-ellipsis">
      5.6 朴素贝叶斯算法扩展
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#_23" class="md-nav__link">
    <span class="md-ellipsis">
      六、决策树模型
    </span>
  </a>
  
    <nav class="md-nav" aria-label="六、决策树模型">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#61" class="md-nav__link">
    <span class="md-ellipsis">
      6.1 决策树模型原理
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#62" class="md-nav__link">
    <span class="md-ellipsis">
      6.2 决策树模型优缺点
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#63" class="md-nav__link">
    <span class="md-ellipsis">
      6.3 决策树模型应用场景
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#64" class="md-nav__link">
    <span class="md-ellipsis">
      6.4 决策树模型实现
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#65" class="md-nav__link">
    <span class="md-ellipsis">
      6.5 决策树模型调优
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#66" class="md-nav__link">
    <span class="md-ellipsis">
      6.6 决策树模型扩展
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#_31" class="md-nav__link">
    <span class="md-ellipsis">
      七、随机森林分类模型
    </span>
  </a>
  
    <nav class="md-nav" aria-label="七、随机森林分类模型">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#71" class="md-nav__link">
    <span class="md-ellipsis">
      7.1 随机森林分类模型原理
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#72" class="md-nav__link">
    <span class="md-ellipsis">
      7.2 随机森林分类模型优缺点
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#73" class="md-nav__link">
    <span class="md-ellipsis">
      7.3 随机森林分类模型应用场景
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#74" class="md-nav__link">
    <span class="md-ellipsis">
      7.4 随机森林分类模型实现
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#75" class="md-nav__link">
    <span class="md-ellipsis">
      7.5 随机森林分类模型调优
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#76" class="md-nav__link">
    <span class="md-ellipsis">
      7.6 随机森林分类模型扩展
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#_34" class="md-nav__link">
    <span class="md-ellipsis">
      八、回归树模型
    </span>
  </a>
  
    <nav class="md-nav" aria-label="八、回归树模型">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#81" class="md-nav__link">
    <span class="md-ellipsis">
      8.1 回归树模型原理
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#82" class="md-nav__link">
    <span class="md-ellipsis">
      8.2 回归树模型优缺点
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#83" class="md-nav__link">
    <span class="md-ellipsis">
      8.3 回归树模型应用场景
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#84" class="md-nav__link">
    <span class="md-ellipsis">
      8.4 回归树模型实现
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#85" class="md-nav__link">
    <span class="md-ellipsis">
      8.5 回归树模型调优
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#86" class="md-nav__link">
    <span class="md-ellipsis">
      8.6 回归树模型扩展
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#gbdt" class="md-nav__link">
    <span class="md-ellipsis">
      九、GBDT模型
    </span>
  </a>
  
    <nav class="md-nav" aria-label="九、GBDT模型">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#91-gbdt" class="md-nav__link">
    <span class="md-ellipsis">
      9.1 GBDT模型原理
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#92-gbdt" class="md-nav__link">
    <span class="md-ellipsis">
      9.2 GBDT模型优缺点
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#93-gbdt" class="md-nav__link">
    <span class="md-ellipsis">
      9.3 GBDT模型应用场景
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#94-gbdt" class="md-nav__link">
    <span class="md-ellipsis">
      9.4 GBDT模型实现
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#95-gbdt" class="md-nav__link">
    <span class="md-ellipsis">
      9.5 GBDT模型调优
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#96-gbdt" class="md-nav__link">
    <span class="md-ellipsis">
      9.6 GBDT模型扩展
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#xgboost" class="md-nav__link">
    <span class="md-ellipsis">
      十、XGBoost模型
    </span>
  </a>
  
    <nav class="md-nav" aria-label="十、XGBoost模型">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#101-xgboost" class="md-nav__link">
    <span class="md-ellipsis">
      10.1 XGBoost模型原理
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#102-xgboost" class="md-nav__link">
    <span class="md-ellipsis">
      10.2 XGBoost模型优缺点
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#103-xgboost" class="md-nav__link">
    <span class="md-ellipsis">
      10.3 XGBoost模型应用场景
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#104-xgboost" class="md-nav__link">
    <span class="md-ellipsis">
      10.4 XGBoost模型实现
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#105-xgboost" class="md-nav__link">
    <span class="md-ellipsis">
      10.5 XGBoost模型调优
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#106-xgboost" class="md-nav__link">
    <span class="md-ellipsis">
      10.6 XGBoost模型扩展
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#lightgbm" class="md-nav__link">
    <span class="md-ellipsis">
      十一、LightGBM模型
    </span>
  </a>
  
    <nav class="md-nav" aria-label="十一、LightGBM模型">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#111-lightgbm" class="md-nav__link">
    <span class="md-ellipsis">
      11.1 LightGBM模型原理
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#112-lightgbm" class="md-nav__link">
    <span class="md-ellipsis">
      11.2 LightGBM模型优缺点
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#113-lightgbm" class="md-nav__link">
    <span class="md-ellipsis">
      11.3 LightGBM模型应用场景
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#114-lightgbm" class="md-nav__link">
    <span class="md-ellipsis">
      11.4 LightGBM模型实现
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#115-lightgbm" class="md-nav__link">
    <span class="md-ellipsis">
      11.5 LightGBM模型调优
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#116-lightgbm" class="md-nav__link">
    <span class="md-ellipsis">
      11.6 LightGBM模型扩展
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#_43" class="md-nav__link">
    <span class="md-ellipsis">
      十二、支持向量机模型
    </span>
  </a>
  
    <nav class="md-nav" aria-label="十二、支持向量机模型">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#121" class="md-nav__link">
    <span class="md-ellipsis">
      12.1 支持向量机模型原理
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#122" class="md-nav__link">
    <span class="md-ellipsis">
      12.2 支持向量机模型优缺点
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#123" class="md-nav__link">
    <span class="md-ellipsis">
      12.3 支持向量机模型应用场景
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#124" class="md-nav__link">
    <span class="md-ellipsis">
      12.4 支持向量机模型实现
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#125" class="md-nav__link">
    <span class="md-ellipsis">
      12.5 支持向量机模型调优
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#126" class="md-nav__link">
    <span class="md-ellipsis">
      12.6 支持向量机模型扩展
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#_46" class="md-nav__link">
    <span class="md-ellipsis">
      十三、聚类算法
    </span>
  </a>
  
    <nav class="md-nav" aria-label="十三、聚类算法">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#131" class="md-nav__link">
    <span class="md-ellipsis">
      13.1 聚类算法原理
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#132" class="md-nav__link">
    <span class="md-ellipsis">
      13.2 聚类算法优缺点
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#133" class="md-nav__link">
    <span class="md-ellipsis">
      13.3 聚类算法应用场景
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#134" class="md-nav__link">
    <span class="md-ellipsis">
      13.4 聚类算法实现
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#135" class="md-nav__link">
    <span class="md-ellipsis">
      13.5 聚类算法调优
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#136" class="md-nav__link">
    <span class="md-ellipsis">
      13.6 聚类算法扩展
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#_49" class="md-nav__link">
    <span class="md-ellipsis">
      十四、降维算法
    </span>
  </a>
  
    <nav class="md-nav" aria-label="十四、降维算法">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#141" class="md-nav__link">
    <span class="md-ellipsis">
      14.1 降维算法原理
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#142" class="md-nav__link">
    <span class="md-ellipsis">
      14.2 降维算法优缺点
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#143" class="md-nav__link">
    <span class="md-ellipsis">
      14.3 降维算法应用场景
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#144" class="md-nav__link">
    <span class="md-ellipsis">
      14.4 降维算法实现
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#145" class="md-nav__link">
    <span class="md-ellipsis">
      14.5 降维算法调优
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#146" class="md-nav__link">
    <span class="md-ellipsis">
      14.6 降维算法扩展
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
    </ul>
  
</nav>
                  </div>
                </div>
              </div>
            
          
          
            <div class="md-content" data-md-component="content">
              <article class="md-content__inner md-typeset">
                
                  



<h1 id="_1">机器学习教程<a class="headerlink" href="#_1" title="Permanent link">&para;</a></h1>
<h2 id="_2">一、机器学习基础知识<a class="headerlink" href="#_2" title="Permanent link">&para;</a></h2>
<h3 id="11">1.1 什么是机器学习<a class="headerlink" href="#11" title="Permanent link">&para;</a></h3>
<p>机器学习是一种让计算机通过数据学习并自动改进性能的技术。它通过算法从数据中提取模式和规律，从而进行预测或决策。</p>
<h3 id="12">1.2 机器学习的类型<a class="headerlink" href="#12" title="Permanent link">&para;</a></h3>
<p>机器学习主要分为三种类型：</p>
<ul>
<li>监督学习：通过标注数据进行训练，常用于分类和回归任务</li>
<li>无监督学习：通过未标注数据进行训练，常用于聚类和降维任务</li>
<li>强化学习：通过与环境交互进行学习，常用于游戏和机器人控制</li>
</ul>
<h3 id="13">1.3 机器学习的基本流程<a class="headerlink" href="#13" title="Permanent link">&para;</a></h3>
<ol>
<li>数据收集：获取相关数据</li>
<li>数据预处理：清洗和转换数据</li>
<li>特征工程：选择和提取有用特征</li>
<li>模型选择：选择合适的算法</li>
<li>模型训练：使用训练数据进行模型训练</li>
<li>模型评估：使用测试数据评估模型性能</li>
<li>模型优化：调整模型参数以提高性能</li>
<li>部署与监控：将模型应用于实际场景并持续监控</li>
</ol>
<h2 id="_3">二、模型评估方法与准则<a class="headerlink" href="#_3" title="Permanent link">&para;</a></h2>
<h3 id="21">2.1 评估指标<a class="headerlink" href="#21" title="Permanent link">&para;</a></h3>
<p>评估模型性能的指标有很多，选择合适的指标取决于具体的任务和数据集。</p>
<p>常用的评估指标包括：</p>
<ul>
<li>准确率（Accuracy）</li>
<li>精确率（Precision）</li>
<li>召回率（Recall）</li>
<li>F1分数（F1 Score）</li>
<li>ROC曲线和AUC值</li>
<li>均方误差（Mean Squared Error, MSE）</li>
<li>平均绝对误差（Mean Absolute Error, MAE）  </li>
<li>平均绝对百分误差 MAPE</li>
<li>R²（决定系数）</li>
</ul>
<h4 id="_4">分类任务指标<a class="headerlink" href="#_4" title="Permanent link">&para;</a></h4>
<ul>
<li>准确率（Accuracy）：正确预测的样本数占总样本数的比例。</li>
<li>精确率（Precision）：预测为正类的样本中实际为正类的比例。</li>
<li>召回率（Recall）：实际为正类的样本中被正确预测为正类的比例。</li>
<li>F1分数（F1 Score）：精确率和召回率的调和平均数。</li>
<li>ROC曲线和AUC值：评估分类模型在不同阈值下的性能。</li>
</ul>
<h5 id="confusion-matrix">混淆矩阵（Confusion Matrix）<a class="headerlink" href="#confusion-matrix" title="Permanent link">&para;</a></h5>
<p>混淆矩阵是用于评估分类模型性能的工具，显示了实际类别与预测类别的对比情况。对于二分类问题，混淆矩阵通常包含以下四个部分：</p>
<table>
<thead>
<tr>
<th></th>
<th>预测为正类 (Positive)</th>
<th>预测为负类 (Negative)</th>
</tr>
</thead>
<tbody>
<tr>
<td>实际为正类 (Positive)</td>
<td>True Positive (TP)</td>
<td>False Negative (FN)</td>
</tr>
<tr>
<td>实际为负类 (Negative)</td>
<td>False Positive (FP)</td>
<td>True Negative (TN)</td>
</tr>
</tbody>
</table>
<h5 id="accuracy">准确率（Accuracy）<a class="headerlink" href="#accuracy" title="Permanent link">&para;</a></h5>
<div class="arithmatex">\[
Accuracy = \frac{TP + TN}{TP + TN + FP + FN}
\]</div>
<p>其中，TP（True Positive）表示真正例，TN（True Negative）表示真反例，FP（False Positive）表示假正例，FN（False Negative）表示假反例。    </p>
<h5 id="precision">精确率（Precision）<a class="headerlink" href="#precision" title="Permanent link">&para;</a></h5>
<div class="arithmatex">\[
Precision = \frac{TP}{TP + FP}
\]</div>
<h5 id="recall">召回率（Recall）<a class="headerlink" href="#recall" title="Permanent link">&para;</a></h5>
<div class="arithmatex">\[
Recall = \frac{TP}{TP + FN}
\]</div>
<h5 id="f1f1-score">F1分数（F1 Score）<a class="headerlink" href="#f1f1-score" title="Permanent link">&para;</a></h5>
<div class="arithmatex">\[
F1 = 2 \times \frac{Precision \times Recall}{Precision + Recall}
\]</div>
<h5 id="rocauc">ROC曲线和AUC值<a class="headerlink" href="#rocauc" title="Permanent link">&para;</a></h5>
<p>ROC曲线（Receiver Operating Characteristic Curve）是通过改变分类阈值绘制的真阳性率（TPR）与假阳性率（FPR）之间的关系图。AUC（Area Under the Curve）值表示ROC曲线下的面积，范围在0到1之间，值越大表示模型性能越好。  </p>
<div class="arithmatex">\[
TPR = \frac{TP}{TP + FN}
\]</div>
<div class="arithmatex">\[
FPR = \frac{FP}{FP + TN}
\]</div>
<h4 id="_5">回归任务指标<a class="headerlink" href="#_5" title="Permanent link">&para;</a></h4>
<ul>
<li>均方误差（Mean Squared Error, MSE）：预测值与实际值之间差异的平方的平均值。</li>
<li>平均绝对误差（Mean Absolute Error, MAE）：预测值与实际值之间差异的绝对值的平均值。</li>
<li>平均绝对百分误差 MAPE：预测值与实际值之间差异的绝对值占实际值的百分比的平均值。</li>
<li>R²（决定系数）：衡量模型解释数据变异的能力。 </li>
</ul>
<h5 id="mean-squared-error-mse">均方误差（Mean Squared Error, MSE）<a class="headerlink" href="#mean-squared-error-mse" title="Permanent link">&para;</a></h5>
<div class="arithmatex">\[
MSE = \frac{1}{n} \sum_{i=1}^{n} (y_i - \hat{y}_i)^2
\]</div>
<p>其中，<span class="arithmatex">\(y_i\)</span> 是实际值，<span class="arithmatex">\(\hat{y}_i\)</span> 是预测值，<span class="arithmatex">\(n\)</span> 是样本数量。</p>
<h5 id="mean-absolute-error-mae">平均绝对误差（Mean Absolute Error, MAE）<a class="headerlink" href="#mean-absolute-error-mae" title="Permanent link">&para;</a></h5>
<div class="arithmatex">\[
MAE = \frac{1}{n} \sum_{i=1}^{n} |y_i - \hat{y}_i|
\]</div>
<h5 id="mean-absolute-percentage-error-mape">平均绝对百分误差（Mean Absolute Percentage Error, MAPE）<a class="headerlink" href="#mean-absolute-percentage-error-mape" title="Permanent link">&para;</a></h5>
<div class="arithmatex">\[
MAPE = \frac{1}{n} \sum_{i=1}^{n} \left| \frac{y_i - \hat{y}_i}{y_i} \right| \times 100\%
\]</div>
<h5 id="r2">R²（决定系数）<a class="headerlink" href="#r2" title="Permanent link">&para;</a></h5>
<div class="arithmatex">\[
R^2 = 1 - \frac{\sum_{i=1}^{n} (y_i - \hat{y}_i)^2}{\sum_{i=1}^{n} (y_i - \bar{y})^2}
\]</div>
<p>其中，<span class="arithmatex">\(\bar{y}\)</span> 是实际值的均值。</p>
<h4 id="_6">不平衡数据集处理<a class="headerlink" href="#_6" title="Permanent link">&para;</a></h4>
<p>对于不平衡数据集，单一的准确率可能会误导模型性能评估。此时，精确率、召回率和F1分数等指标更为重要。  </p>
<h3 id="22">2.2 交叉验证<a class="headerlink" href="#22" title="Permanent link">&para;</a></h3>
<p>交叉验证是一种评估模型性能的技术，通过将数据集划分为多个子集，轮流使用其中一个子集作为测试集，其余子集作为训练集。常见的交叉验证方法有：    </p>
<ul>
<li>K折交叉验证（K-Fold Cross-Validation）</li>
<li>留一法交叉验证（Leave-One-Out Cross-Validation）</li>
<li>分层K折交叉验证（Stratified K-Fold Cross-Validation）     </li>
</ul>
<h5 id="kk-fold-cross-validation">K折交叉验证（K-Fold Cross-Validation）<a class="headerlink" href="#kk-fold-cross-validation" title="Permanent link">&para;</a></h5>
<p>K折交叉验证将数据集划分为K个子集，轮流使用每个子集作为测试集，其余子集作为训练集。最终的模型性能是K次评估结果的平均值。</p>
<h5 id="leave-one-out-cross-validation">留一法交叉验证（Leave-One-Out Cross-Validation）<a class="headerlink" href="#leave-one-out-cross-validation" title="Permanent link">&para;</a></h5>
<p>留一法交叉验证是K折交叉验证的特例，其中K等于样本数量。每次使用一个样本作为测试集，其余样本作为训练集。适用于小数据集，但计算成本较高。  </p>
<h5 id="kstratified-k-fold-cross-validation">分层K折交叉验证（Stratified K-Fold Cross-Validation）<a class="headerlink" href="#kstratified-k-fold-cross-validation" title="Permanent link">&para;</a></h5>
<p>分层K折交叉验证在划分数据集时，保持各类样本的比例与原始数据集一致，适用于分类任务中的不平衡数据集。</p>
<h3 id="23">2.3 模型选择与调优<a class="headerlink" href="#23" title="Permanent link">&para;</a></h3>
<p>选择合适的模型和调优模型参数是提高模型性能的关键步骤。常用的方法包括：</p>
<ul>
<li>网格搜索（Grid Search）</li>
<li>随机搜索（Random Search）</li>
<li>贝叶斯优化（Bayesian Optimization）</li>
<li>超参数调优（Hyperparameter Tuning）       </li>
</ul>
<h5 id="grid-search">网格搜索（Grid Search）<a class="headerlink" href="#grid-search" title="Permanent link">&para;</a></h5>
<p>网格搜索通过定义一组超参数的取值范围，遍历所有可能的组合，找到性能最优的参数组合。适用于参数空间较小的情况。</p>
<h5 id="random-search">随机搜索（Random Search）<a class="headerlink" href="#random-search" title="Permanent link">&para;</a></h5>
<p>随机搜索从定义的超参数空间中随机采样一定数量的参数组合，评估其性能。适用于参数空间较大的情况，计算效率较高。</p>
<h5 id="bayesian-optimization">贝叶斯优化（Bayesian Optimization）<a class="headerlink" href="#bayesian-optimization" title="Permanent link">&para;</a></h5>
<p>贝叶斯优化通过构建代理模型，利用已有的评估结果指导下一次的参数选择，逐步逼近最优参数组合。适用于计算成本较高的情况。</p>
<h5 id="hyperparameter-tuning">超参数调优（Hyperparameter Tuning）<a class="headerlink" href="#hyperparameter-tuning" title="Permanent link">&para;</a></h5>
<p>超参数调优是指调整模型的超参数（如学习率、正则化参数等）以优化模型性能。可以结合上述方法进行调优。</p>
<h3 id="24">2.4 模型解释性<a class="headerlink" href="#24" title="Permanent link">&para;</a></h3>
<p>模型解释性是指理解和解释模型的决策过程，帮助用户信任和使用模型。常用的方法包括：</p>
<ul>
<li>特征重要性（Feature Importance）</li>
<li>局部解释模型（LIME）</li>
<li>SHAP值（SHapley Additive exPlanations）       </li>
</ul>
<h5 id="feature-importance">特征重要性（Feature Importance）<a class="headerlink" href="#feature-importance" title="Permanent link">&para;</a></h5>
<p>特征重要性评估每个特征对模型预测的贡献，常用于树模型。可以通过查看特征重要性排名，了解哪些特征对模型影响最大。  </p>
<h5 id="lime">局部解释模型（LIME）<a class="headerlink" href="#lime" title="Permanent link">&para;</a></h5>
<p>LIME通过在局部区域拟合简单模型，解释复杂模型的预测结果。适用于任何类型的模型，帮助理解单个预测的原因。  </p>
<h5 id="shapshapley-additive-explanations">SHAP值（SHapley Additive exPlanations）<a class="headerlink" href="#shapshapley-additive-explanations" title="Permanent link">&para;</a></h5>
<p>SHAP值基于博弈论，量化每个特征对预测结果的贡献。提供全局和局部的解释，适用于各种模型类型。  </p>
<h3 id="25">2.5 模型部署<a class="headerlink" href="#25" title="Permanent link">&para;</a></h3>
<h4 id="_7">什么是模型部署？<a class="headerlink" href="#_7" title="Permanent link">&para;</a></h4>
<ul>
<li><strong>训练阶段</strong>：你在本地用数据训练出模型（比如 sklearn、PyTorch、TensorFlow）。</li>
<li><strong>部署阶段</strong>：让别人能使用模型，通常通过：<ol>
<li>本地调用（Python 脚本或 Notebook）</li>
<li>打包 API 服务（Flask/FastAPI/Triton）</li>
<li>容器化 &amp; 云部署（Docker + Kubernetes + 云服务）</li>
<li>前端/移动端集成（ONNX/TensorRT/TF Lite）</li>
</ol>
</li>
</ul>
<h4 id="1">1、本地部署<a class="headerlink" href="#1" title="Permanent link">&para;</a></h4>
<p>适合学习和小规模测试。</p>
<p><strong>方式</strong>：直接保存模型，再加载调用。</p>
<div class="highlight"><pre><span></span><code><span class="kn">import</span><span class="w"> </span><span class="nn">joblib</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">sklearn.linear_model</span><span class="w"> </span><span class="kn">import</span> <span class="n">LogisticRegression</span>

<span class="c1"># 训练模型</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">LogisticRegression</span><span class="p">()</span>
<span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>

<span class="c1"># 保存模型</span>
<span class="n">joblib</span><span class="o">.</span><span class="n">dump</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="s2">&quot;model.pkl&quot;</span><span class="p">)</span>

<span class="c1"># 加载模型</span>
<span class="n">loaded_model</span> <span class="o">=</span> <span class="n">joblib</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="s2">&quot;model.pkl&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">loaded_model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">))</span>
</code></pre></div>
<h4 id="2api">2、API 服务化部署<a class="headerlink" href="#2api" title="Permanent link">&para;</a></h4>
<p>API 服务化部署.</p>
<h5 id="fastapi">FastAPI 部署<a class="headerlink" href="#fastapi" title="Permanent link">&para;</a></h5>
<p><div class="highlight"><pre><span></span><code><span class="kn">from</span><span class="w"> </span><span class="nn">fastapi</span><span class="w"> </span><span class="kn">import</span> <span class="n">FastAPI</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">joblib</span>

<span class="n">app</span> <span class="o">=</span> <span class="n">FastAPI</span><span class="p">()</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">joblib</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="s2">&quot;model.pkl&quot;</span><span class="p">)</span>

<span class="nd">@app</span><span class="o">.</span><span class="n">post</span><span class="p">(</span><span class="s2">&quot;/predict&quot;</span><span class="p">)</span>
<span class="k">def</span><span class="w"> </span><span class="nf">predict</span><span class="p">(</span><span class="n">features</span><span class="p">:</span> <span class="nb">list</span><span class="p">[</span><span class="nb">float</span><span class="p">]):</span>
    <span class="n">pred</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">predict</span><span class="p">([</span><span class="n">features</span><span class="p">])</span>
    <span class="k">return</span> <span class="p">{</span><span class="s2">&quot;prediction&quot;</span><span class="p">:</span> <span class="nb">int</span><span class="p">(</span><span class="n">pred</span><span class="p">[</span><span class="mi">0</span><span class="p">])}</span>
</code></pre></div>
<strong>启动</strong></p>
<div class="highlight"><pre><span></span><code>uvicorn<span class="w"> </span>app:app<span class="w"> </span>--reload
</code></pre></div>
<h4 id="3">3、容器化部署<a class="headerlink" href="#3" title="Permanent link">&para;</a></h4>
<p>当你需要在不同机器上运行，或部署到云端时，使用 Docker。</p>
<p><strong>Dockerfile 示例</strong>
<div class="highlight"><pre><span></span><code><span class="k">FROM</span><span class="w"> </span><span class="s">python:3.10-slim</span>
<span class="k">WORKDIR</span><span class="w"> </span><span class="s">/app</span>
<span class="k">COPY</span><span class="w"> </span>requirements.txt<span class="w"> </span>.
<span class="k">RUN</span><span class="w"> </span>pip<span class="w"> </span>install<span class="w"> </span>-r<span class="w"> </span>requirements.txt
<span class="k">COPY</span><span class="w"> </span>.<span class="w"> </span>.
<span class="k">CMD</span><span class="w"> </span><span class="p">[</span><span class="s2">&quot;uvicorn&quot;</span><span class="p">,</span><span class="w"> </span><span class="s2">&quot;app:app&quot;</span><span class="p">,</span><span class="w"> </span><span class="s2">&quot;--host&quot;</span><span class="p">,</span><span class="w"> </span><span class="s2">&quot;0.0.0.0&quot;</span><span class="p">,</span><span class="w"> </span><span class="s2">&quot;--port&quot;</span><span class="p">,</span><span class="w"> </span><span class="s2">&quot;8000&quot;</span><span class="p">]</span>
</code></pre></div>
构建镜像并运行：</p>
<div class="highlight"><pre><span></span><code>docker<span class="w"> </span>build<span class="w"> </span>-t<span class="w"> </span>ml-api<span class="w"> </span>.
docker<span class="w"> </span>run<span class="w"> </span>-p<span class="w"> </span><span class="m">8000</span>:8000<span class="w"> </span>ml-api
</code></pre></div>
<h4 id="4">4、云端部署<a class="headerlink" href="#4" title="Permanent link">&para;</a></h4>
<h5 id="_8">常见选择<a class="headerlink" href="#_8" title="Permanent link">&para;</a></h5>
<ul>
<li>AWS Sagemaker：官方托管服务，支持自动伸缩。</li>
<li>Google Vertex AI：适合 TensorFlow、PyTorch。</li>
<li>Azure ML：企业友好。</li>
<li>Hugging Face Spaces：免费快速搭建。</li>
<li>Render/Heroku：快速 Web 服务部署。</li>
</ul>
<h5 id="hugging-face-spaces-gradio">Hugging Face Spaces 示例（Gradio）<a class="headerlink" href="#hugging-face-spaces-gradio" title="Permanent link">&para;</a></h5>
<div class="highlight"><pre><span></span><code><span class="kn">import</span><span class="w"> </span><span class="nn">gradio</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">gr</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">joblib</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">joblib</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="s2">&quot;model.pkl&quot;</span><span class="p">)</span>

<span class="k">def</span><span class="w"> </span><span class="nf">predict</span><span class="p">(</span><span class="n">features</span><span class="p">):</span>
    <span class="k">return</span> <span class="nb">int</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">predict</span><span class="p">([</span><span class="n">features</span><span class="p">])[</span><span class="mi">0</span><span class="p">])</span>

<span class="n">iface</span> <span class="o">=</span> <span class="n">gr</span><span class="o">.</span><span class="n">Interface</span><span class="p">(</span><span class="n">fn</span><span class="o">=</span><span class="n">predict</span><span class="p">,</span> <span class="n">inputs</span><span class="o">=</span><span class="s2">&quot;text&quot;</span><span class="p">,</span> <span class="n">outputs</span><span class="o">=</span><span class="s2">&quot;label&quot;</span><span class="p">)</span>
<span class="n">iface</span><span class="o">.</span><span class="n">launch</span><span class="p">()</span>
</code></pre></div>
<h4 id="5">5、高性能推理<a class="headerlink" href="#5" title="Permanent link">&para;</a></h4>
<p>当模型较大时，需要优化：</p>
<ul>
<li>ONNX Runtime（跨平台推理）</li>
<li>TensorRT（NVIDIA GPU 加速）</li>
<li>Triton Inference Server（大规模部署）</li>
<li>vLLM（大模型推理优化）</li>
</ul>
<h2 id="knn">三、KNN算法<a class="headerlink" href="#knn" title="Permanent link">&para;</a></h2>
<p>KNN（K-Nearest Neighbors）算法是一种基于实例的监督学习算法，常用于分类和回归任务。其基本思想是通过计算样本之间的距离，找到与待预测样本最相似的K个邻居，根据邻居的类别或数值进行预测。</p>
<h3 id="31-knn">3.1 KNN算法原理<a class="headerlink" href="#31-knn" title="Permanent link">&para;</a></h3>
<p>KNN算法的主要步骤包括：</p>
<ol>
<li>选择合适的K值（邻居数量）</li>
<li>计算待预测样本与训练样本之间的距离（常用欧氏距离、曼哈顿距离等）</li>
<li>找到距离最近的K个邻居</li>
<li>根据邻居的类别或数值进行预测（分类任务中采用多数投票法，回归任务中采用平均值）   </li>
</ol>
<h5 id="_9">距离度量方法<a class="headerlink" href="#_9" title="Permanent link">&para;</a></h5>
<ul>
<li>欧氏距离（Euclidean Distance）：</li>
</ul>
<div class="arithmatex">\[
d(p, q) = \sqrt{\sum_{i=1}^{n} (p_i - q_i)^2}
\]</div>
<ul>
<li>曼哈顿距离（Manhattan Distance）：</li>
</ul>
<div class="arithmatex">\[
d(p, q) = \sum_{i=1}^{n} |p_i - q_i|
\]</div>
<ul>
<li>闵可夫斯基距离（Minkowski Distance）：</li>
</ul>
<div class="arithmatex">\[
d(p, q) = \left( \sum_{i=1}^{n} |p_i - q_i|^p \right)^{1/p}
\]</div>
<ul>
<li>余弦相似度（Cosine Similarity）：</li>
</ul>
<div class="arithmatex">\[
\text{similarity}(A, B) = \frac{A \cdot B}{\|A\| \|B\|}
\]</div>
<h3 id="32-knn">3.2 KNN算法优缺点<a class="headerlink" href="#32-knn" title="Permanent link">&para;</a></h3>
<h4 id="_10">优点<a class="headerlink" href="#_10" title="Permanent link">&para;</a></h4>
<ul>
<li>简单易懂，易于实现</li>
<li>无需训练过程，适合小数据集</li>
<li>可以处理多分类问题    </li>
</ul>
<h4 id="_11">缺点<a class="headerlink" href="#_11" title="Permanent link">&para;</a></h4>
<ul>
<li>计算复杂度高，适合小数据集</li>
<li>对噪声和异常值敏感</li>
<li>需要选择合适的K值和距离度量方法</li>
<li>维度灾难问题，随着特征数量增加，距离计算效果下降  </li>
</ul>
<h3 id="33-knn">3.3 KNN算法应用场景<a class="headerlink" href="#33-knn" title="Permanent link">&para;</a></h3>
<p>KNN算法适用于以下场景：</p>
<ul>
<li>分类任务，如文本分类、图像识别等</li>
<li>回归任务，如房价预测、股票价格预测等</li>
<li>推荐系统，如电影推荐、商品推荐等</li>
<li>异常检测，如信用卡欺诈检测、网络入侵检测等    </li>
</ul>
<h3 id="34-knn">3.4 KNN算法实现<a class="headerlink" href="#34-knn" title="Permanent link">&para;</a></h3>
<p>以下是使用Python和Scikit-learn库实现KNN算法的示例代码：</p>
<div class="highlight"><pre><span></span><code><span class="kn">import</span><span class="w"> </span><span class="nn">numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">np</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">sklearn.datasets</span><span class="w"> </span><span class="kn">import</span> <span class="n">load_iris</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">sklearn.model_selection</span><span class="w"> </span><span class="kn">import</span> <span class="n">train_test_split</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">sklearn.neighbors</span><span class="w"> </span><span class="kn">import</span> <span class="n">KNeighborsClassifier</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">sklearn.metrics</span><span class="w"> </span><span class="kn">import</span> <span class="n">classification_report</span><span class="p">,</span><span class="n">confusion_matrix</span><span class="p">,</span><span class="n">ConfusionMatrixDisplay</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">sklearn.preprocessing</span><span class="w"> </span><span class="kn">import</span> <span class="n">StandardScaler</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">matplotlib.pyplot</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">plt</span>

<span class="c1"># 加载数据集</span>
<span class="n">data</span> <span class="o">=</span> <span class="n">load_iris</span><span class="p">()</span>
<span class="n">X</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">data</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">target</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;特征名称：&quot;</span><span class="p">,</span><span class="n">data</span><span class="o">.</span><span class="n">feature_names</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;目标值：&quot;</span><span class="p">,</span><span class="n">data</span><span class="o">.</span><span class="n">target_names</span><span class="p">)</span>
<span class="c1"># 拆分训练数据和测试数据</span>
<span class="n">x_train</span><span class="p">,</span><span class="n">x_test</span><span class="p">,</span><span class="n">y_train</span><span class="p">,</span><span class="n">y_test</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span><span class="n">X</span><span class="p">,</span><span class="n">y</span><span class="p">,</span><span class="n">test_size</span><span class="o">=</span><span class="mf">0.2</span><span class="p">,</span><span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;训练集形状：&quot;</span><span class="p">,</span><span class="n">x_train</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;测试集形状：&quot;</span><span class="p">,</span><span class="n">x_test</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
<span class="c1"># 标准化</span>
<span class="n">scaler</span> <span class="o">=</span> <span class="n">StandardScaler</span><span class="p">()</span>
<span class="n">x_train</span> <span class="o">=</span> <span class="n">scaler</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">x_train</span><span class="p">)</span>
<span class="n">x_test</span> <span class="o">=</span> <span class="n">scaler</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">x_test</span><span class="p">)</span>
<span class="c1"># 训练模型</span>
<span class="n">knn</span> <span class="o">=</span> <span class="n">KNeighborsClassifier</span><span class="p">(</span><span class="n">n_neighbors</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span><span class="n">n_jobs</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
<span class="n">knn</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">x_train</span><span class="p">,</span><span class="n">y_train</span><span class="p">)</span>
<span class="c1"># 模型评估</span>
<span class="n">y_pred</span> <span class="o">=</span> <span class="n">knn</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">x_test</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;混淆矩阵&quot;</span><span class="o">.</span><span class="n">center</span><span class="p">(</span><span class="mi">80</span><span class="p">,</span><span class="s2">&quot;=&quot;</span><span class="p">))</span>
<span class="n">cm</span> <span class="o">=</span> <span class="n">confusion_matrix</span><span class="p">(</span><span class="n">y_true</span><span class="o">=</span><span class="n">y_test</span><span class="p">,</span><span class="n">y_pred</span><span class="o">=</span><span class="n">y_pred</span><span class="p">)</span>
<span class="n">disp</span> <span class="o">=</span> <span class="n">ConfusionMatrixDisplay</span><span class="p">(</span><span class="n">confusion_matrix</span><span class="o">=</span><span class="n">cm</span><span class="p">)</span>
<span class="n">disp</span><span class="o">.</span><span class="n">plot</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;分类报告&quot;</span><span class="o">.</span><span class="n">center</span><span class="p">(</span><span class="mi">80</span><span class="p">,</span><span class="s2">&quot;=&quot;</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="n">classification_report</span><span class="p">(</span><span class="n">y_true</span><span class="o">=</span><span class="n">y_test</span><span class="p">,</span><span class="n">y_pred</span><span class="o">=</span><span class="n">y_pred</span><span class="p">))</span>
</code></pre></div>
<p><code>KNeighborsClassifier</code> 是 scikit-learn 中基于 k-近邻（k-NN）算法的分类模型，通过计算待预测样本与训练集中最近邻样本的距离进行分类。以下是其核心参数的详细说明：</p>
<h4 id="1-n_neighbors"><strong>1. </strong><code>n_neighbors</code><a class="headerlink" href="#1-n_neighbors" title="Permanent link">&para;</a></h4>
<ul>
<li><strong>类型</strong>：<code>int</code>，默认值 <code>5</code></li>
<li><strong>作用</strong>：指定分类时参考的“最近邻”样本数量（k值）。</li>
<li><strong>说明</strong>：<ul>
<li>k值越小，模型对噪声越敏感，可能过拟合；k值越大，模型平滑性增强，但可能忽略局部特征。</li>
<li>通常通过交叉验证（如网格搜索）选择最优k值。</li>
</ul>
</li>
</ul>
<h4 id="2-weights"><strong>2. </strong><code>weights</code><a class="headerlink" href="#2-weights" title="Permanent link">&para;</a></h4>
<ul>
<li><strong>类型</strong>：<code>str</code> 或 <code>callable</code>，可选值 <code>'uniform'</code>（默认）、<code>'distance'</code> 或自定义函数</li>
<li><strong>作用</strong>：指定邻居样本的权重计算方式。</li>
<li><strong>说明</strong>：<ul>
<li><code>'uniform'</code>：所有邻居权重相同，直接按多数投票分类。</li>
<li><code>'distance'</code>：权重与距离成反比（距离越近权重越大），即 <code>weight = 1 / distance</code>。</li>
<li><code>callable</code>：自定义权重函数，输入距离数组，返回对应的权重数组。</li>
</ul>
</li>
</ul>
<h4 id="3-algorithm"><strong>3. </strong><code>algorithm</code><a class="headerlink" href="#3-algorithm" title="Permanent link">&para;</a></h4>
<ul>
<li><strong>类型</strong>：<code>str</code>，可选值 <code>'auto'</code>（默认）、<code>'ball_tree'</code>、<code>'kd_tree'</code>、<code>'brute'</code></li>
<li><strong>作用</strong>：指定计算最近邻的算法。</li>
<li><strong>说明</strong>：<ul>
<li><code>'auto'</code>：根据数据规模和维度自动选择（小数据用 <code>'brute'</code>，高维数据用树结构）。</li>
<li><code>'brute'</code>：暴力搜索（遍历所有样本计算距离），适用于低维小数据集。</li>
<li><code>'kd_tree'</code>/<code>'ball_tree'</code>：基于树结构的高效搜索（KD树适合低维数据，Ball树适合高维数据）。</li>
</ul>
</li>
</ul>
<h4 id="4-leaf_size"><strong>4. </strong><code>leaf_size</code><a class="headerlink" href="#4-leaf_size" title="Permanent link">&para;</a></h4>
<ul>
<li><strong>类型</strong>：<code>int</code>，默认值 <code>30</code></li>
<li><strong>作用</strong>：树结构（<code>kd_tree</code>/<code>ball_tree</code>）的叶节点大小。</li>
<li><strong>说明</strong>：<ul>
<li>叶节点越小，树结构越复杂，查询速度越快但内存占用更高；反之则相反。</li>
<li>仅在 <code>algorithm='kd_tree'</code> 或 <code>'ball_tree'</code> 时生效。</li>
</ul>
</li>
</ul>
<h4 id="5-p"><strong>5. </strong><code>p</code><a class="headerlink" href="#5-p" title="Permanent link">&para;</a></h4>
<ul>
<li><strong>类型</strong>：<code>int</code>，默认值 <code>2</code></li>
<li><strong>作用</strong>：Minkowski距离的幂次参数（仅当 <code>metric='minkowski'</code> 时生效）。</li>
<li><strong>说明</strong>：<ul>
<li><code>p=1</code>：等价于曼哈顿距离（L1距离）：<code>|x1 - x2| + |y1 - y2|</code>。</li>
<li><code>p=2</code>：等价于欧几里得距离（L2距离）：<code>√[(x1-x2)² + (y1-y2)²]</code>。</li>
<li><code>p&gt;2</code>：高阶 Minkowski 距离，如 <code>p=∞</code> 时接近切比雪夫距离。</li>
</ul>
</li>
</ul>
<h4 id="6-metric"><strong>6. </strong><code>metric</code><a class="headerlink" href="#6-metric" title="Permanent link">&para;</a></h4>
<ul>
<li><strong>类型</strong>：<code>str</code> 或 <code>callable</code>，默认值 <code>'minkowski'</code></li>
<li><strong>作用</strong>：指定距离度量方式。</li>
<li><strong>常用取值</strong>：<ul>
<li><code>'euclidean'</code>：欧几里得距离（等价于 <code>metric='minkowski'</code> 且 <code>p=2</code>）。</li>
<li><code>'manhattan'</code>：曼哈顿距离（等价于 <code>metric='minkowski'</code> 且 <code>p=1</code>）。</li>
<li><code>'chebyshev'</code>：切比雪夫距离（<code>max(|x1-x2|, |y1-y2|)</code>）。</li>
<li><code>'cosine'</code>：余弦相似度（常用于文本分类等稀疏数据）。</li>
<li><code>'precomputed'</code>：输入为预计算的距离矩阵（此时 <code>X</code> 需是 <code>n_samples x n_samples</code> 的距离矩阵）。</li>
</ul>
</li>
</ul>
<h4 id="7-metric_params"><strong>7. </strong><code>metric_params</code><a class="headerlink" href="#7-metric_params" title="Permanent link">&para;</a></h4>
<ul>
<li><strong>类型</strong>：<code>dict</code>，可选（默认 <code>None</code>）</li>
<li><strong>作用</strong>：传递给距离度量函数的额外参数（如自定义距离函数的参数）。</li>
</ul>
<h4 id="8-n_jobs"><strong>8. </strong><code>n_jobs</code><a class="headerlink" href="#8-n_jobs" title="Permanent link">&para;</a></h4>
<ul>
<li><strong>类型</strong>：<code>int</code>，可选（默认 <code>None</code>）</li>
<li><strong>作用</strong>：指定并行计算的线程数。</li>
<li><strong>说明</strong>：<ul>
<li><code>None</code>：使用1个线程；<code>-1</code>：使用所有可用CPU核心；<code>n</code>：使用 <code>n</code> 个核心。</li>
<li>加速邻居搜索和预测过程（训练阶段无并行）。</li>
</ul>
</li>
</ul>
<h4 id="_12"><strong>参数使用示例</strong><a class="headerlink" href="#_12" title="Permanent link">&para;</a></h4>
<div class="highlight"><pre><span></span><code>from sklearn.neighbors import KNeighborsClassifier

# 初始化模型：k=5，距离权重，欧几里得距离，并行计算
knn = KNeighborsClassifier(
    n_neighbors=5,
    weights=&#39;distance&#39;,
    metric=&#39;euclidean&#39;,
    n_jobs=-1
)
</code></pre></div>
<h4 id="_13"><strong>关键参数总结</strong><a class="headerlink" href="#_13" title="Permanent link">&para;</a></h4>
<ul>
<li><strong>核心调优参数</strong>：<code>n_neighbors</code>（k值）、<code>weights</code>（权重方式）、<code>metric</code>（距离度量）。</li>
<li><strong>效率相关参数</strong>：<code>algorithm</code>（搜索算法）、<code>leaf_size</code>（树结构参数）、<code>n_jobs</code>（并行）。</li>
</ul>
<p>根据数据规模（样本量、维度）和分布选择合适参数，通常需结合交叉验证优化。</p>
<h3 id="35-knn">3.5 KNN算法调优<a class="headerlink" href="#35-knn" title="Permanent link">&para;</a></h3>
<p>KNN算法的性能受K值和距离度量方法的影响。可以通过交叉验证和网格搜索等方法调优K值，选择最佳的距离度量方法（如欧氏距离、曼哈顿距离等）以提高模型性能。</p>
<div class="highlight"><pre><span></span><code><span class="kn">from</span><span class="w"> </span><span class="nn">sklearn.model_selection</span><span class="w"> </span><span class="kn">import</span> <span class="n">GridSearchCV</span>
<span class="c1"># 定义参数范围</span>
<span class="n">param_grid</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;n_neighbors&#39;</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">20</span><span class="p">)}</span>
<span class="c1"># 创建KNN模型</span>
<span class="n">knn</span> <span class="o">=</span> <span class="n">KNeighborsClassifier</span><span class="p">()</span>
<span class="c1"># 使用网格搜索进行参数调优</span>
<span class="n">grid_search</span> <span class="o">=</span> <span class="n">GridSearchCV</span><span class="p">(</span><span class="n">knn</span><span class="p">,</span> <span class="n">param_grid</span><span class="p">,</span> <span class="n">cv</span><span class="o">=</span><span class="mi">5</span><span class="p">)</span>
<span class="n">grid_search</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
<span class="c1"># 输出最佳参数</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Best parameters:&quot;</span><span class="p">,</span> <span class="n">grid_search</span><span class="o">.</span><span class="n">best_params_</span><span class="p">)</span>
<span class="c1"># 使用最佳参数训练模型</span>
<span class="n">best_knn</span> <span class="o">=</span> <span class="n">grid_search</span><span class="o">.</span><span class="n">best_estimator_</span>
<span class="n">best_knn</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
<span class="c1"># 预测</span>
<span class="n">y_pred</span> <span class="o">=</span> <span class="n">best_knn</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>
<span class="c1"># 评估模型</span>
<span class="nb">print</span><span class="p">(</span><span class="n">confusion_matrix</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="n">classification_report</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">))</span>
</code></pre></div>
<h3 id="36-knn">3.6 KNN算法扩展<a class="headerlink" href="#36-knn" title="Permanent link">&para;</a></h3>
<p>KNN算法可以与其他技术结合使用，如加权KNN（根据距离加权邻居的贡献）、局部敏感哈希（加速高维数据的邻居搜索）等，以提高算法的性能和适用性。    </p>
<h2 id="_14">四、逻辑回归算法<a class="headerlink" href="#_14" title="Permanent link">&para;</a></h2>
<p>逻辑回归（Logistic Regression）是一种广泛应用于分类任务的统计模型，特别适用于二分类问题。它通过估计事件发生的概率来进行分类决策。尽管名称中包含“回归”，但逻辑回归实际上是一种分类算法。</p>
<h3 id="41">4.1 逻辑回归算法原理<a class="headerlink" href="#41" title="Permanent link">&para;</a></h3>
<p>逻辑回归的核心思想是使用逻辑函数（Logistic Function）将线性回归的输出映射到0到1之间的概率值。逻辑函数的数学表达式为：</p>
<div class="arithmatex">\[
P(Y=1|X) = \frac{1}{1 + e^{-(\beta_0 + \beta_1 X_1 + \beta_2 X_2 + ... + \beta_n X_n)}}
\]</div>
<p>其中，<span class="arithmatex">\(P(Y=1|X)\)</span> 表示给定输入特征 <span class="arithmatex">\(X\)</span> 时，事件 <span class="arithmatex">\(Y=1\)</span> 发生的概率；<span class="arithmatex">\(\beta_0\)</span> 是截距项，<span class="arithmatex">\(\beta_1, \beta_2, ..., \beta_n\)</span> 是特征的系数。</p>
<p>逻辑回归通过最大化似然函数来估计模型参数，常用的优化算法包括梯度下降和牛顿法。分类决策通常基于概率阈值（如0.5），即当 <span class="arithmatex">\(P(Y=1|X) &gt; 0.5\)</span> 时预测为正类，否则为负类。</p>
<h3 id="42">4.2 逻辑回归算法优缺点<a class="headerlink" href="#42" title="Permanent link">&para;</a></h3>
<h4 id="_15">优点<a class="headerlink" href="#_15" title="Permanent link">&para;</a></h4>
<ul>
<li>简单易懂，易于实现</li>
<li>计算效率高，适合大规模数据集</li>
<li>输出概率值，便于解释和理解</li>
<li>可以处理多分类问题（通过一对多或一对一策略）</li>
</ul>
<h4 id="_16">缺点<a class="headerlink" href="#_16" title="Permanent link">&para;</a></h4>
<ul>
<li>只能处理线性可分问题，非线性关系需特征工程</li>
<li>对异常值敏感，可能影响模型性能</li>
<li>需要较大的样本量以获得稳定的参数估计</li>
</ul>
<h3 id="43">4.3 逻辑回归算法应用场景<a class="headerlink" href="#43" title="Permanent link">&para;</a></h3>
<p>逻辑回归算法适用于以下场景：</p>
<ul>
<li>二分类任务，如垃圾邮件检测、疾病预测等</li>
<li>多分类任务，如手写数字识别、图像分类等</li>
<li>风险评估，如信用评分、欺诈检测等</li>
<li>市场营销，如客户流失预测、用户行为分析等 </li>
</ul>
<h3 id="44">4.4 逻辑回归算法实现<a class="headerlink" href="#44" title="Permanent link">&para;</a></h3>
<p>以下是使用Python和Scikit-learn库实现逻辑回归算法的示例代码：</p>
<div class="highlight"><pre><span></span><code><span class="kn">import</span><span class="w"> </span><span class="nn">numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">np</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">sklearn.model_selection</span><span class="w"> </span><span class="kn">import</span> <span class="n">train_test_split</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">sklearn.preprocessing</span><span class="w"> </span><span class="kn">import</span> <span class="n">StandardScaler</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">sklearn.linear_model</span><span class="w"> </span><span class="kn">import</span> <span class="n">LogisticRegression</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">sklearn.metrics</span><span class="w"> </span><span class="kn">import</span> <span class="n">classification_report</span><span class="p">,</span> <span class="n">confusion_matrix</span> 
<span class="kn">from</span><span class="w"> </span><span class="nn">sklearn.datasets</span><span class="w"> </span><span class="kn">import</span> <span class="n">load_iris</span>
<span class="c1"># 加载数据集</span>
<span class="n">data</span> <span class="o">=</span> <span class="n">load_iris</span><span class="p">()</span>
<span class="n">X</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">data</span>
<span class="n">y</span> <span class="o">=</span> <span class="p">(</span><span class="n">data</span><span class="o">.</span><span class="n">target</span> <span class="o">==</span> <span class="mi">2</span><span class="p">)</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="nb">int</span><span class="p">)</span>  <span class="c1"># 二分类任务，将类别2作为正类</span>
<span class="c1"># 划分训练集和测试集</span>
<span class="n">X_train</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">y_test</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">test_size</span><span class="o">=</span><span class="mf">0.2</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">)</span>
<span class="c1"># 数据标准化</span>
<span class="n">scaler</span> <span class="o">=</span> <span class="n">StandardScaler</span><span class="p">()</span>
<span class="n">X_train</span> <span class="o">=</span> <span class="n">scaler</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">X_train</span><span class="p">)</span>
<span class="n">X_test</span> <span class="o">=</span> <span class="n">scaler</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>
<span class="c1"># 创建逻辑回归模型</span>
<span class="n">log_reg</span> <span class="o">=</span> <span class="n">LogisticRegression</span><span class="p">()</span>
<span class="c1"># 训练模型</span>
<span class="n">log_reg</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
<span class="c1"># 预测</span>
<span class="n">y_pred</span> <span class="o">=</span> <span class="n">log_reg</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>
<span class="c1"># 评估模型</span>
<span class="nb">print</span><span class="p">(</span><span class="n">confusion_matrix</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="n">classification_report</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">))</span>
</code></pre></div>
<h3 id="45">4.5 逻辑回归算法调优<a class="headerlink" href="#45" title="Permanent link">&para;</a></h3>
<p>逻辑回归算法的性能受正则化参数和特征选择的影响。可以通过交叉验证和网格搜索等方法调优正则化参数（如L1、L2正则化），选择最佳的特征子集以提高模型性能。    </p>
<div class="highlight"><pre><span></span><code><span class="kn">from</span><span class="w"> </span><span class="nn">sklearn.model_selection</span><span class="w"> </span><span class="kn">import</span> <span class="n">GridSearchCV</span>
<span class="c1"># 定义参数范围</span>
<span class="n">param_grid</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;C&#39;</span><span class="p">:</span> <span class="p">[</span><span class="mf">0.01</span><span class="p">,</span> <span class="mf">0.1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">10</span><span class="p">,</span> <span class="mi">100</span><span class="p">],</span> <span class="s1">&#39;penalty&#39;</span><span class="p">:</span> <span class="p">[</span><span class="s1">&#39;l1&#39;</span><span class="p">,</span> <span class="s1">&#39;l2&#39;</span><span class="p">]}</span>
<span class="c1"># 创建逻辑回归模型</span>
<span class="n">log_reg</span> <span class="o">=</span> <span class="n">LogisticRegression</span><span class="p">(</span><span class="n">solver</span><span class="o">=</span><span class="s1">&#39;liblinear&#39;</span><span class="p">)</span>  <span class="c1"># &#39;liblinear&#39; 支持 L1 正则化</span>
<span class="c1"># 使用网格搜索进行参数调优</span>
<span class="n">grid_search</span> <span class="o">=</span> <span class="n">GridSearchCV</span><span class="p">(</span><span class="n">log_reg</span><span class="p">,</span> <span class="n">param_grid</span><span class="p">,</span> <span class="n">cv</span><span class="o">=</span><span class="mi">5</span><span class="p">)</span>
<span class="n">grid_search</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
<span class="c1"># 输出最佳参数</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Best parameters:&quot;</span><span class="p">,</span> <span class="n">grid_search</span><span class="o">.</span><span class="n">best_params_</span><span class="p">)</span>
<span class="c1"># 使用最佳参数训练模型</span>
<span class="n">best_log_reg</span> <span class="o">=</span> <span class="n">grid_search</span><span class="o">.</span><span class="n">best_estimator_</span>
<span class="n">best_log_reg</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
<span class="c1"># 预测</span>
<span class="n">y_pred</span> <span class="o">=</span> <span class="n">best_log_reg</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>
<span class="c1"># 评估模型</span>

<span class="nb">print</span><span class="p">(</span><span class="n">confusion_matrix</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">))</span> 
<span class="nb">print</span><span class="p">(</span><span class="n">classification_report</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">))</span>
</code></pre></div>
<h3 id="46">4.6 逻辑回归算法扩展<a class="headerlink" href="#46" title="Permanent link">&para;</a></h3>
<p>逻辑回归算法可以与其他技术结合使用，如多项式逻辑回归（处理非线性关系）、正则化技术（防止过拟合）等，以提高算法的性能和适用性。</p>
<h2 id="_17">五、朴素贝叶斯算法<a class="headerlink" href="#_17" title="Permanent link">&para;</a></h2>
<p>朴素贝叶斯（Naive Bayes）算法是一种基于贝叶斯定理的概率分类算法，适用于文本分类、垃圾邮件检测等任务。其核心思想是假设特征之间相互独立，从而简化计算过程。</p>
<h3 id="51">5.1 朴素贝叶斯算法原理<a class="headerlink" href="#51" title="Permanent link">&para;</a></h3>
<p>朴素贝叶斯算法是一种基于贝叶斯定理和特征条件独立假设的分类算法。</p>
<h5 id="_18">贝叶斯定理<a class="headerlink" href="#_18" title="Permanent link">&para;</a></h5>
<p>贝叶斯定理描述了在已知相关证据下，事件发生的概率，公式为：</p>
<div class="arithmatex">\[P(Y|X) = \frac{P(X|Y) \cdot P(Y)}{P(X)}\]</div>
<p>其中：</p>
<ul>
<li><span class="arithmatex">\(P(Y)\)</span>：先验概率，类别<span class="arithmatex">\(Y\)</span>的初始概率。</li>
<li><span class="arithmatex">\(P(X|Y)\)</span>：似然概率，给定类别<span class="arithmatex">\(Y\)</span>时特征<span class="arithmatex">\(X\)</span>出现的概率。</li>
<li><span class="arithmatex">\(P(X)\)</span>：证据概率，特征<span class="arithmatex">\(X\)</span>出现的总概率。</li>
<li><span class="arithmatex">\(P(Y|X)\)</span>：后验概率，给定特征<span class="arithmatex">\(X\)</span>时类别<span class="arithmatex">\(Y\)</span>的概率。</li>
</ul>
<h5 id="_19">特征条件独立假设<a class="headerlink" href="#_19" title="Permanent link">&para;</a></h5>
<p>算法假设所有特征在给定类别下相互独立，即：</p>
<div class="arithmatex">\[P(X|Y) = P(x_1|Y) \cdot P(x_2|Y) \cdot \ldots \cdot P(x_n|Y)\]</div>
<p>这一假设简化了计算，但现实中特征往往存在依赖关系。</p>
<h5 id="_20">算法步骤<a class="headerlink" href="#_20" title="Permanent link">&para;</a></h5>
<ol>
<li>计算先验概率：统计训练数据中每个类别的频率，得到<span class="arithmatex">\(P(Y)\)</span>。</li>
<li>计算条件概率：对每个类别<span class="arithmatex">\(Y\)</span>，计算每个特征<span class="arithmatex">\(X\)</span>的条件概率<span class="arithmatex">\(P(X|Y)\)</span>。</li>
<li>计算后验概率：利用贝叶斯定理，结合先验概率和条件概率，计算给定特征下每个类别的后验概率<span class="arithmatex">\(P(Y|X)\)</span>。</li>
<li>分类决策：选择后验概率最大的类别作为预测结果。</li>
</ol>
<h3 id="52">5.2 朴素贝叶斯算法优缺点<a class="headerlink" href="#52" title="Permanent link">&para;</a></h3>
<h4 id="_21">优点<a class="headerlink" href="#_21" title="Permanent link">&para;</a></h4>
<ul>
<li>简单易懂，易于实现</li>
<li>计算效率高，适合大规模数据集</li>
<li>对小样本数据表现良好</li>
<li>能处理多分类问题</li>
</ul>
<h4 id="_22">缺点<a class="headerlink" href="#_22" title="Permanent link">&para;</a></h4>
<ul>
<li>假设特征独立，实际应用中可能不成立</li>
<li>对零概率问题敏感，需使用平滑技术</li>
<li>不能捕捉特征之间的复杂关系</li>
</ul>
<h3 id="53">5.3 朴素贝叶斯算法应用场景<a class="headerlink" href="#53" title="Permanent link">&para;</a></h3>
<p>朴素贝叶斯算法适用于以下场景：</p>
<ul>
<li>文本分类，如垃圾邮件检测、情感分析等</li>
<li>医疗诊断，如疾病预测等</li>
<li>市场营销，如客户细分、用户行为分析等</li>
<li>推荐系统，如电影推荐、商品推荐等  </li>
</ul>
<h3 id="54">5.4 朴素贝叶斯算法实现<a class="headerlink" href="#54" title="Permanent link">&para;</a></h3>
<p>以下是使用Python和Scikit-learn库实现朴素贝叶斯算法的示例代码：</p>
<div class="highlight"><pre><span></span><code><span class="kn">import</span><span class="w"> </span><span class="nn">numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">np</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">sklearn.model_selection</span><span class="w"> </span><span class="kn">import</span> <span class="n">train_test_split</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">sklearn.preprocessing</span><span class="w"> </span><span class="kn">import</span> <span class="n">StandardScaler</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">sklearn.naive_bayes</span><span class="w"> </span><span class="kn">import</span> <span class="n">GaussianNB</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">sklearn.metrics</span><span class="w"> </span><span class="kn">import</span> <span class="n">classification_report</span><span class="p">,</span> <span class="n">confusion_matrix</span> 
<span class="kn">from</span><span class="w"> </span><span class="nn">sklearn.datasets</span><span class="w"> </span><span class="kn">import</span> <span class="n">load_iris</span>
<span class="c1"># 加载数据集</span>
<span class="n">data</span> <span class="o">=</span> <span class="n">load_iris</span><span class="p">()</span>
<span class="n">X</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">data</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">target</span>
<span class="c1"># 划分训练集和测试集</span>
<span class="n">X_train</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">y_test</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">test_size</span><span class="o">=</span><span class="mf">0.2</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">)</span>
<span class="c1"># 数据标准化</span>
<span class="n">scaler</span> <span class="o">=</span> <span class="n">StandardScaler</span><span class="p">()</span>
<span class="n">X_train</span> <span class="o">=</span> <span class="n">scaler</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">X_train</span><span class="p">)</span>
<span class="n">X_test</span> <span class="o">=</span> <span class="n">scaler</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>
<span class="c1"># 创建朴素贝叶斯模型</span>
<span class="n">nb</span> <span class="o">=</span> <span class="n">GaussianNB</span><span class="p">()</span>
<span class="c1"># 训练模型</span>
<span class="n">nb</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
<span class="c1"># 预测</span>
<span class="n">y_pred</span> <span class="o">=</span> <span class="n">nb</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>
<span class="c1"># 评估模型</span>
<span class="nb">print</span><span class="p">(</span><span class="n">confusion_matrix</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="n">classification_report</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">))</span>
</code></pre></div>
<h3 id="55">5.5 朴素贝叶斯算法调优<a class="headerlink" href="#55" title="Permanent link">&para;</a></h3>
<p>朴素贝叶斯算法的性能受特征选择和数据预处理的影响。可以通过选择相关特征、处理缺失值和异常值等方法提高模型性能。</p>
<div class="highlight"><pre><span></span><code><span class="kn">from</span><span class="w"> </span><span class="nn">sklearn.feature_selection</span><span class="w"> </span><span class="kn">import</span> <span class="n">SelectKBest</span><span class="p">,</span> <span class="n">chi2</span>
<span class="c1"># 特征选择</span>
<span class="n">selector</span> <span class="o">=</span> <span class="n">SelectKBest</span><span class="p">(</span><span class="n">chi2</span><span class="p">,</span> <span class="n">k</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>  <span class="c1"># 选择前2个最佳特征</span>
<span class="n">X_train_selected</span> <span class="o">=</span> <span class="n">selector</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
<span class="n">X_test_selected</span> <span class="o">=</span> <span class="n">selector</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>
<span class="c1"># 使用选择的特征训练模型</span>
<span class="n">nb</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train_selected</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
<span class="c1"># 预测</span>
<span class="n">y_pred</span> <span class="o">=</span> <span class="n">nb</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test_selected</span><span class="p">)</span>
<span class="c1"># 评估模型</span>
<span class="nb">print</span><span class="p">(</span><span class="n">confusion_matrix</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="n">classification_report</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">))</span>
</code></pre></div>
<h3 id="56">5.6 朴素贝叶斯算法扩展<a class="headerlink" href="#56" title="Permanent link">&para;</a></h3>
<p>朴素贝叶斯算法可以与其他技术结合使用，如多项式朴素贝叶斯（处理文本数据）、贝叶斯网络（捕捉特征之间的关系）等，以提高算法的性能和适用性。      </p>
<h2 id="_23">六、决策树模型<a class="headerlink" href="#_23" title="Permanent link">&para;</a></h2>
<p>决策树（Decision Tree）是一种基于树形结构的监督学习算法，适用于分类和回归任务。其核心思想是通过一系列的决策规则将数据划分为不同的类别或数值范围。</p>
<h3 id="61">6.1 决策树模型原理<a class="headerlink" href="#61" title="Permanent link">&para;</a></h3>
<p>决策树模型是一种基于树状结构的监督学习算法，用于分类和回归任务。其原理主要包括以下步骤：</p>
<h5 id="_24">模型结构<a class="headerlink" href="#_24" title="Permanent link">&para;</a></h5>
<ul>
<li>根节点：树的起点，包含所有样本数据，是第一个特征判断的起点。</li>
<li>内部节点：表示对某个特征的判断条件，每个内部节点会根据特征值分裂为多个子节点。</li>
<li>分支：连接节点的线段，代表特征判断的结果。</li>
<li>叶子节点：树的终点，输出最终的预测结果。</li>
</ul>
<h5 id="_25">特征选择<a class="headerlink" href="#_25" title="Permanent link">&para;</a></h5>
<ul>
<li>目标：选择最优特征进行节点分裂，以提高子节点的纯度。</li>
<li>衡量指标：<ul>
<li>信息熵：度量数据集的不确定性，熵值越低，纯度越高。</li>
<li>信息增益：基于熵的计算，选择信息增益最大的特征进行分裂。</li>
<li>基尼指数：衡量数据集的不纯度，基尼指数越小，纯度越高。</li>
</ul>
</li>
</ul>
<h6 id="entropy">信息熵（Entropy）<a class="headerlink" href="#entropy" title="Permanent link">&para;</a></h6>
<ul>
<li>定义：信息熵是度量样本集合纯度的指标，表示数据的混乱程度。熵值越小，数据纯度越高。</li>
<li>公式：<ul>
<li><span class="arithmatex">\(Ent(D) = -\sum_{k=1}^{|y|} p_k \log_2 p_k\)</span></li>
<li>其中，<span class="arithmatex">\(p_k\)</span>是样本集合<span class="arithmatex">\(D\)</span>中第<span class="arithmatex">\(k\)</span>类样本所占的比例。</li>
</ul>
</li>
<li>作用：在决策树算法中，信息熵用于计算节点的纯度，选择最优特征进行划分。</li>
</ul>
<h6 id="information-gain">信息增益（Information Gain）<a class="headerlink" href="#information-gain" title="Permanent link">&para;</a></h6>
<ul>
<li>定义：信息增益是使用某个特征对数据集进行划分后，信息熵的减少量。信息增益越大，说明该特征对分类的贡献越大。</li>
<li>公式：<ul>
<li><span class="arithmatex">\(Gain(D, a) = Ent(D) - \sum_{v=1}^{V} \frac{|D^v|}{|D|} Ent(D^v)\)</span></li>
<li>其中，<span class="arithmatex">\(a\)</span>是特征，<span class="arithmatex">\(V\)</span>是特征<span class="arithmatex">\(a\)</span>的可能取值个数，<span class="arithmatex">\(D^v\)</span>是特征<span class="arithmatex">\(a\)</span>取值为<span class="arithmatex">\(v\)</span>的样本子集。</li>
</ul>
</li>
<li>作用：在ID3决策树算法中，选择信息增益最大的特征作为划分依据。</li>
</ul>
<h6 id="gini-index">基尼指数（Gini Index）<a class="headerlink" href="#gini-index" title="Permanent link">&para;</a></h6>
<ul>
<li>定义：基尼指数是度量数据集不纯度的指标，表示从数据集中随机抽取两个样本类别标记不一致的概率。基尼指数越小，数据纯度越高。</li>
<li>公式：<ul>
<li><span class="arithmatex">\(Gini(D) = 1 - \sum_{k=1}^{|y|} p_k^2\)</span></li>
<li>其中，<span class="arithmatex">\(p_k\)</span>是样本集合<span class="arithmatex">\(D\)</span>中第<span class="arithmatex">\(k\)</span>类样本所占的比例。</li>
</ul>
</li>
<li>作用：在CART（分类与回归树）决策树算法中，选择基尼指数最小的特征进行划分。</li>
</ul>
<h6 id="_26">总结<a class="headerlink" href="#_26" title="Permanent link">&para;</a></h6>
<ul>
<li>信息熵和基尼指数：都是衡量数据纯度的指标，值越小，纯度越高<dfn seq=source_group_web_10 type=source_group_pro>8。</li>
<li>信息增益：用于衡量特征划分对纯度提升的效果，值越大，特征的分类能力越强。</li>
<li>应用场景：<ul>
<li>ID3算法：使用信息增益选择特征。</li>
<li>C4.5算法：使用信息增益率（信息增益与特征固有值的比值）选择特征。</li>
<li>CART算法：使用基尼指数选择特征。</li>
</ul>
</li>
</ul>
<h5 id="_27">树的生成<a class="headerlink" href="#_27" title="Permanent link">&para;</a></h5>
<ol>
<li>初始节点：将所有样本视为初始节点。</li>
<li>最优分割：计算每个特征的最优分割点，选择提升纯度最大的分割方式。</li>
<li>递归分裂：根据最优分割点将数据集划分为子集，递归地对子集重复上述过程。</li>
<li>停止条件：当子节点足够“纯”或满足预设条件（如达到最大深度、样本数小于阈值）时停止分裂。</li>
</ol>
<h5 id="_28">剪枝处理<a class="headerlink" href="#_28" title="Permanent link">&para;</a></h5>
<ul>
<li>目的：防止过拟合，提高模型泛化能力。</li>
<li>方法：<ul>
<li>预剪枝：在树的生长过程中设定指标，达到指标时停止生长。</li>
<li>后剪枝：先充分生长，再合并相邻叶节点，减少树的复杂度。</li>
</ul>
</li>
</ul>
<p>决策树模型通过递归地选择最优特征进行分裂，构建树状结构，实现对数据的分类或回归。其优点是易于理解和解释，但对连续字段和时间序列数据处理能力较弱。</p>
<h3 id="62">6.2 决策树模型优缺点<a class="headerlink" href="#62" title="Permanent link">&para;</a></h3>
<h4 id="_29">优点<a class="headerlink" href="#_29" title="Permanent link">&para;</a></h4>
<ul>
<li>易于理解和解释，直观展示决策过程</li>
<li>计算效率高，适合大规模数据集</li>
<li>能处理多分类问题</li>
<li>能处理缺失值和异常值</li>
<li>可处理数值型和类别型特征</li>
</ul>
<h4 id="_30">缺点<a class="headerlink" href="#_30" title="Permanent link">&para;</a></h4>
<ul>
<li>容易过拟合，需剪枝等技术防止</li>
<li>对噪声敏感，可能影响模型性能</li>
<li>不能捕捉特征之间的复杂关系</li>
<li>决策边界为轴平行，可能不适合某些数据分布</li>
</ul>
<h3 id="63">6.3 决策树模型应用场景<a class="headerlink" href="#63" title="Permanent link">&para;</a></h3>
<p>决策树模型适用于以下场景：</p>
<ul>
<li>分类任务，如客户细分、信用评分等</li>
<li>回归任务，如房价预测、销售预测等</li>
<li>风险评估，如欺诈检测、信用风险评估等</li>
<li>医疗诊断，如疾病预测等</li>
<li>市场营销，如用户行为分析、客户流失预测等  </li>
</ul>
<h3 id="64">6.4 决策树模型实现<a class="headerlink" href="#64" title="Permanent link">&para;</a></h3>
<p>以下是使用Python和Scikit-learn库实现决策树模型的示例代码：
<div class="highlight"><pre><span></span><code><span class="kn">import</span><span class="w"> </span><span class="nn">numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">np</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">sklearn.model_selection</span><span class="w"> </span><span class="kn">import</span> <span class="n">train_test_split</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">sklearn.preprocessing</span><span class="w"> </span><span class="kn">import</span> <span class="n">StandardScaler</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">sklearn.tree</span><span class="w"> </span><span class="kn">import</span> <span class="n">DecisionTreeClassifier</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">sklearn.metrics</span><span class="w"> </span><span class="kn">import</span> <span class="n">classification_report</span><span class="p">,</span> <span class="n">confusion_matrix</span> 
<span class="kn">from</span><span class="w"> </span><span class="nn">sklearn.datasets</span><span class="w"> </span><span class="kn">import</span> <span class="n">load_iris</span>
<span class="c1"># 加载数据集</span>
<span class="n">data</span> <span class="o">=</span> <span class="n">load_iris</span><span class="p">()</span>
<span class="n">X</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">data</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">target</span>
<span class="c1"># 划分训练集和测试集</span>
<span class="n">X_train</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">y_test</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">test_size</span><span class="o">=</span><span class="mf">0.2</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">)</span>
<span class="c1"># 数据标准化</span>
<span class="n">scaler</span> <span class="o">=</span> <span class="n">StandardScaler</span><span class="p">()</span>  
<span class="n">X_train</span> <span class="o">=</span> <span class="n">scaler</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">X_train</span><span class="p">)</span>
<span class="n">X_test</span> <span class="o">=</span> <span class="n">scaler</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>   
<span class="c1"># 创建决策树模型</span>
<span class="n">dt</span> <span class="o">=</span> <span class="n">DecisionTreeClassifier</span><span class="p">()</span>
<span class="c1"># 训练模型</span>
<span class="n">dt</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
<span class="c1"># 预测</span>
<span class="n">y_pred</span> <span class="o">=</span> <span class="n">dt</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>
<span class="c1"># 评估模型</span>
<span class="nb">print</span><span class="p">(</span><span class="n">confusion_matrix</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="n">classification_report</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">))</span>
</code></pre></div></p>
<h3 id="65">6.5 决策树模型调优<a class="headerlink" href="#65" title="Permanent link">&para;</a></h3>
<p>决策树模型的性能受树的深度和划分标准的影响。可以通过交叉验证和网格搜索等方法调优树的深度、最小样本分裂数等参数，以提高模型性能。
<div class="highlight"><pre><span></span><code><span class="kn">from</span><span class="w"> </span><span class="nn">sklearn.model_selection</span><span class="w"> </span><span class="kn">import</span> <span class="n">GridSearchCV</span>
<span class="c1"># 定义参数范围</span>
<span class="n">param_grid</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;max_depth&#39;</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">10</span><span class="p">),</span> <span class="s1">&#39;min_samples_split&#39;</span><span class="p">:</span> <span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">10</span><span class="p">]}</span>
<span class="c1"># 创建决策树模型    </span>
<span class="n">dt</span> <span class="o">=</span> <span class="n">DecisionTreeClassifier</span><span class="p">()</span>
<span class="c1"># 使用网格搜索进行参数调优</span>
<span class="n">grid_search</span> <span class="o">=</span> <span class="n">GridSearchCV</span><span class="p">(</span><span class="n">dt</span><span class="p">,</span> <span class="n">param_grid</span><span class="p">,</span> <span class="n">cv</span><span class="o">=</span><span class="mi">5</span><span class="p">)</span>
<span class="n">grid_search</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
<span class="c1"># 输出最佳参数</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Best parameters:&quot;</span><span class="p">,</span> <span class="n">grid_search</span><span class="o">.</span><span class="n">best_params_</span><span class="p">)</span>
<span class="c1"># 使用最佳参数训练模型</span>
<span class="n">best_dt</span> <span class="o">=</span> <span class="n">grid_search</span><span class="o">.</span><span class="n">best_estimator_</span>
<span class="n">best_dt</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
<span class="c1"># 预测</span>
<span class="n">y_pred</span> <span class="o">=</span> <span class="n">best_dt</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>
<span class="c1"># 评估模型</span>
<span class="nb">print</span><span class="p">(</span><span class="n">confusion_matrix</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="n">classification_report</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">))</span>
</code></pre></div></p>
<h3 id="66">6.6 决策树模型扩展<a class="headerlink" href="#66" title="Permanent link">&para;</a></h3>
<p>决策树模型可以与其他技术结合使用，如随机森林（集成多棵决策树）、梯度提升树（提升弱分类器）等，以提高算法的性能和适用性。</p>
<h2 id="_31">七、随机森林分类模型<a class="headerlink" href="#_31" title="Permanent link">&para;</a></h2>
<p>随机森林（Random Forest）是一种集成学习算法，通过构建多棵决策树并结合其预测结果来提高模型的性能和稳定性。随机森林适用于分类和回归任务，具有较强的抗过拟合能力。</p>
<h3 id="71">7.1 随机森林分类模型原理<a class="headerlink" href="#71" title="Permanent link">&para;</a></h3>
<p>随机森林通过以下步骤构建模型：</p>
<ol>
<li>从原始数据集中有放回地抽取多个子样本集（Bootstrap采样）。</li>
<li>对每个子样本集训练一棵决策树，在每个节点划分时随机选择部分特征进行分裂。</li>
<li>对于分类任务，通过多数投票法结合所有决策树的预测结果；对于回归任务，通过平均值结合预测结果。</li>
</ol>
<h3 id="72">7.2 随机森林分类模型优缺点<a class="headerlink" href="#72" title="Permanent link">&para;</a></h3>
<h4 id="_32">优点<a class="headerlink" href="#_32" title="Permanent link">&para;</a></h4>
<ul>
<li>抗过拟合能力强，适合高维数据</li>
<li>计算效率高，适合大规模数据集</li>
<li>能处理多分类问题</li>
<li>能处理缺失值和异常值</li>
<li>提供特征重要性评估</li>
</ul>
<h4 id="_33">缺点<a class="headerlink" href="#_33" title="Permanent link">&para;</a></h4>
<ul>
<li>模型复杂，难以解释</li>
<li>训练时间较长，尤其是树的数量较多时</li>
<li>对于某些数据分布，可能不如单棵决策树表现  </li>
</ul>
<h3 id="73">7.3 随机森林分类模型应用场景<a class="headerlink" href="#73" title="Permanent link">&para;</a></h3>
<p>随机森林分类模型适用于以下场景：</p>
<ul>
<li>分类任务，如客户细分、信用评分等</li>
<li>回归任务，如房价预测、销售预测等</li>
<li>风险评估，如欺诈检测、信用风险评估等</li>
<li>医疗诊断，如疾病预测等</li>
<li>市场营销，如用户行为分析、客户流失预测等</li>
<li>图像分类，如手写数字识别、物体检测等</li>
<li>文本分类，如垃圾邮件检测、情感分析等</li>
</ul>
<h3 id="74">7.4 随机森林分类模型实现<a class="headerlink" href="#74" title="Permanent link">&para;</a></h3>
<p>以下是使用Python和Scikit-learn库实现随机森林分类模型的示例代码
<div class="highlight"><pre><span></span><code><span class="kn">import</span><span class="w"> </span><span class="nn">numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">np</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">sklearn.model_selection</span><span class="w"> </span><span class="kn">import</span> <span class="n">train_test_split</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">sklearn.preprocessing</span><span class="w"> </span><span class="kn">import</span> <span class="n">StandardScaler</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">sklearn.ensemble</span><span class="w"> </span><span class="kn">import</span> <span class="n">RandomForestClassifier</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">sklearn.metrics</span><span class="w"> </span><span class="kn">import</span> <span class="n">classification_report</span><span class="p">,</span> <span class="n">confusion_matrix</span> 
<span class="kn">from</span><span class="w"> </span><span class="nn">sklearn.datasets</span><span class="w"> </span><span class="kn">import</span> <span class="n">load_iris</span>
<span class="c1"># 加载数据集</span>
<span class="n">data</span> <span class="o">=</span> <span class="n">load_iris</span><span class="p">()</span>
<span class="n">X</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">data</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">target</span>
<span class="c1"># 划分训练集和测试集</span>
<span class="n">X_train</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">y_test</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">test_size</span><span class="o">=</span><span class="mf">0.2</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">)</span>
<span class="c1"># 数据标准化</span>
<span class="n">scaler</span> <span class="o">=</span> <span class="n">StandardScaler</span><span class="p">()</span>
<span class="n">X_train</span> <span class="o">=</span> <span class="n">scaler</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">X_train</span><span class="p">)</span>
<span class="n">X_test</span> <span class="o">=</span> <span class="n">scaler</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>
<span class="c1"># 创建随机森林模型</span>
<span class="n">rf</span> <span class="o">=</span> <span class="n">RandomForestClassifier</span><span class="p">(</span><span class="n">n_estimators</span><span class="o">=</span><span class="mi">100</span><span class="p">)</span>  <span class="c1"># 使用100棵树</span>
<span class="c1"># 训练模型</span>
<span class="n">rf</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
<span class="c1"># 预测</span>
<span class="n">y_pred</span> <span class="o">=</span> <span class="n">rf</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>
<span class="c1"># 评估模型</span>
<span class="nb">print</span><span class="p">(</span><span class="n">confusion_matrix</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="n">classification_report</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">))</span>
</code></pre></div></p>
<h3 id="75">7.5 随机森林分类模型调优<a class="headerlink" href="#75" title="Permanent link">&para;</a></h3>
<p>随机森林分类模型的性能受树的数量和深度等参数的影响。可以通过交叉验证和网格搜索等方法调优树的数量、最大深度、最小样本分裂数等参数，以提高模型性能。
<div class="highlight"><pre><span></span><code><span class="kn">from</span><span class="w"> </span><span class="nn">sklearn.model_selection</span><span class="w"> </span><span class="kn">import</span> <span class="n">GridSearchCV</span>
<span class="c1"># 定义参数范围</span>
<span class="n">param_grid</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;n_estimators&#39;</span><span class="p">:</span> <span class="p">[</span><span class="mi">50</span><span class="p">,</span> <span class="mi">100</span><span class="p">,</span> <span class="mi">200</span><span class="p">],</span> <span class="s1">&#39;max_depth&#39;</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">10</span><span class="p">),</span> <span class="s1">&#39;min_samples_split&#39;</span><span class="p">:</span> <span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">10</span><span class="p">]}</span>
<span class="c1"># 创建随机森林模型</span>
<span class="n">rf</span> <span class="o">=</span> <span class="n">RandomForestClassifier</span><span class="p">()</span>
<span class="c1"># 使用网格搜索进行参数调优</span>
<span class="n">grid_search</span> <span class="o">=</span> <span class="n">GridSearchCV</span><span class="p">(</span><span class="n">rf</span><span class="p">,</span> <span class="n">param_grid</span><span class="p">,</span> <span class="n">cv</span><span class="o">=</span><span class="mi">5</span><span class="p">)</span>
<span class="n">grid_search</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
<span class="c1"># 输出最佳参数</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Best parameters:&quot;</span><span class="p">,</span> <span class="n">grid_search</span><span class="o">.</span><span class="n">best_params_</span><span class="p">)</span>
<span class="c1"># 使用最佳参数训练模型</span>
<span class="n">best_rf</span> <span class="o">=</span> <span class="n">grid_search</span><span class="o">.</span><span class="n">best_estimator_</span>
<span class="n">best_rf</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
<span class="c1"># 预测</span>
<span class="n">y_pred</span> <span class="o">=</span> <span class="n">best_rf</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>
<span class="c1"># 评估模型</span>
<span class="nb">print</span><span class="p">(</span><span class="n">confusion_matrix</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="n">classification_report</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">))</span>
</code></pre></div></p>
<h3 id="76">7.6 随机森林分类模型扩展<a class="headerlink" href="#76" title="Permanent link">&para;</a></h3>
<p>随机森林分类模型可以与其他技术结合使用，如梯度提升树（提升弱分类器）、极端随机树（增加随机性）等，以提高算法的性能和适用性。</p>
<h2 id="_34">八、回归树模型<a class="headerlink" href="#_34" title="Permanent link">&para;</a></h2>
<p>回归树（Regression Tree）是一种基于树形结构的监督学习算法，适用于回归任务。其核心思想是通过一系列的决策规则将数据划分为不同的数值范围，从而进行数值预测。</p>
<h3 id="81">8.1 回归树模型原理<a class="headerlink" href="#81" title="Permanent link">&para;</a></h3>
<p>回归树通过递归地选择最优特征进行数据划分，构建一棵树形结构。每个节点表示一个特征，每个分支表示该特征的取值范围，每个叶节点表示一个数值预测结果。常用的划分标准包括均方误差（Mean Squared Error, MSE）和平均绝对误差（Mean Absolute Error, MAE）。</p>
<h3 id="82">8.2 回归树模型优缺点<a class="headerlink" href="#82" title="Permanent link">&para;</a></h3>
<h4 id="_35">优点<a class="headerlink" href="#_35" title="Permanent link">&para;</a></h4>
<ul>
<li>易于理解和解释，直观展示决策过程</li>
<li>计算效率高，适合大规模数据集</li>
<li>能处理缺失值和异常值</li>
<li>可处理数值型和类别型特征</li>
</ul>
<h4 id="_36">缺点<a class="headerlink" href="#_36" title="Permanent link">&para;</a></h4>
<ul>
<li>容易过拟合，需剪枝等技术防止</li>
<li>对噪声敏感，可能影响模型性能</li>
<li>不能捕捉特征之间的复杂关系</li>
<li>决策边界为轴平行，可能不适合某些数据分布</li>
</ul>
<h3 id="83">8.3 回归树模型应用场景<a class="headerlink" href="#83" title="Permanent link">&para;</a></h3>
<p>回归树模型适用于以下场景：
- 回归任务，如房价预测、销售预测等
- 风险评估，如信用风险评估等
- 医疗诊断，如疾病严重程度预测等
- 市场营销，如用户行为分析、客户流失预测等  </p>
<h3 id="84">8.4 回归树模型实现<a class="headerlink" href="#84" title="Permanent link">&para;</a></h3>
<p>以下是使用Python和Scikit-learn库实现回归树模型的示例代码
<div class="highlight"><pre><span></span><code><span class="kn">import</span><span class="w"> </span><span class="nn">numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">np</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">sklearn.model_selection</span><span class="w"> </span><span class="kn">import</span> <span class="n">train_test_split</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">sklearn.preprocessing</span><span class="w"> </span><span class="kn">import</span> <span class="n">StandardScaler</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">sklearn.tree</span><span class="w"> </span><span class="kn">import</span> <span class="n">DecisionTreeRegressor</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">sklearn.metrics</span><span class="w"> </span><span class="kn">import</span> <span class="n">mean_squared_error</span><span class="p">,</span> <span class="n">mean_absolute_error</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">sklearn.datasets</span><span class="w"> </span><span class="kn">import</span> <span class="n">load_boston</span>
<span class="c1"># 加载数据集</span>
<span class="n">data</span> <span class="o">=</span> <span class="n">load_boston</span><span class="p">()</span>
<span class="n">X</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">data</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">target</span>
<span class="c1"># 划分训练集和测试集</span>
<span class="n">X_train</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">y_test</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">test_size</span><span class="o">=</span><span class="mf">0.2</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">)</span>
<span class="c1"># 数据标准化</span>
<span class="n">scaler</span> <span class="o">=</span> <span class="n">StandardScaler</span><span class="p">()</span>
<span class="n">X_train</span> <span class="o">=</span> <span class="n">scaler</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">X_train</span><span class="p">)</span>
<span class="n">X_test</span> <span class="o">=</span> <span class="n">scaler</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>
<span class="c1"># 创建回归树模型</span>
<span class="n">rt</span> <span class="o">=</span> <span class="n">DecisionTreeRegressor</span><span class="p">()</span>
<span class="c1"># 训练模型</span>
<span class="n">rt</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
<span class="c1"># 预测</span>
<span class="n">y_pred</span> <span class="o">=</span> <span class="n">rt</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>
<span class="c1"># 评估模型</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Mean Squared Error:&quot;</span><span class="p">,</span> <span class="n">mean_squared_error</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Mean Absolute Error:&quot;</span><span class="p">,</span> <span class="n">mean_absolute_error</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">))</span>
</code></pre></div></p>
<h3 id="85">8.5 回归树模型调优<a class="headerlink" href="#85" title="Permanent link">&para;</a></h3>
<p>回归树模型的性能受树的深度和划分标准的影响。可以通过交叉验证和网格搜索等方法调优树的深度、最小样本分裂数等参数，以提高模型性能。
<div class="highlight"><pre><span></span><code><span class="kn">from</span><span class="w"> </span><span class="nn">sklearn.model_selection</span><span class="w"> </span><span class="kn">import</span> <span class="n">GridSearchCV</span>
<span class="c1"># 定义参数范围</span>
<span class="n">param_grid</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;max_depth&#39;</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">10</span><span class="p">),</span> <span class="s1">&#39;min_samples_split&#39;</span><span class="p">:</span> <span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">10</span><span class="p">]}</span>
<span class="c1"># 创建回归树模型</span>
<span class="n">rt</span> <span class="o">=</span> <span class="n">DecisionTreeRegressor</span><span class="p">()</span>
<span class="c1"># 使用网格搜索进行参数调优</span>
<span class="n">grid_search</span> <span class="o">=</span> <span class="n">GridSearchCV</span><span class="p">(</span><span class="n">rt</span><span class="p">,</span> <span class="n">param_grid</span><span class="p">,</span> <span class="n">cv</span><span class="o">=</span><span class="mi">5</span><span class="p">)</span>
<span class="n">grid_search</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
<span class="c1"># 输出最佳参数</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Best parameters:&quot;</span><span class="p">,</span> <span class="n">grid_search</span><span class="o">.</span><span class="n">best_params_</span><span class="p">)</span>
<span class="c1"># 使用最佳参数训练模型</span>
<span class="n">best_rt</span> <span class="o">=</span> <span class="n">grid_search</span><span class="o">.</span><span class="n">best_estimator_</span>
<span class="n">best_rt</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
<span class="c1"># 预测</span>
<span class="n">y_pred</span> <span class="o">=</span> <span class="n">best_rt</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>
<span class="c1"># 评估模型</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Mean Squared Error:&quot;</span><span class="p">,</span> <span class="n">mean_squared_error</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Mean Absolute Error:&quot;</span><span class="p">,</span> <span class="n">mean_absolute_error</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">))</span>
</code></pre></div></p>
<h3 id="86">8.6 回归树模型扩展<a class="headerlink" href="#86" title="Permanent link">&para;</a></h3>
<p>回归树模型可以与其他技术结合使用，如随机森林回归（集成多棵回归树）、梯度提升回归（提升弱回归器）等，以提高算法的性能和适用性。  </p>
<h2 id="gbdt">九、GBDT模型<a class="headerlink" href="#gbdt" title="Permanent link">&para;</a></h2>
<p>GBDT（Gradient Boosting Decision Tree）是一种集成学习算法，通过构建多棵决策树并结合其预测结果来提高模型的性能和稳定性。GBDT适用于分类和回归任务，具有较强的抗过拟合能力。   </p>
<h3 id="91-gbdt">9.1 GBDT模型原理<a class="headerlink" href="#91-gbdt" title="Permanent link">&para;</a></h3>
<p>GBDT通过以下步骤构建模型：</p>
<ol>
<li>初始化模型，通常使用常数值（如均值）作为初始预测值。</li>
<li>计算当前模型的残差（真实值与预测值之差）。</li>
<li>训练一棵决策树拟合残差，得到新的弱学习器。</li>
<li>将新弱学习器的预测结果加权累加到当前模型中。</li>
<li>重复步骤2-4，直到达到预定的树数量或其他停止条件。    </li>
</ol>
<h3 id="92-gbdt">9.2 GBDT模型优缺点<a class="headerlink" href="#92-gbdt" title="Permanent link">&para;</a></h3>
<h4 id="_37">优点<a class="headerlink" href="#_37" title="Permanent link">&para;</a></h4>
<ul>
<li>抗过拟合能力强，适合高维数据</li>
<li>计算效率高，适合大规模数据集</li>
<li>能处理多分类问题</li>
<li>能处理缺失值和异常值</li>
<li>提供特征重要性评估</li>
</ul>
<h4 id="_38">缺点<a class="headerlink" href="#_38" title="Permanent link">&para;</a></h4>
<ul>
<li>模型复杂，难以解释</li>
<li>训练时间较长，尤其是树的数量较多时</li>
<li>对于某些数据分布，可能不如单棵决策树表现  </li>
</ul>
<h3 id="93-gbdt">9.3 GBDT模型应用场景<a class="headerlink" href="#93-gbdt" title="Permanent link">&para;</a></h3>
<p>GBDT模型适用于以下场景：</p>
<ul>
<li>分类任务，如客户细分、信用评分等</li>
<li>回归任务，如房价预测、销售预测等</li>
<li>风险评估，如欺诈检测、信用风险评估等</li>
<li>医疗诊断，如疾病预测等</li>
<li>市场营销，如用户行为分析、客户流失预测等</li>
<li>图像分类，如手写数字识别、物体检测等</li>
<li>文本分类，如垃圾邮件检测、情感分析等</li>
</ul>
<h3 id="94-gbdt">9.4 GBDT模型实现<a class="headerlink" href="#94-gbdt" title="Permanent link">&para;</a></h3>
<p>以下是使用Python和Scikit-learn库实现GBDT模型的示例代码
<div class="highlight"><pre><span></span><code><span class="kn">import</span><span class="w"> </span><span class="nn">numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">np</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">sklearn.model_selection</span><span class="w"> </span><span class="kn">import</span> <span class="n">train_test_split</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">sklearn.preprocessing</span><span class="w"> </span><span class="kn">import</span> <span class="n">StandardScaler</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">sklearn.ensemble</span><span class="w"> </span><span class="kn">import</span> <span class="n">GradientBoostingClassifier</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">sklearn.metrics</span><span class="w"> </span><span class="kn">import</span> <span class="n">classification_report</span><span class="p">,</span> <span class="n">confusion_matrix</span> 
<span class="kn">from</span><span class="w"> </span><span class="nn">sklearn.datasets</span><span class="w"> </span><span class="kn">import</span> <span class="n">load_iris</span>
<span class="c1"># 加载数据集</span>
<span class="n">data</span> <span class="o">=</span> <span class="n">load_iris</span><span class="p">()</span>
<span class="n">X</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">data</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">target</span>
<span class="c1"># 划分训练集和测试集</span>
<span class="n">X_train</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">y_test</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">test_size</span><span class="o">=</span><span class="mf">0.2</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">)</span>
<span class="c1"># 数据标准化</span>
<span class="n">scaler</span> <span class="o">=</span> <span class="n">StandardScaler</span><span class="p">()</span>
<span class="n">X_train</span> <span class="o">=</span> <span class="n">scaler</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">X_train</span><span class="p">)</span>
<span class="n">X_test</span> <span class="o">=</span> <span class="n">scaler</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>
<span class="c1"># 创建GBDT模型</span>
<span class="n">gbdt</span> <span class="o">=</span> <span class="n">GradientBoostingClassifier</span><span class="p">(</span><span class="n">n_estimators</span><span class="o">=</span><span class="mi">100</span><span class="p">)</span>  <span class="c1"># 使用100棵树</span>
<span class="c1"># 训练模型</span>
<span class="n">gbdt</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
<span class="c1"># 预测</span>
<span class="n">y_pred</span> <span class="o">=</span> <span class="n">gbdt</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>
<span class="c1"># 评估模型</span>
<span class="nb">print</span><span class="p">(</span><span class="n">confusion_matrix</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="n">classification_report</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">))</span>
</code></pre></div></p>
<h3 id="95-gbdt">9.5 GBDT模型调优<a class="headerlink" href="#95-gbdt" title="Permanent link">&para;</a></h3>
<p>GBDT模型的性能受树的数量和深度等参数的影响。可以通过交叉验证和网格搜索等方法调优树的数量、最大深度、最小样本分裂数等参数，以提高模型性能。
<div class="highlight"><pre><span></span><code><span class="kn">from</span><span class="w"> </span><span class="nn">sklearn.model_selection</span><span class="w"> </span><span class="kn">import</span> <span class="n">GridSearchCV</span>
<span class="c1"># 定义参数范围</span>
<span class="n">param_grid</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;n_estimators&#39;</span><span class="p">:</span> <span class="p">[</span><span class="mi">50</span><span class="p">,</span> <span class="mi">100</span><span class="p">,</span> <span class="mi">200</span><span class="p">],</span> <span class="s1">&#39;max_depth&#39;</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">10</span><span class="p">),</span> <span class="s1">&#39;min_samples_split&#39;</span><span class="p">:</span> <span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">10</span><span class="p">]}</span>
<span class="c1"># 创建GBDT模型</span>
<span class="n">gbdt</span> <span class="o">=</span> <span class="n">GradientBoostingClassifier</span><span class="p">()</span>
<span class="c1"># 使用网格搜索进行参数调优</span>
<span class="n">grid_search</span> <span class="o">=</span> <span class="n">GridSearchCV</span><span class="p">(</span><span class="n">gbdt</span><span class="p">,</span> <span class="n">param_grid</span><span class="p">,</span> <span class="n">cv</span><span class="o">=</span><span class="mi">5</span><span class="p">)</span>
<span class="n">grid_search</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
<span class="c1"># 输出最佳参数</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Best parameters:&quot;</span><span class="p">,</span> <span class="n">grid_search</span><span class="o">.</span><span class="n">best_params_</span><span class="p">)</span>
<span class="c1"># 使用最佳参数训练模型</span>
<span class="n">best_gbdt</span> <span class="o">=</span> <span class="n">grid_search</span><span class="o">.</span><span class="n">best_estimator_</span>
<span class="n">best_gbdt</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
<span class="c1"># 预测</span>
<span class="n">y_pred</span> <span class="o">=</span> <span class="n">best_gbdt</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>
<span class="c1"># 评估模型</span>
<span class="nb">print</span><span class="p">(</span><span class="n">confusion_matrix</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="n">classification_report</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">))</span>
</code></pre></div></p>
<h3 id="96-gbdt">9.6 GBDT模型扩展<a class="headerlink" href="#96-gbdt" title="Permanent link">&para;</a></h3>
<p>GBDT模型可以与其他技术结合使用，如XGBoost（极端梯度提升）、LightGBM（轻量级梯度提升）等，以提高算法的性能和适用性。 </p>
<h2 id="xgboost">十、XGBoost模型<a class="headerlink" href="#xgboost" title="Permanent link">&para;</a></h2>
<p>XGBoost（Extreme Gradient Boosting）是一种高效的梯度提升决策树（GBDT）实现，广泛应用于分类和回归任务。它通过优化计算效率和模型性能，成为许多机器学习竞赛中的首选算法。</p>
<h3 id="101-xgboost">10.1 XGBoost模型原理<a class="headerlink" href="#101-xgboost" title="Permanent link">&para;</a></h3>
<p>XGBoost基于GBDT的原理，通过以下步骤构建模型：</p>
<ol>
<li>初始化模型，通常使用常数值（如均值）作为初始预测值。</li>
<li>计算当前模型的残差（真实值与预测值之差）。</li>
<li>训练一棵决策树拟合残差，得到新的弱学习器。</li>
<li>将新弱学习器的预测结果加权累加到当前模型中。</li>
<li>重复步骤2-4，直到达到预定的树数量或其他停止条件。    </li>
</ol>
<h3 id="102-xgboost">10.2 XGBoost模型优缺点<a class="headerlink" href="#102-xgboost" title="Permanent link">&para;</a></h3>
<h4 id="_39">优点<a class="headerlink" href="#_39" title="Permanent link">&para;</a></h4>
<ul>
<li>高效的计算性能，适合大规模数据集</li>
<li>抗过拟合能力强，适合高维数据</li>
<li>能处理多分类问题</li>
<li>能处理缺失值和异常值</li>
<li>提供特征重要性评估</li>
<li>支持并行计算和分布式计算</li>
</ul>
<h4 id="_40">缺点<a class="headerlink" href="#_40" title="Permanent link">&para;</a></h4>
<ul>
<li>模型复杂，难以解释</li>
<li>训练时间较长，尤其是树的数量较多时</li>
<li>对于某些数据分布，可能不如单棵决策树表现  </li>
</ul>
<h3 id="103-xgboost">10.3 XGBoost模型应用场景<a class="headerlink" href="#103-xgboost" title="Permanent link">&para;</a></h3>
<p>XGBoost模型适用于以下场景：</p>
<ul>
<li>分类任务，如客户细分、信用评分等</li>
<li>回归任务，如房价预测、销售预测等</li>
<li>风险评估，如欺诈检测、信用风险评估等</li>
<li>医疗诊断，如疾病预测等</li>
<li>市场营销，如用户行为分析、客户流失预测等</li>
<li>图像分类，如手写数字识别、物体检测等</li>
<li>文本分类，如垃圾邮件检测、情感分析等</li>
</ul>
<h3 id="104-xgboost">10.4 XGBoost模型实现<a class="headerlink" href="#104-xgboost" title="Permanent link">&para;</a></h3>
<p>以下是使用Python和XGBoost库实现XGBoost模型的示例代码
<div class="highlight"><pre><span></span><code><span class="kn">import</span><span class="w"> </span><span class="nn">numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">np</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">sklearn.model_selection</span><span class="w"> </span><span class="kn">import</span> <span class="n">train_test_split</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">sklearn.preprocessing</span><span class="w"> </span><span class="kn">import</span> <span class="n">StandardScaler</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">xgboost</span><span class="w"> </span><span class="kn">import</span> <span class="n">XGBClassifier</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">sklearn.metrics</span><span class="w"> </span><span class="kn">import</span> <span class="n">classification_report</span><span class="p">,</span> <span class="n">confusion_matrix</span> 
<span class="kn">from</span><span class="w"> </span><span class="nn">sklearn.datasets</span><span class="w"> </span><span class="kn">import</span> <span class="n">load_iris</span>
<span class="c1"># 加载数据集</span>
<span class="n">data</span> <span class="o">=</span> <span class="n">load_iris</span><span class="p">()</span>
<span class="n">X</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">data</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">target</span>
<span class="c1"># 划分训练集和测试集</span>
<span class="n">X_train</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">y_test</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">test_size</span><span class="o">=</span><span class="mf">0.2</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">)</span>
<span class="c1"># 数据标准化</span>
<span class="n">scaler</span> <span class="o">=</span> <span class="n">StandardScaler</span><span class="p">()</span>
<span class="n">X_train</span> <span class="o">=</span> <span class="n">scaler</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">X_train</span><span class="p">)</span>
<span class="n">X_test</span> <span class="o">=</span> <span class="n">scaler</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>
<span class="c1"># 创建XGBoost模型</span>
<span class="n">xgb</span> <span class="o">=</span> <span class="n">XGBClassifier</span><span class="p">(</span><span class="n">n_estimators</span><span class="o">=</span><span class="mi">100</span><span class="p">)</span>  <span class="c1"># 使用100棵树</span>
<span class="c1"># 训练模型</span>
<span class="n">xgb</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
<span class="c1"># 预测</span>
<span class="n">y_pred</span> <span class="o">=</span> <span class="n">xgb</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>
<span class="c1"># 评估模型</span>
<span class="nb">print</span><span class="p">(</span><span class="n">confusion_matrix</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="n">classification_report</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">))</span>
</code></pre></div></p>
<h3 id="105-xgboost">10.5 XGBoost模型调优<a class="headerlink" href="#105-xgboost" title="Permanent link">&para;</a></h3>
<p>XGBoost模型的性能受树的数量和深度等参数的影响。可以通过交叉验证和网格搜索等方法调优树的数量、最大深度、最小样本分裂数等参数，以提高模型性能。
<div class="highlight"><pre><span></span><code><span class="kn">from</span><span class="w"> </span><span class="nn">sklearn.model_selection</span><span class="w"> </span><span class="kn">import</span> <span class="n">GridSearchCV</span>
<span class="c1"># 定义参数范围</span>
<span class="n">param_grid</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;n_estimators&#39;</span><span class="p">:</span> <span class="p">[</span><span class="mi">50</span><span class="p">,</span> <span class="mi">100</span><span class="p">,</span> <span class="mi">200</span><span class="p">],</span> <span class="s1">&#39;max_depth&#39;</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">10</span><span class="p">),</span> <span class="s1">&#39;learning_rate&#39;</span><span class="p">:</span> <span class="p">[</span><span class="mf">0.01</span><span class="p">,</span> <span class="mf">0.1</span><span class="p">,</span> <span class="mf">0.2</span><span class="p">],</span> <span class="s1">&#39;subsample&#39;</span><span class="p">:</span> <span class="p">[</span><span class="mf">0.6</span><span class="p">,</span> <span class="mf">0.8</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">]}</span>
<span class="c1"># 创建XGBoost模型</span>
<span class="n">xgb</span> <span class="o">=</span> <span class="n">XGBClassifier</span><span class="p">()</span>
<span class="c1"># 使用网格搜索进行参数调优</span>
<span class="n">grid_search</span> <span class="o">=</span> <span class="n">GridSearchCV</span><span class="p">(</span><span class="n">xgb</span><span class="p">,</span> <span class="n">param_grid</span><span class="p">,</span> <span class="n">cv</span><span class="o">=</span><span class="mi">5</span><span class="p">)</span>
<span class="n">grid_search</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
<span class="c1"># 输出最佳参数</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Best parameters:&quot;</span><span class="p">,</span> <span class="n">grid_search</span><span class="o">.</span><span class="n">best_params_</span><span class="p">)</span>
<span class="c1"># 使用最佳参数训练模型</span>
<span class="n">best_xgb</span> <span class="o">=</span> <span class="n">grid_search</span><span class="o">.</span><span class="n">best_estimator_</span>
<span class="n">best_xgb</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
<span class="c1"># 预测</span>
<span class="n">y_pred</span> <span class="o">=</span> <span class="n">best_xgb</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>
<span class="c1"># 评估模型</span>
<span class="nb">print</span><span class="p">(</span><span class="n">confusion_matrix</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="n">classification_report</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">))</span>
</code></pre></div></p>
<h3 id="106-xgboost">10.6 XGBoost模型扩展<a class="headerlink" href="#106-xgboost" title="Permanent link">&para;</a></h3>
<p>XGBoost模型可以与其他技术结合使用，如LightGBM（轻量级梯度提升）、CatBoost（处理类别特征）等，以提高算法的性能和适用性。    - <code>'minkowski'</code>：闵可夫斯基距离（默认值，</p>
<h2 id="lightgbm">十一、LightGBM模型<a class="headerlink" href="#lightgbm" title="Permanent link">&para;</a></h2>
<p>LightGBM（Light Gradient Boosting Machine）是一种高效的梯度提升决策树（GBDT）实现，广泛应用于分类和回归任务。它通过优化计算效率和模型性能，成为许多机器学习竞赛中的首选算法。</p>
<h3 id="111-lightgbm">11.1 LightGBM模型原理<a class="headerlink" href="#111-lightgbm" title="Permanent link">&para;</a></h3>
<p>LightGBM基于GBDT的原理，通过以下步骤构建模型：</p>
<ol>
<li>初始化模型，通常使用常数值（如均值）作为初始预测值。</li>
<li>计算当前模型的残差（真实值与预测值之差）。</li>
<li>训练一棵决策树拟合残差，得到新的弱学习器。</li>
<li>将新弱学习器的预测结果加权累加到当前模型中。</li>
<li>重复步骤2-4，直到达到预定的树数量或其他停止条件。</li>
</ol>
<h3 id="112-lightgbm">11.2 LightGBM模型优缺点<a class="headerlink" href="#112-lightgbm" title="Permanent link">&para;</a></h3>
<h4 id="_41">优点<a class="headerlink" href="#_41" title="Permanent link">&para;</a></h4>
<ul>
<li>高效的计算性能，适合大规模数据集</li>
<li>抗过拟合能力强，适合高维数据</li>
<li>能处理多分类问题</li>
<li>能处理缺失值和异常值</li>
<li>提供特征重要性评估</li>
<li>支持并行计算和分布式计算</li>
<li>采用基于直方图的决策树算法，减少内存使用</li>
<li>支持类别特征，减少预处理工作</li>
</ul>
<h4 id="_42">缺点<a class="headerlink" href="#_42" title="Permanent link">&para;</a></h4>
<ul>
<li>模型复杂，难以解释</li>
<li>训练时间较长，尤其是树的数量较多时</li>
<li>对于某些数据分布，可能不如单棵决策树表现  </li>
</ul>
<h3 id="113-lightgbm">11.3 LightGBM模型应用场景<a class="headerlink" href="#113-lightgbm" title="Permanent link">&para;</a></h3>
<p>LightGBM模型适用于以下场景：</p>
<ul>
<li>分类任务，如客户细分、信用评分等</li>
<li>回归任务，如房价预测、销售预测等</li>
<li>风险评估，如欺诈检测、信用风险评估等</li>
<li>医疗诊断，如疾病预测等</li>
<li>市场营销，如用户行为分析、客户流失预测等</li>
<li>图像分类，如手写数字识别、物体检测等</li>
<li>文本分类，如垃圾邮件检测、情感分析等</li>
</ul>
<h3 id="114-lightgbm">11.4 LightGBM模型实现<a class="headerlink" href="#114-lightgbm" title="Permanent link">&para;</a></h3>
<p>以下是使用Python和LightGBM库实现LightGBM模型的示例代码
<div class="highlight"><pre><span></span><code><span class="kn">import</span><span class="w"> </span><span class="nn">numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">np</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">sklearn.model_selection</span><span class="w"> </span><span class="kn">import</span> <span class="n">train_test_split</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">sklearn.preprocessing</span><span class="w"> </span><span class="kn">import</span> <span class="n">StandardScaler</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">lightgbm</span><span class="w"> </span><span class="kn">import</span> <span class="n">LGBMClassifier</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">sklearn.metrics</span><span class="w"> </span><span class="kn">import</span> <span class="n">classification_report</span><span class="p">,</span> <span class="n">confusion_matrix</span> 
<span class="kn">from</span><span class="w"> </span><span class="nn">sklearn.datasets</span><span class="w"> </span><span class="kn">import</span> <span class="n">load_iris</span>
<span class="c1"># 加载数据集</span>
<span class="n">data</span> <span class="o">=</span> <span class="n">load_iris</span><span class="p">()</span>
<span class="n">X</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">data</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">target</span>
<span class="c1"># 划分训练集和测试集</span>
<span class="n">X_train</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">y_test</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">test_size</span><span class="o">=</span><span class="mf">0.2</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">)</span>
<span class="c1"># 数据标准化</span>
<span class="n">scaler</span> <span class="o">=</span> <span class="n">StandardScaler</span><span class="p">()</span>
<span class="n">X_train</span> <span class="o">=</span> <span class="n">scaler</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">X_train</span><span class="p">)</span>
<span class="n">X_test</span> <span class="o">=</span> <span class="n">scaler</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>
<span class="c1"># 创建LightGBM模型</span>
<span class="n">lgbm</span> <span class="o">=</span> <span class="n">LGBMClassifier</span><span class="p">(</span><span class="n">n_estimators</span><span class="o">=</span><span class="mi">100</span><span class="p">)</span>  <span class="c1"># 使用100棵树</span>
<span class="c1"># 训练模型</span>
<span class="n">lgbm</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
<span class="c1"># 预测</span>
<span class="n">y_pred</span> <span class="o">=</span> <span class="n">lgbm</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>
<span class="c1"># 评估模型</span>
<span class="nb">print</span><span class="p">(</span><span class="n">confusion_matrix</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="n">classification_report</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">))</span>
</code></pre></div></p>
<h3 id="115-lightgbm">11.5 LightGBM模型调优<a class="headerlink" href="#115-lightgbm" title="Permanent link">&para;</a></h3>
<p>LightGBM模型的性能受树的数量和深度等参数的影响。可以通过交叉验证和网格搜索等方法调优树的数量、最大深度、最小样本分裂数等参数，以提高模型性能。
<div class="highlight"><pre><span></span><code><span class="kn">from</span><span class="w"> </span><span class="nn">sklearn.model_selection</span><span class="w"> </span><span class="kn">import</span> <span class="n">GridSearchCV</span>
<span class="c1"># 定义参数范围</span>
<span class="n">param_grid</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;n_estimators&#39;</span><span class="p">:</span> <span class="p">[</span><span class="mi">50</span><span class="p">,</span> <span class="mi">100</span><span class="p">,</span> <span class="mi">200</span><span class="p">],</span> <span class="s1">&#39;max_depth&#39;</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">10</span><span class="p">),</span> <span class="s1">&#39;learning_rate&#39;</span><span class="p">:</span> <span class="p">[</span><span class="mf">0.01</span><span class="p">,</span> <span class="mf">0.1</span><span class="p">,</span> <span class="mf">0.2</span><span class="p">],</span> <span class="s1">&#39;subsample&#39;</span><span class="p">:</span> <span class="p">[</span><span class="mf">0.6</span><span class="p">,</span> <span class="mf">0.8</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">]}</span>
<span class="c1"># 创建LightGBM模型</span>
<span class="n">lgbm</span> <span class="o">=</span> <span class="n">LGBMClassifier</span><span class="p">()</span>
<span class="c1"># 使用网格搜索进行参数调优</span>
<span class="n">grid_search</span> <span class="o">=</span> <span class="n">GridSearchCV</span><span class="p">(</span><span class="n">lgbm</span><span class="p">,</span> <span class="n">param_grid</span><span class="p">,</span> <span class="n">cv</span><span class="o">=</span><span class="mi">5</span><span class="p">)</span>
<span class="n">grid_search</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
<span class="c1"># 输出最佳参数</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Best parameters:&quot;</span><span class="p">,</span> <span class="n">grid_search</span><span class="o">.</span><span class="n">best_params_</span><span class="p">)</span>
<span class="c1"># 使用最佳参数训练模型</span>
<span class="n">best_lgbm</span> <span class="o">=</span> <span class="n">grid_search</span><span class="o">.</span><span class="n">best_estimator_</span>
<span class="n">best_lgbm</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
<span class="c1"># 预测</span>
<span class="n">y_pred</span> <span class="o">=</span> <span class="n">best_lgbm</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>
<span class="c1"># 评估模型</span>
<span class="nb">print</span><span class="p">(</span><span class="n">confusion_matrix</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="n">classification_report</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">))</span>
</code></pre></div></p>
<h3 id="116-lightgbm">11.6 LightGBM模型扩展<a class="headerlink" href="#116-lightgbm" title="Permanent link">&para;</a></h3>
<p>LightGBM模型可以与其他技术结合使用，如XGBoost（极端梯度提升）、CatBoost（处理类别特征）等，以提高算法的性能和适用性。    其计算公式为：(d(p, q) = \left( \sum_{i=1}^{n} |p_i - q_i|^r \right)^{1</p>
<h2 id="_43">十二、支持向量机模型<a class="headerlink" href="#_43" title="Permanent link">&para;</a></h2>
<p>支持向量机（Support Vector Machine, SVM）是一种强大的监督学习算法，广泛应用于分类和回归任务。其核心思想是通过寻找最优超平面，将不同类别的数据点分开，从而实现分类。</p>
<h3 id="121">12.1 支持向量机模型原理<a class="headerlink" href="#121" title="Permanent link">&para;</a></h3>
<p>支持向量机通过以下步骤构建模型：</p>
<ol>
<li>选择一个合适的核函数，将数据映射到高维空间，以便在该空间中找到线性可分的超平面。</li>
<li>通过最大化类别间的间隔（Margin），找到最优超平面。</li>
<li>使用支持向量（距离超平面最近的样本点）来确定超平面的位置。</li>
<li>对于非线性可分的数据，使用软间隔（Soft Margin）技术，允许部分样本点位于错误的一侧。  </li>
</ol>
<h3 id="122">12.2 支持向量机模型优缺点<a class="headerlink" href="#122" title="Permanent link">&para;</a></h3>
<h4 id="_44">优点<a class="headerlink" href="#_44" title="Permanent link">&para;</a></h4>
<ul>
<li>在高维空间中表现良好，适合复杂数据</li>
<li>能处理非线性分类问题</li>
<li>对小样本数据表现良好</li>
<li>具有较强的泛化能力</li>
</ul>
<h4 id="_45">缺点<a class="headerlink" href="#_45" title="Permanent link">&para;</a></h4>
<ul>
<li>计算复杂度高，训练时间较长</li>
<li>对参数选择和核函数敏感</li>
<li>对噪声和异常值敏感</li>
<li>不能直接处理多分类问题，需使用一对多或一对一策略</li>
</ul>
<h3 id="123">12.3 支持向量机模型应用场景<a class="headerlink" href="#123" title="Permanent link">&para;</a></h3>
<p>支持向量机模型适用于以下场景：</p>
<ul>
<li>分类任务，如文本分类、图像识别等</li>
<li>回归任务，如房价预测、股票价格预测等</li>
<li>风险评估，如信用风险评估等</li>
<li>医疗诊断，如疾病预测等</li>
<li>市场营销，如用户行为分析、客户流失预测等</li>
<li>生物信息学，如基因表达数据分析等</li>
</ul>
<h3 id="124">12.4 支持向量机模型实现<a class="headerlink" href="#124" title="Permanent link">&para;</a></h3>
<p>以下是使用Python和Scikit-learn库实现支持向量机模型的示例代码
<div class="highlight"><pre><span></span><code><span class="kn">import</span><span class="w"> </span><span class="nn">numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">np</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">sklearn.model_selection</span><span class="w"> </span><span class="kn">import</span> <span class="n">train_test_split</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">sklearn.preprocessing</span><span class="w"> </span><span class="kn">import</span> <span class="n">StandardScaler</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">sklearn.svm</span><span class="w"> </span><span class="kn">import</span> <span class="n">SVC</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">sklearn.metrics</span><span class="w"> </span><span class="kn">import</span> <span class="n">classification_report</span><span class="p">,</span> <span class="n">confusion_matrix</span> 
<span class="kn">from</span><span class="w"> </span><span class="nn">sklearn.datasets</span><span class="w"> </span><span class="kn">import</span> <span class="n">load_iris</span>
<span class="c1"># 加载数据集</span>
<span class="n">data</span> <span class="o">=</span> <span class="n">load_iris</span><span class="p">()</span>
<span class="n">X</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">data</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">target</span>
<span class="c1"># 划分训练集和测试集</span>
<span class="n">X_train</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">y_test</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">test_size</span><span class="o">=</span><span class="mf">0.2</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">)</span>
<span class="c1"># 数据标准化</span>
<span class="n">scaler</span> <span class="o">=</span> <span class="n">StandardScaler</span><span class="p">()</span>
<span class="n">X_train</span> <span class="o">=</span> <span class="n">scaler</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">X_train</span><span class="p">)</span>
<span class="n">X_test</span> <span class="o">=</span> <span class="n">scaler</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>
<span class="c1"># 创建支持向量机模型</span>
<span class="n">svm</span> <span class="o">=</span> <span class="n">SVC</span><span class="p">(</span><span class="n">kernel</span><span class="o">=</span><span class="s1">&#39;rbf&#39;</span><span class="p">)</span>  <span class="c1"># 使用径向基函数（RBF）核</span>
<span class="c1"># 训练模型</span>
<span class="n">svm</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
<span class="c1"># 预测</span>
<span class="n">y_pred</span> <span class="o">=</span> <span class="n">svm</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>
<span class="c1"># 评估模型</span>
<span class="nb">print</span><span class="p">(</span><span class="n">confusion_matrix</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="n">classification_report</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">))</span>
</code></pre></div></p>
<h3 id="125">12.5 支持向量机模型调优<a class="headerlink" href="#125" title="Permanent link">&para;</a></h3>
<p>支持向量机模型的性能受核函数和参数选择的影响。可以通过交叉验证和网格搜索等方法调优核函数类型、正则化参数C和核函数参数gamma等，以提高模型性能。
<div class="highlight"><pre><span></span><code><span class="kn">from</span><span class="w"> </span><span class="nn">sklearn.model_selection</span><span class="w"> </span><span class="kn">import</span> <span class="n">GridSearchCV</span>
<span class="c1"># 定义参数范围</span>
<span class="n">param_grid</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;C&#39;</span><span class="p">:</span> <span class="p">[</span><span class="mf">0.1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">10</span><span class="p">],</span> <span class="s1">&#39;gamma&#39;</span><span class="p">:</span> <span class="p">[</span><span class="mf">0.01</span><span class="p">,</span> <span class="mf">0.1</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="s1">&#39;kernel&#39;</span><span class="p">:</span> <span class="p">[</span><span class="s1">&#39;linear&#39;</span><span class="p">,</span> <span class="s1">&#39;rbf&#39;</span><span class="p">,</span> <span class="s1">&#39;poly&#39;</span><span class="p">]}</span>
<span class="c1"># 创建支持向量机模型</span>
<span class="n">svm</span> <span class="o">=</span> <span class="n">SVC</span><span class="p">()</span>
<span class="c1"># 使用网格搜索进行参数调优</span>
<span class="n">grid_search</span> <span class="o">=</span> <span class="n">GridSearchCV</span><span class="p">(</span><span class="n">svm</span><span class="p">,</span> <span class="n">param_grid</span><span class="p">,</span> <span class="n">cv</span><span class="o">=</span><span class="mi">5</span><span class="p">)</span>
<span class="n">grid_search</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
<span class="c1"># 输出最佳参数</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Best parameters:&quot;</span><span class="p">,</span> <span class="n">grid_search</span><span class="o">.</span><span class="n">best_params_</span><span class="p">)</span>
<span class="c1"># 使用最佳参数训练模型</span>
<span class="n">best_svm</span> <span class="o">=</span> <span class="n">grid_search</span><span class="o">.</span><span class="n">best_estimator_</span>
<span class="n">best_svm</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
<span class="c1"># 预测</span>
<span class="n">y_pred</span> <span class="o">=</span> <span class="n">best_svm</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>
<span class="c1"># 评估模型</span>
<span class="nb">print</span><span class="p">(</span><span class="n">confusion_matrix</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="n">classification_report</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">))</span>
</code></pre></div></p>
<h3 id="126">12.6 支持向量机模型扩展<a class="headerlink" href="#126" title="Permanent link">&para;</a></h3>
<p>支持向量机模型可以与其他技术结合使用，如核方法（如多项式核、径向基函数核等）、集成学习（如Bagging、Boosting等）等，以提高算法的性能和适用性。</p>
<h2 id="_46">十三、聚类算法<a class="headerlink" href="#_46" title="Permanent link">&para;</a></h2>
<p>聚类（Clustering）是一种无监督学习方法，用于将数据集划分为若干个簇，使得同一簇内的数据点相似度较高，而不同簇之间的数据点相似度较低。常见的聚类算法包括K均值（K-Means）、层次聚类（Hierarchical Clustering）和DBSCAN等。</p>
<h3 id="131">13.1 聚类算法原理<a class="headerlink" href="#131" title="Permanent link">&para;</a></h3>
<ul>
<li>K均值算法通过迭代优化簇中心位置，将数据点分配到最近的簇中心，直到簇中心不再变化。</li>
<li>层次聚类通过构建树形结构（树状图）来表示数据点之间的层次关系，可以是自底向上（凝聚型）或自顶向下（分裂型）。</li>
<li>DBSCAN通过密度连接的方式识别簇，能够发现任意形状的簇，并能处理噪声点。</li>
</ul>
<h3 id="132">13.2 聚类算法优缺点<a class="headerlink" href="#132" title="Permanent link">&para;</a></h3>
<h4 id="_47">优点<a class="headerlink" href="#_47" title="Permanent link">&para;</a></h4>
<ul>
<li>能发现数据中的潜在结构和模式</li>
<li>不需要预先标注数据，适用于无监督学习</li>
<li>适用于大规模数据集</li>
</ul>
<h4 id="_48">缺点<a class="headerlink" href="#_48" title="Permanent link">&para;</a></h4>
<ul>
<li>聚类结果受初始参数和算法选择影响较大</li>
<li>可能难以解释聚类结果</li>
<li>对噪声和异常值敏感</li>
<li>需要预先指定簇的数量（如K均值）   </li>
</ul>
<h3 id="133">13.3 聚类算法应用场景<a class="headerlink" href="#133" title="Permanent link">&para;</a></h3>
<p>聚类算法适用于以下场景：
- 客户细分，如市场营销中的客户分类
- 图像分割，如医学图像处理中的组织分割
- 文本挖掘，如文档分类和主题发现
- 异常检测，如网络安全中的入侵检测
- 社交网络分析，如社区发现
- 生物信息学，如基因表达数据分析    </p>
<h3 id="134">13.4 聚类算法实现<a class="headerlink" href="#134" title="Permanent link">&para;</a></h3>
<p>以下是使用Python和Scikit-learn库实现K均值聚类算法的示例代码
<div class="highlight"><pre><span></span><code><span class="kn">import</span><span class="w"> </span><span class="nn">numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">np</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">sklearn.cluster</span><span class="w"> </span><span class="kn">import</span> <span class="n">KMeans</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">sklearn.datasets</span><span class="w"> </span><span class="kn">import</span> <span class="n">load_iris</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">matplotlib.pyplot</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">plt</span>
<span class="c1"># 加载数据集</span>
<span class="n">data</span> <span class="o">=</span> <span class="n">load_iris</span><span class="p">()</span>
<span class="n">X</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">data</span>
<span class="c1"># 创建K均值模型</span>
<span class="n">kmeans</span> <span class="o">=</span> <span class="n">KMeans</span><span class="p">(</span><span class="n">n_clusters</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">)</span>
<span class="c1"># 训练模型</span>
<span class="n">kmeans</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
<span class="c1"># 预测簇标签</span>
<span class="n">y_kmeans</span> <span class="o">=</span> <span class="n">kmeans</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
<span class="c1"># 可视化聚类结果</span>
<span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">X</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">X</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">c</span><span class="o">=</span><span class="n">y_kmeans</span><span class="p">,</span> <span class="n">s</span><span class="o">=</span><span class="mi">50</span><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="s1">&#39;viridis&#39;</span><span class="p">)</span>
<span class="n">centers</span> <span class="o">=</span> <span class="n">kmeans</span><span class="o">.</span><span class="n">cluster_centers_</span>
<span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">centers</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">centers</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">c</span><span class="o">=</span><span class="s1">&#39;red&#39;</span><span class="p">,</span> <span class="n">s</span><span class="o">=</span><span class="mi">200</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.75</span><span class="p">,</span> <span class="n">marker</span><span class="o">=</span><span class="s1">&#39;X&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;Feature 1&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;Feature 2&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39;K-Means Clustering&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</code></pre></div></p>
<h3 id="135">13.5 聚类算法调优<a class="headerlink" href="#135" title="Permanent link">&para;</a></h3>
<p>聚类算法的性能受初始参数和算法选择的影响。可以通过调整簇的数量（如K均值中的K值）、距离度量方式（如欧氏距离、曼哈顿距离等）和算法参数（如DBSCAN中的eps和min_samples）等，以提高聚类效果。
<div class="highlight"><pre><span></span><code><span class="kn">from</span><span class="w"> </span><span class="nn">sklearn.metrics</span><span class="w"> </span><span class="kn">import</span> <span class="n">silhouette_score</span>
<span class="c1"># 计算轮廓系数评估聚类效果</span>
<span class="n">silhouette_avg</span> <span class="o">=</span> <span class="n">silhouette_score</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y_kmeans</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Silhouette Score:&quot;</span><span class="p">,</span> <span class="n">silhouette_avg</span><span class="p">)</span>
</code></pre></div></p>
<h3 id="136">13.6 聚类算法扩展<a class="headerlink" href="#136" title="Permanent link">&para;</a></h3>
<p>聚类算法可以与其他技术结合使用，如降维（如PCA、t-SNE等）以提高聚类效果，或与分类算法结合进行半监督学习等。</p>
<h2 id="_49">十四、降维算法<a class="headerlink" href="#_49" title="Permanent link">&para;</a></h2>
<p>降维（Dimensionality Reduction）是一种数据预处理技术，用于减少数据集的特征数量，同时尽可能保留数据的主要信息。常见的降维算法包括主成分分析（PCA）、线性判别分析（LDA）和t-SNE等。</p>
<h3 id="141">14.1 降维算法原理<a class="headerlink" href="#141" title="Permanent link">&para;</a></h3>
<ul>
<li>主成分分析（PCA）通过线性变换将数据投影到新的坐标系中，使得投影后的数据方差最大化，从而实现降维。</li>
<li>线性判别分析（LDA）通过寻找能够最大化类间距离和最小化类内距离的投影方向，实现降维和分类。</li>
<li>t-SNE通过非线性映射将高维数据嵌入到低维空间，保留数据的局部结构，适用于可视化高维数据。</li>
</ul>
<h3 id="142">14.2 降维算法优缺点<a class="headerlink" href="#142" title="Permanent link">&para;</a></h3>
<h4 id="_50">优点<a class="headerlink" href="#_50" title="Permanent link">&para;</a></h4>
<ul>
<li>减少数据维度，降低计算复杂度</li>
<li>去除冗余和噪声，提高模型性能</li>
<li>便于数据可视化和解释</li>
</ul>
<h4 id="_51">缺点<a class="headerlink" href="#_51" title="Permanent link">&para;</a></h4>
<ul>
<li>可能丢失部分信息，影响模型性能</li>
<li>需要选择合适的降维方法和参数</li>
<li>对数据分布和结构敏感，可能不适用于所有数据集</li>
</ul>
<h3 id="143">14.3 降维算法应用场景<a class="headerlink" href="#143" title="Permanent link">&para;</a></h3>
<p>降维算法适用于以下场景：
- 数据预处理，如特征选择和特征提取
- 数据可视化，如高维数据的二维或三维展示
- 噪声过滤，如去除数据中的冗余信息
- 提高模型性能，如减少过拟合风险
- 图像处理，如图像压缩和特征提取
- 自然语言处理，如文本表示和主题建模</p>
<h3 id="144">14.4 降维算法实现<a class="headerlink" href="#144" title="Permanent link">&para;</a></h3>
<p>以下是使用Python和Scikit-learn库实现主成分分析（PCA）的示例代码
<div class="highlight"><pre><span></span><code><span class="kn">import</span><span class="w"> </span><span class="nn">numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">np</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">sklearn.model_selection</span><span class="w"> </span><span class="kn">import</span> <span class="n">train_test_split</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">sklearn.preprocessing</span><span class="w"> </span><span class="kn">import</span> <span class="n">StandardScaler</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">sklearn.decomposition</span><span class="w"> </span><span class="kn">import</span> <span class="n">PCA</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">sklearn.datasets</span><span class="w"> </span><span class="kn">import</span> <span class="n">load_iris</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">matplotlib.pyplot</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">plt</span>
<span class="c1"># 加载数据集</span>
<span class="n">data</span> <span class="o">=</span> <span class="n">load_iris</span><span class="p">()</span>
<span class="n">X</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">data</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">target</span>
<span class="c1"># 划分训练集和测试集</span>
<span class="n">X_train</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">y_test</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">test_size</span><span class="o">=</span><span class="mf">0.2</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">)</span>
<span class="c1"># 数据标准化</span>
<span class="n">scaler</span> <span class="o">=</span> <span class="n">StandardScaler</span><span class="p">()</span>
<span class="n">X_train</span> <span class="o">=</span> <span class="n">scaler</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">X_train</span><span class="p">)</span>
<span class="n">X_test</span> <span class="o">=</span> <span class="n">scaler</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>
<span class="c1"># 创建PCA模型，降至2维</span>
<span class="n">pca</span> <span class="o">=</span> <span class="n">PCA</span><span class="p">(</span><span class="n">n_components</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
<span class="c1"># 训练模型</span>
<span class="n">X_train_pca</span> <span class="o">=</span> <span class="n">pca</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">X_train</span><span class="p">)</span>
<span class="n">X_test_pca</span> <span class="o">=</span> <span class="n">pca</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>
<span class="c1"># 可视化降维结果</span>
<span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">X_train_pca</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">X_train_pca</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">c</span><span class="o">=</span><span class="n">y_train</span><span class="p">,</span> <span class="n">s</span><span class="o">=</span><span class="mi">50</span><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="s1">&#39;viridis&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;Principal Component 1&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;Principal Component 2&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39;PCA Result&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</code></pre></div></p>
<h3 id="145">14.5 降维算法调优<a class="headerlink" href="#145" title="Permanent link">&para;</a></h3>
<p>降维算法的性能受方法选择和参数设置的影响。可以通过调整降维后的维度数量、选择不同的降维方法（如PCA、LDA、t-SNE等）和参数（如t-SNE中的perplexity和learning_rate）等，以提高降维效果。
<div class="highlight"><pre><span></span><code><span class="c1"># 输出PCA解释的方差比例</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Explained variance ratio:&quot;</span><span class="p">,</span> <span class="n">pca</span><span class="o">.</span><span class="n">explained_variance_ratio_</span><span class="p">)</span>
</code></pre></div></p>
<h3 id="146">14.6 降维算法扩展<a class="headerlink" href="#146" title="Permanent link">&para;</a></h3>
<p>降维算法可以与其他技术结合使用，如聚类（如K均值、DBSCAN等）以提高聚类效果，或与分类算法结合进行特征选择等。</p>












                
              </article>
            </div>
          
          
  <script>var tabs=__md_get("__tabs");if(Array.isArray(tabs))e:for(var set of document.querySelectorAll(".tabbed-set")){var labels=set.querySelector(".tabbed-labels");for(var tab of tabs)for(var label of labels.getElementsByTagName("label"))if(label.innerText.trim()===tab){var input=document.getElementById(label.htmlFor);input.checked=!0;continue e}}</script>

<script>var target=document.getElementById(location.hash.slice(1));target&&target.name&&(target.checked=target.name.startsWith("__tabbed_"))</script>
        </div>
        
      </main>
      
        <footer class="md-footer">
  
  <div class="md-footer-meta md-typeset">
    <div class="md-footer-meta__inner md-grid">
      <div class="md-copyright">
  
  
    Made with
    <a href="https://squidfunk.github.io/mkdocs-material/" target="_blank" rel="noopener">
      Material for MkDocs
    </a>
  
</div>
      
    </div>
  </div>
</footer>
      
    </div>
    <div class="md-dialog" data-md-component="dialog">
      <div class="md-dialog__inner md-typeset"></div>
    </div>
    
    
    
      
      <script id="__config" type="application/json">{"base": "../..", "features": ["navigation.section", "navigation.expand", "navigation.tabs", "navigation.sections", "navigation.indexes", "content.code.copy", "content.tabs.link", "content.code.annotate", "math"], "search": "../../assets/javascripts/workers/search.d50fe291.min.js", "tags": null, "translations": {"clipboard.copied": "\u5df2\u590d\u5236", "clipboard.copy": "\u590d\u5236", "search.result.more.one": "\u5728\u8be5\u9875\u4e0a\u8fd8\u6709 1 \u4e2a\u7b26\u5408\u6761\u4ef6\u7684\u7ed3\u679c", "search.result.more.other": "\u5728\u8be5\u9875\u4e0a\u8fd8\u6709 # \u4e2a\u7b26\u5408\u6761\u4ef6\u7684\u7ed3\u679c", "search.result.none": "\u6ca1\u6709\u627e\u5230\u7b26\u5408\u6761\u4ef6\u7684\u7ed3\u679c", "search.result.one": "\u627e\u5230 1 \u4e2a\u7b26\u5408\u6761\u4ef6\u7684\u7ed3\u679c", "search.result.other": "# \u4e2a\u7b26\u5408\u6761\u4ef6\u7684\u7ed3\u679c", "search.result.placeholder": "\u952e\u5165\u4ee5\u5f00\u59cb\u641c\u7d22", "search.result.term.missing": "\u7f3a\u5c11", "select.version": "\u9009\u62e9\u5f53\u524d\u7248\u672c"}, "version": null}</script>
    
    
      <script src="../../assets/javascripts/bundle.50899def.min.js"></script>
      
        <script src="../../styles/javascripts/config.js"></script>
      
        <script src="https://cdn.jsdelivr.net/npm/katex@0.16.4/dist/katex.min.js"></script>
      
        <script src="https://cdn.jsdelivr.net/npm/katex@0.16.4/dist/contrib/auto-render.min.js"></script>
      
        <script src="../../styles/javascripts/katex.js"></script>
      
    
  </body>
</html>