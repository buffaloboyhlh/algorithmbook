
<!doctype html>
<html lang="zh" class="no-js">
  <head>
    
      <meta charset="utf-8">
      <meta name="viewport" content="width=device-width,initial-scale=1">
      
      
        <meta name="author" content="Buffalo">
      
      
        <link rel="canonical" href="https://github.com/buffaloboyhlh/algorithmbook/machine/tutorial/">
      
      
        <link rel="prev" href="../math/">
      
      
        <link rel="next" href="../interview/">
      
      
      <link rel="icon" href="../../assets/images/favicon.png">
      <meta name="generator" content="mkdocs-1.6.1, mkdocs-material-9.6.20">
    
    
      
        <title>机器学习教程 - 算法面试大集</title>
      
    
    
      <link rel="stylesheet" href="../../assets/stylesheets/main.e53b48f4.min.css">
      
        
        <link rel="stylesheet" href="../../assets/stylesheets/palette.06af60db.min.css">
      
      


    
    
      
    
    
      
        
        
        <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
        <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Roboto:300,300i,400,400i,700,700i%7CRoboto+Mono:400,400i,700,700i&display=fallback">
        <style>:root{--md-text-font:"Roboto";--md-code-font:"Roboto Mono"}</style>
      
    
    
      <link rel="stylesheet" href="../../styles/extra.css">
    
      <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.4/dist/katex.min.css">
    
    <script>__md_scope=new URL("../..",location),__md_hash=e=>[...e].reduce(((e,_)=>(e<<5)-e+_.charCodeAt(0)),0),__md_get=(e,_=localStorage,t=__md_scope)=>JSON.parse(_.getItem(t.pathname+"."+e)),__md_set=(e,_,t=localStorage,a=__md_scope)=>{try{t.setItem(a.pathname+"."+e,JSON.stringify(_))}catch(e){}}</script>
    
      

    
    
    
  </head>
  
  
    
    
      
    
    
    
    
    <body dir="ltr" data-md-color-scheme="default" data-md-color-primary="teal" data-md-color-accent="amber">
  
    
    <input class="md-toggle" data-md-toggle="drawer" type="checkbox" id="__drawer" autocomplete="off">
    <input class="md-toggle" data-md-toggle="search" type="checkbox" id="__search" autocomplete="off">
    <label class="md-overlay" for="__drawer"></label>
    <div data-md-component="skip">
      
        
        <a href="#_2" class="md-skip">
          跳转至
        </a>
      
    </div>
    <div data-md-component="announce">
      
    </div>
    
    
      

<header class="md-header" data-md-component="header">
  <nav class="md-header__inner md-grid" aria-label="页眉">
    <a href="../.." title="算法面试大集" class="md-header__button md-logo" aria-label="算法面试大集" data-md-component="logo">
      
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 8a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3 3 3 0 0 0 3 3m0 3.54C9.64 9.35 6.5 8 3 8v11c3.5 0 6.64 1.35 9 3.54 2.36-2.19 5.5-3.54 9-3.54V8c-3.5 0-6.64 1.35-9 3.54"/></svg>

    </a>
    <label class="md-header__button md-icon" for="__drawer">
      
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M3 6h18v2H3zm0 5h18v2H3zm0 5h18v2H3z"/></svg>
    </label>
    <div class="md-header__title" data-md-component="header-title">
      <div class="md-header__ellipsis">
        <div class="md-header__topic">
          <span class="md-ellipsis">
            算法面试大集
          </span>
        </div>
        <div class="md-header__topic" data-md-component="header-topic">
          <span class="md-ellipsis">
            
              机器学习教程
            
          </span>
        </div>
      </div>
    </div>
    
      
        <form class="md-header__option" data-md-component="palette">
  
    
    
    
    <input class="md-option" data-md-color-media="(prefers-color-scheme: light)" data-md-color-scheme="default" data-md-color-primary="teal" data-md-color-accent="amber"  aria-label="切换至夜间模式"  type="radio" name="__palette" id="__palette_0">
    
      <label class="md-header__button md-icon" title="切换至夜间模式" for="__palette_1" hidden>
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 8a4 4 0 0 0-4 4 4 4 0 0 0 4 4 4 4 0 0 0 4-4 4 4 0 0 0-4-4m0 10a6 6 0 0 1-6-6 6 6 0 0 1 6-6 6 6 0 0 1 6 6 6 6 0 0 1-6 6m8-9.31V4h-4.69L12 .69 8.69 4H4v4.69L.69 12 4 15.31V20h4.69L12 23.31 15.31 20H20v-4.69L23.31 12z"/></svg>
      </label>
    
  
    
    
    
    <input class="md-option" data-md-color-media="(prefers-color-scheme: dark)" data-md-color-scheme="slate" data-md-color-primary="black" data-md-color-accent="indigo"  aria-label="切换至日间模式"  type="radio" name="__palette" id="__palette_1">
    
      <label class="md-header__button md-icon" title="切换至日间模式" for="__palette_0" hidden>
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 18c-.89 0-1.74-.2-2.5-.55C11.56 16.5 13 14.42 13 12s-1.44-4.5-3.5-5.45C10.26 6.2 11.11 6 12 6a6 6 0 0 1 6 6 6 6 0 0 1-6 6m8-9.31V4h-4.69L12 .69 8.69 4H4v4.69L.69 12 4 15.31V20h4.69L12 23.31 15.31 20H20v-4.69L23.31 12z"/></svg>
      </label>
    
  
</form>
      
    
    
      <script>var palette=__md_get("__palette");if(palette&&palette.color){if("(prefers-color-scheme)"===palette.color.media){var media=matchMedia("(prefers-color-scheme: light)"),input=document.querySelector(media.matches?"[data-md-color-media='(prefers-color-scheme: light)']":"[data-md-color-media='(prefers-color-scheme: dark)']");palette.color.media=input.getAttribute("data-md-color-media"),palette.color.scheme=input.getAttribute("data-md-color-scheme"),palette.color.primary=input.getAttribute("data-md-color-primary"),palette.color.accent=input.getAttribute("data-md-color-accent")}for(var[key,value]of Object.entries(palette.color))document.body.setAttribute("data-md-color-"+key,value)}</script>
    
    
    
      
      
        <label class="md-header__button md-icon" for="__search">
          
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"/></svg>
        </label>
        <div class="md-search" data-md-component="search" role="dialog">
  <label class="md-search__overlay" for="__search"></label>
  <div class="md-search__inner" role="search">
    <form class="md-search__form" name="search">
      <input type="text" class="md-search__input" name="query" aria-label="搜索" placeholder="搜索" autocapitalize="off" autocorrect="off" autocomplete="off" spellcheck="false" data-md-component="search-query" required>
      <label class="md-search__icon md-icon" for="__search">
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"/></svg>
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11z"/></svg>
      </label>
      <nav class="md-search__options" aria-label="查找">
        
        <button type="reset" class="md-search__icon md-icon" title="清空当前内容" aria-label="清空当前内容" tabindex="-1">
          
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M19 6.41 17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12z"/></svg>
        </button>
      </nav>
      
    </form>
    <div class="md-search__output">
      <div class="md-search__scrollwrap" tabindex="0" data-md-scrollfix>
        <div class="md-search-result" data-md-component="search-result">
          <div class="md-search-result__meta">
            正在初始化搜索引擎
          </div>
          <ol class="md-search-result__list" role="presentation"></ol>
        </div>
      </div>
    </div>
  </div>
</div>
      
    
    
  </nav>
  
</header>
    
    <div class="md-container" data-md-component="container">
      
      
        
          
            
<nav class="md-tabs" aria-label="标签" data-md-component="tabs">
  <div class="md-grid">
    <ul class="md-tabs__list">
      
        
  
  
  
  
    
    
      <li class="md-tabs__item">
        <a href="../../math/probability/" class="md-tabs__link">
          
  
  
    
  
  数学

        </a>
      </li>
    
  

      
        
  
  
  
    
  
  
    
    
      <li class="md-tabs__item md-tabs__item--active">
        <a href="../math/" class="md-tabs__link">
          
  
  
    
  
  机器学习

        </a>
      </li>
    
  

      
        
  
  
  
  
    
    
      <li class="md-tabs__item">
        <a href="../../deeplearning/math/" class="md-tabs__link">
          
  
  
    
  
  深度学习

        </a>
      </li>
    
  

      
        
  
  
  
  
    
    
      <li class="md-tabs__item">
        <a href="../../reinforcement/math/" class="md-tabs__link">
          
  
  
    
  
  强化学习

        </a>
      </li>
    
  

      
    </ul>
  </div>
</nav>
          
        
      
      <main class="md-main" data-md-component="main">
        <div class="md-main__inner md-grid">
          
            
              
              <div class="md-sidebar md-sidebar--primary" data-md-component="sidebar" data-md-type="navigation" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    


  


<nav class="md-nav md-nav--primary md-nav--lifted" aria-label="导航栏" data-md-level="0">
  <label class="md-nav__title" for="__drawer">
    <a href="../.." title="算法面试大集" class="md-nav__button md-logo" aria-label="算法面试大集" data-md-component="logo">
      
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 8a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3 3 3 0 0 0 3 3m0 3.54C9.64 9.35 6.5 8 3 8v11c3.5 0 6.64 1.35 9 3.54 2.36-2.19 5.5-3.54 9-3.54V8c-3.5 0-6.64 1.35-9 3.54"/></svg>

    </a>
    算法面试大集
  </label>
  
  <ul class="md-nav__list" data-md-scrollfix>
    
      
      
  
  
  
  
    
    
      
        
      
        
      
        
      
    
    
    
      
      
        
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
          
        
        <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type="checkbox" id="__nav_1" >
        
          
          <label class="md-nav__link" for="__nav_1" id="__nav_1_label" tabindex="0">
            
  
  
  <span class="md-ellipsis">
    数学
    
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_1_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_1">
            <span class="md-nav__icon md-icon"></span>
            数学
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../math/probability/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    概率统计
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../math/linear/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    线性代数
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../math/calculus/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    微积分与优化
    
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
    
  
  
  
    
    
      
        
      
        
      
        
      
    
    
    
      
        
        
      
      
        
      
    
    
    <li class="md-nav__item md-nav__item--active md-nav__item--section md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_2" checked>
        
          
          <label class="md-nav__link" for="__nav_2" id="__nav_2_label" tabindex="">
            
  
  
  <span class="md-ellipsis">
    机器学习
    
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_2_label" aria-expanded="true">
          <label class="md-nav__title" for="__nav_2">
            <span class="md-nav__icon md-icon"></span>
            机器学习
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../math/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    机器学习中的数学
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
    
  
  
  
    <li class="md-nav__item md-nav__item--active">
      
      <input class="md-nav__toggle md-toggle" type="checkbox" id="__toc">
      
      
      
        <label class="md-nav__link md-nav__link--active" for="__toc">
          
  
  
  <span class="md-ellipsis">
    机器学习教程
    
  </span>
  

          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <a href="./" class="md-nav__link md-nav__link--active">
        
  
  
  <span class="md-ellipsis">
    机器学习教程
    
  </span>
  

      </a>
      
        

<nav class="md-nav md-nav--secondary" aria-label="目录">
  
  
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      目录
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#_2" class="md-nav__link">
    <span class="md-ellipsis">
      一、机器学习基础知识
    </span>
  </a>
  
    <nav class="md-nav" aria-label="一、机器学习基础知识">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#11" class="md-nav__link">
    <span class="md-ellipsis">
      1.1 什么是机器学习
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#12" class="md-nav__link">
    <span class="md-ellipsis">
      1.2 机器学习的类型
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#13" class="md-nav__link">
    <span class="md-ellipsis">
      1.3 机器学习的基本流程
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#_3" class="md-nav__link">
    <span class="md-ellipsis">
      二、模型评估方法与准则
    </span>
  </a>
  
    <nav class="md-nav" aria-label="二、模型评估方法与准则">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#21" class="md-nav__link">
    <span class="md-ellipsis">
      2.1 评估指标
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#22" class="md-nav__link">
    <span class="md-ellipsis">
      2.2 交叉验证
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#23" class="md-nav__link">
    <span class="md-ellipsis">
      2.3 模型选择与调优
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#24" class="md-nav__link">
    <span class="md-ellipsis">
      2.4 模型解释性
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#25" class="md-nav__link">
    <span class="md-ellipsis">
      2.5 模型部署
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#knn" class="md-nav__link">
    <span class="md-ellipsis">
      三、KNN算法
    </span>
  </a>
  
    <nav class="md-nav" aria-label="三、KNN算法">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#31-knn" class="md-nav__link">
    <span class="md-ellipsis">
      3.1 KNN算法原理
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#32-knn" class="md-nav__link">
    <span class="md-ellipsis">
      3.2 KNN算法优缺点
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#33-knn" class="md-nav__link">
    <span class="md-ellipsis">
      3.3 KNN算法应用场景
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#34-knn" class="md-nav__link">
    <span class="md-ellipsis">
      3.4 KNN算法实现
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#35-knn" class="md-nav__link">
    <span class="md-ellipsis">
      3.5 KNN算法调优
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#36-knn" class="md-nav__link">
    <span class="md-ellipsis">
      3.6 KNN算法扩展
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#_14" class="md-nav__link">
    <span class="md-ellipsis">
      四、线性回归算法
    </span>
  </a>
  
    <nav class="md-nav" aria-label="四、线性回归算法">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#1_1" class="md-nav__link">
    <span class="md-ellipsis">
      1. 原理
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#2" class="md-nav__link">
    <span class="md-ellipsis">
      2. 优缺点
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#3_1" class="md-nav__link">
    <span class="md-ellipsis">
      3. 应用场景
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#4_1" class="md-nav__link">
    <span class="md-ellipsis">
      4. 代码实现
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#5_1" class="md-nav__link">
    <span class="md-ellipsis">
      5. 算法调优
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#6" class="md-nav__link">
    <span class="md-ellipsis">
      6. 最佳实践建议
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#_15" class="md-nav__link">
    <span class="md-ellipsis">
      四、逻辑回归算法
    </span>
  </a>
  
    <nav class="md-nav" aria-label="四、逻辑回归算法">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#41" class="md-nav__link">
    <span class="md-ellipsis">
      4.1 逻辑回归算法原理
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#42_1" class="md-nav__link">
    <span class="md-ellipsis">
      4.2 逻辑回归算法优缺点
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#43" class="md-nav__link">
    <span class="md-ellipsis">
      4.3 逻辑回归算法应用场景
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#44" class="md-nav__link">
    <span class="md-ellipsis">
      4.4 逻辑回归算法实现
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#45" class="md-nav__link">
    <span class="md-ellipsis">
      4.5 逻辑回归算法调优
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#46" class="md-nav__link">
    <span class="md-ellipsis">
      4.6 逻辑回归算法扩展
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#_19" class="md-nav__link">
    <span class="md-ellipsis">
      五、朴素贝叶斯算法
    </span>
  </a>
  
    <nav class="md-nav" aria-label="五、朴素贝叶斯算法">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#51_1" class="md-nav__link">
    <span class="md-ellipsis">
      5.1 朴素贝叶斯算法原理
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#52_1" class="md-nav__link">
    <span class="md-ellipsis">
      5.2 朴素贝叶斯算法优缺点
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#53_1" class="md-nav__link">
    <span class="md-ellipsis">
      5.3 朴素贝叶斯算法应用场景
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#54_1" class="md-nav__link">
    <span class="md-ellipsis">
      5.4 朴素贝叶斯算法实现
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#55_1" class="md-nav__link">
    <span class="md-ellipsis">
      5.5 朴素贝叶斯算法调优
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#56" class="md-nav__link">
    <span class="md-ellipsis">
      5.6 朴素贝叶斯算法扩展
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#_27" class="md-nav__link">
    <span class="md-ellipsis">
      六、决策树模型
    </span>
  </a>
  
    <nav class="md-nav" aria-label="六、决策树模型">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#61" class="md-nav__link">
    <span class="md-ellipsis">
      6.1 决策树模型原理
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#62" class="md-nav__link">
    <span class="md-ellipsis">
      6.2 决策树模型优缺点
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#63" class="md-nav__link">
    <span class="md-ellipsis">
      6.3 决策树模型应用场景
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#64" class="md-nav__link">
    <span class="md-ellipsis">
      6.4 决策树模型实现
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#65" class="md-nav__link">
    <span class="md-ellipsis">
      6.5 决策树模型调优
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#66" class="md-nav__link">
    <span class="md-ellipsis">
      6.6 决策树模型扩展
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#_35" class="md-nav__link">
    <span class="md-ellipsis">
      七、随机森林分类模型
    </span>
  </a>
  
    <nav class="md-nav" aria-label="七、随机森林分类模型">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#71" class="md-nav__link">
    <span class="md-ellipsis">
      7.1 随机森林分类模型原理
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#72" class="md-nav__link">
    <span class="md-ellipsis">
      7.2 随机森林分类模型优缺点
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#73" class="md-nav__link">
    <span class="md-ellipsis">
      7.3 随机森林分类模型应用场景
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#74" class="md-nav__link">
    <span class="md-ellipsis">
      7.4 随机森林分类模型实现
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#75" class="md-nav__link">
    <span class="md-ellipsis">
      7.5 随机森林分类模型调优
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#76" class="md-nav__link">
    <span class="md-ellipsis">
      7.6 随机森林分类模型扩展
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#_38" class="md-nav__link">
    <span class="md-ellipsis">
      八、回归树模型
    </span>
  </a>
  
    <nav class="md-nav" aria-label="八、回归树模型">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#81" class="md-nav__link">
    <span class="md-ellipsis">
      8.1 回归树模型原理
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#82" class="md-nav__link">
    <span class="md-ellipsis">
      8.2 回归树模型优缺点
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#83" class="md-nav__link">
    <span class="md-ellipsis">
      8.3 回归树模型应用场景
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#84" class="md-nav__link">
    <span class="md-ellipsis">
      8.4 回归树模型实现
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#85" class="md-nav__link">
    <span class="md-ellipsis">
      8.5 回归树模型调优
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#86" class="md-nav__link">
    <span class="md-ellipsis">
      8.6 回归树模型扩展
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#gbdt" class="md-nav__link">
    <span class="md-ellipsis">
      九、GBDT模型
    </span>
  </a>
  
    <nav class="md-nav" aria-label="九、GBDT模型">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#91-gbdt" class="md-nav__link">
    <span class="md-ellipsis">
      9.1 GBDT模型原理
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#92-gbdt" class="md-nav__link">
    <span class="md-ellipsis">
      9.2 GBDT模型优缺点
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#93-gbdt" class="md-nav__link">
    <span class="md-ellipsis">
      9.3 GBDT模型应用场景
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#94-gbdt" class="md-nav__link">
    <span class="md-ellipsis">
      9.4 GBDT模型实现
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#95-gbdt" class="md-nav__link">
    <span class="md-ellipsis">
      9.5 GBDT模型调优
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#96-gbdt" class="md-nav__link">
    <span class="md-ellipsis">
      9.6 GBDT模型扩展
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#xgboost" class="md-nav__link">
    <span class="md-ellipsis">
      十、XGBoost模型
    </span>
  </a>
  
    <nav class="md-nav" aria-label="十、XGBoost模型">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#101-xgboost" class="md-nav__link">
    <span class="md-ellipsis">
      10.1 XGBoost模型原理
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#102-xgboost" class="md-nav__link">
    <span class="md-ellipsis">
      10.2 XGBoost模型优缺点
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#103-xgboost" class="md-nav__link">
    <span class="md-ellipsis">
      10.3 XGBoost模型应用场景
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#104-xgboost" class="md-nav__link">
    <span class="md-ellipsis">
      10.4 XGBoost模型实现
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#105-xgboost" class="md-nav__link">
    <span class="md-ellipsis">
      10.5 XGBoost模型调优
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#106-xgboost" class="md-nav__link">
    <span class="md-ellipsis">
      10.6 XGBoost模型扩展
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#lightgbm" class="md-nav__link">
    <span class="md-ellipsis">
      十一、LightGBM模型
    </span>
  </a>
  
    <nav class="md-nav" aria-label="十一、LightGBM模型">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#111-lightgbm" class="md-nav__link">
    <span class="md-ellipsis">
      11.1 LightGBM模型原理
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#112-lightgbm" class="md-nav__link">
    <span class="md-ellipsis">
      11.2 LightGBM模型优缺点
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#113-lightgbm" class="md-nav__link">
    <span class="md-ellipsis">
      11.3 LightGBM模型应用场景
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#114-lightgbm" class="md-nav__link">
    <span class="md-ellipsis">
      11.4 LightGBM模型实现
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#115-lightgbm" class="md-nav__link">
    <span class="md-ellipsis">
      11.5 LightGBM模型调优
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#116-lightgbm" class="md-nav__link">
    <span class="md-ellipsis">
      11.6 LightGBM模型扩展
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#_47" class="md-nav__link">
    <span class="md-ellipsis">
      十二、支持向量机模型
    </span>
  </a>
  
    <nav class="md-nav" aria-label="十二、支持向量机模型">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#121" class="md-nav__link">
    <span class="md-ellipsis">
      12.1 支持向量机模型原理
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#122" class="md-nav__link">
    <span class="md-ellipsis">
      12.2 支持向量机模型优缺点
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#123" class="md-nav__link">
    <span class="md-ellipsis">
      12.3 支持向量机模型应用场景
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#124" class="md-nav__link">
    <span class="md-ellipsis">
      12.4 支持向量机模型实现
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#125" class="md-nav__link">
    <span class="md-ellipsis">
      12.5 支持向量机模型调优
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#126" class="md-nav__link">
    <span class="md-ellipsis">
      12.6 支持向量机模型扩展
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#_50" class="md-nav__link">
    <span class="md-ellipsis">
      十三、聚类算法
    </span>
  </a>
  
    <nav class="md-nav" aria-label="十三、聚类算法">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#131" class="md-nav__link">
    <span class="md-ellipsis">
      13.1 聚类算法原理
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#132" class="md-nav__link">
    <span class="md-ellipsis">
      13.2 聚类算法优缺点
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#133" class="md-nav__link">
    <span class="md-ellipsis">
      13.3 聚类算法应用场景
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#134" class="md-nav__link">
    <span class="md-ellipsis">
      13.4 聚类算法实现
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#135" class="md-nav__link">
    <span class="md-ellipsis">
      13.5 聚类算法调优
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#136" class="md-nav__link">
    <span class="md-ellipsis">
      13.6 聚类算法扩展
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#_53" class="md-nav__link">
    <span class="md-ellipsis">
      十四、降维算法
    </span>
  </a>
  
    <nav class="md-nav" aria-label="十四、降维算法">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#141" class="md-nav__link">
    <span class="md-ellipsis">
      14.1 降维算法原理
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#142" class="md-nav__link">
    <span class="md-ellipsis">
      14.2 降维算法优缺点
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#143" class="md-nav__link">
    <span class="md-ellipsis">
      14.3 降维算法应用场景
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#144" class="md-nav__link">
    <span class="md-ellipsis">
      14.4 降维算法实现
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#145" class="md-nav__link">
    <span class="md-ellipsis">
      14.5 降维算法调优
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#146" class="md-nav__link">
    <span class="md-ellipsis">
      14.6 降维算法扩展
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#_56" class="md-nav__link">
    <span class="md-ellipsis">
      十五、神经网络模型
    </span>
  </a>
  
    <nav class="md-nav" aria-label="十五、神经网络模型">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#151" class="md-nav__link">
    <span class="md-ellipsis">
      15.1 神经网络模型原理
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#152" class="md-nav__link">
    <span class="md-ellipsis">
      15.2 神经网络模型优缺点
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#153" class="md-nav__link">
    <span class="md-ellipsis">
      15.3 神经网络模型应用场景
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#154" class="md-nav__link">
    <span class="md-ellipsis">
      15.4 神经网络模型实现
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#155" class="md-nav__link">
    <span class="md-ellipsis">
      15.5 神经网络模型调优
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#_59" class="md-nav__link">
    <span class="md-ellipsis">
      十六、集成学习
    </span>
  </a>
  
    <nav class="md-nav" aria-label="十六、集成学习">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#1_3" class="md-nav__link">
    <span class="md-ellipsis">
      1. 什么是集成学习（核心思想）
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#2_2" class="md-nav__link">
    <span class="md-ellipsis">
      2. 常见方法与原理（简要）
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#3_2" class="md-nav__link">
    <span class="md-ellipsis">
      3. 优缺点总结
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#4_2" class="md-nav__link">
    <span class="md-ellipsis">
      4. 典型应用场景
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#5-scikit-learn" class="md-nav__link">
    <span class="md-ellipsis">
      5. 实战代码（scikit-learn）
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#6_1" class="md-nav__link">
    <span class="md-ellipsis">
      6. 常用实践建议（工程层面）
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#7" class="md-nav__link">
    <span class="md-ellipsis">
      7. 进阶技巧（小贴士）
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#8" class="md-nav__link">
    <span class="md-ellipsis">
      8. 小结（快速回顾）
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
    </ul>
  
</nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../interview/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    机器学习面试
    
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
  
  
    
    
      
        
      
        
      
    
    
    
      
      
        
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
          
        
        <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type="checkbox" id="__nav_3" >
        
          
          <label class="md-nav__link" for="__nav_3" id="__nav_3_label" tabindex="0">
            
  
  
  <span class="md-ellipsis">
    深度学习
    
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_3_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_3">
            <span class="md-nav__icon md-icon"></span>
            深度学习
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../deeplearning/math/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    深度学习中的数学
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../deeplearning/tutorial/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    深度学习教程
    
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
  
  
    
    
      
        
      
        
      
    
    
    
      
      
        
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
          
        
        <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type="checkbox" id="__nav_4" >
        
          
          <label class="md-nav__link" for="__nav_4" id="__nav_4_label" tabindex="0">
            
  
  
  <span class="md-ellipsis">
    强化学习
    
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_4_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_4">
            <span class="md-nav__icon md-icon"></span>
            强化学习
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../reinforcement/math/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    强化学习中的数学
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../reinforcement/tutorial/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    强化学习教程
    
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
  </ul>
</nav>
                  </div>
                </div>
              </div>
            
            
              
              <div class="md-sidebar md-sidebar--secondary" data-md-component="sidebar" data-md-type="toc" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    

<nav class="md-nav md-nav--secondary" aria-label="目录">
  
  
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      目录
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#_2" class="md-nav__link">
    <span class="md-ellipsis">
      一、机器学习基础知识
    </span>
  </a>
  
    <nav class="md-nav" aria-label="一、机器学习基础知识">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#11" class="md-nav__link">
    <span class="md-ellipsis">
      1.1 什么是机器学习
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#12" class="md-nav__link">
    <span class="md-ellipsis">
      1.2 机器学习的类型
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#13" class="md-nav__link">
    <span class="md-ellipsis">
      1.3 机器学习的基本流程
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#_3" class="md-nav__link">
    <span class="md-ellipsis">
      二、模型评估方法与准则
    </span>
  </a>
  
    <nav class="md-nav" aria-label="二、模型评估方法与准则">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#21" class="md-nav__link">
    <span class="md-ellipsis">
      2.1 评估指标
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#22" class="md-nav__link">
    <span class="md-ellipsis">
      2.2 交叉验证
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#23" class="md-nav__link">
    <span class="md-ellipsis">
      2.3 模型选择与调优
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#24" class="md-nav__link">
    <span class="md-ellipsis">
      2.4 模型解释性
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#25" class="md-nav__link">
    <span class="md-ellipsis">
      2.5 模型部署
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#knn" class="md-nav__link">
    <span class="md-ellipsis">
      三、KNN算法
    </span>
  </a>
  
    <nav class="md-nav" aria-label="三、KNN算法">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#31-knn" class="md-nav__link">
    <span class="md-ellipsis">
      3.1 KNN算法原理
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#32-knn" class="md-nav__link">
    <span class="md-ellipsis">
      3.2 KNN算法优缺点
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#33-knn" class="md-nav__link">
    <span class="md-ellipsis">
      3.3 KNN算法应用场景
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#34-knn" class="md-nav__link">
    <span class="md-ellipsis">
      3.4 KNN算法实现
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#35-knn" class="md-nav__link">
    <span class="md-ellipsis">
      3.5 KNN算法调优
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#36-knn" class="md-nav__link">
    <span class="md-ellipsis">
      3.6 KNN算法扩展
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#_14" class="md-nav__link">
    <span class="md-ellipsis">
      四、线性回归算法
    </span>
  </a>
  
    <nav class="md-nav" aria-label="四、线性回归算法">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#1_1" class="md-nav__link">
    <span class="md-ellipsis">
      1. 原理
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#2" class="md-nav__link">
    <span class="md-ellipsis">
      2. 优缺点
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#3_1" class="md-nav__link">
    <span class="md-ellipsis">
      3. 应用场景
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#4_1" class="md-nav__link">
    <span class="md-ellipsis">
      4. 代码实现
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#5_1" class="md-nav__link">
    <span class="md-ellipsis">
      5. 算法调优
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#6" class="md-nav__link">
    <span class="md-ellipsis">
      6. 最佳实践建议
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#_15" class="md-nav__link">
    <span class="md-ellipsis">
      四、逻辑回归算法
    </span>
  </a>
  
    <nav class="md-nav" aria-label="四、逻辑回归算法">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#41" class="md-nav__link">
    <span class="md-ellipsis">
      4.1 逻辑回归算法原理
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#42_1" class="md-nav__link">
    <span class="md-ellipsis">
      4.2 逻辑回归算法优缺点
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#43" class="md-nav__link">
    <span class="md-ellipsis">
      4.3 逻辑回归算法应用场景
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#44" class="md-nav__link">
    <span class="md-ellipsis">
      4.4 逻辑回归算法实现
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#45" class="md-nav__link">
    <span class="md-ellipsis">
      4.5 逻辑回归算法调优
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#46" class="md-nav__link">
    <span class="md-ellipsis">
      4.6 逻辑回归算法扩展
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#_19" class="md-nav__link">
    <span class="md-ellipsis">
      五、朴素贝叶斯算法
    </span>
  </a>
  
    <nav class="md-nav" aria-label="五、朴素贝叶斯算法">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#51_1" class="md-nav__link">
    <span class="md-ellipsis">
      5.1 朴素贝叶斯算法原理
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#52_1" class="md-nav__link">
    <span class="md-ellipsis">
      5.2 朴素贝叶斯算法优缺点
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#53_1" class="md-nav__link">
    <span class="md-ellipsis">
      5.3 朴素贝叶斯算法应用场景
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#54_1" class="md-nav__link">
    <span class="md-ellipsis">
      5.4 朴素贝叶斯算法实现
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#55_1" class="md-nav__link">
    <span class="md-ellipsis">
      5.5 朴素贝叶斯算法调优
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#56" class="md-nav__link">
    <span class="md-ellipsis">
      5.6 朴素贝叶斯算法扩展
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#_27" class="md-nav__link">
    <span class="md-ellipsis">
      六、决策树模型
    </span>
  </a>
  
    <nav class="md-nav" aria-label="六、决策树模型">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#61" class="md-nav__link">
    <span class="md-ellipsis">
      6.1 决策树模型原理
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#62" class="md-nav__link">
    <span class="md-ellipsis">
      6.2 决策树模型优缺点
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#63" class="md-nav__link">
    <span class="md-ellipsis">
      6.3 决策树模型应用场景
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#64" class="md-nav__link">
    <span class="md-ellipsis">
      6.4 决策树模型实现
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#65" class="md-nav__link">
    <span class="md-ellipsis">
      6.5 决策树模型调优
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#66" class="md-nav__link">
    <span class="md-ellipsis">
      6.6 决策树模型扩展
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#_35" class="md-nav__link">
    <span class="md-ellipsis">
      七、随机森林分类模型
    </span>
  </a>
  
    <nav class="md-nav" aria-label="七、随机森林分类模型">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#71" class="md-nav__link">
    <span class="md-ellipsis">
      7.1 随机森林分类模型原理
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#72" class="md-nav__link">
    <span class="md-ellipsis">
      7.2 随机森林分类模型优缺点
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#73" class="md-nav__link">
    <span class="md-ellipsis">
      7.3 随机森林分类模型应用场景
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#74" class="md-nav__link">
    <span class="md-ellipsis">
      7.4 随机森林分类模型实现
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#75" class="md-nav__link">
    <span class="md-ellipsis">
      7.5 随机森林分类模型调优
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#76" class="md-nav__link">
    <span class="md-ellipsis">
      7.6 随机森林分类模型扩展
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#_38" class="md-nav__link">
    <span class="md-ellipsis">
      八、回归树模型
    </span>
  </a>
  
    <nav class="md-nav" aria-label="八、回归树模型">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#81" class="md-nav__link">
    <span class="md-ellipsis">
      8.1 回归树模型原理
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#82" class="md-nav__link">
    <span class="md-ellipsis">
      8.2 回归树模型优缺点
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#83" class="md-nav__link">
    <span class="md-ellipsis">
      8.3 回归树模型应用场景
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#84" class="md-nav__link">
    <span class="md-ellipsis">
      8.4 回归树模型实现
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#85" class="md-nav__link">
    <span class="md-ellipsis">
      8.5 回归树模型调优
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#86" class="md-nav__link">
    <span class="md-ellipsis">
      8.6 回归树模型扩展
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#gbdt" class="md-nav__link">
    <span class="md-ellipsis">
      九、GBDT模型
    </span>
  </a>
  
    <nav class="md-nav" aria-label="九、GBDT模型">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#91-gbdt" class="md-nav__link">
    <span class="md-ellipsis">
      9.1 GBDT模型原理
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#92-gbdt" class="md-nav__link">
    <span class="md-ellipsis">
      9.2 GBDT模型优缺点
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#93-gbdt" class="md-nav__link">
    <span class="md-ellipsis">
      9.3 GBDT模型应用场景
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#94-gbdt" class="md-nav__link">
    <span class="md-ellipsis">
      9.4 GBDT模型实现
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#95-gbdt" class="md-nav__link">
    <span class="md-ellipsis">
      9.5 GBDT模型调优
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#96-gbdt" class="md-nav__link">
    <span class="md-ellipsis">
      9.6 GBDT模型扩展
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#xgboost" class="md-nav__link">
    <span class="md-ellipsis">
      十、XGBoost模型
    </span>
  </a>
  
    <nav class="md-nav" aria-label="十、XGBoost模型">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#101-xgboost" class="md-nav__link">
    <span class="md-ellipsis">
      10.1 XGBoost模型原理
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#102-xgboost" class="md-nav__link">
    <span class="md-ellipsis">
      10.2 XGBoost模型优缺点
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#103-xgboost" class="md-nav__link">
    <span class="md-ellipsis">
      10.3 XGBoost模型应用场景
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#104-xgboost" class="md-nav__link">
    <span class="md-ellipsis">
      10.4 XGBoost模型实现
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#105-xgboost" class="md-nav__link">
    <span class="md-ellipsis">
      10.5 XGBoost模型调优
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#106-xgboost" class="md-nav__link">
    <span class="md-ellipsis">
      10.6 XGBoost模型扩展
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#lightgbm" class="md-nav__link">
    <span class="md-ellipsis">
      十一、LightGBM模型
    </span>
  </a>
  
    <nav class="md-nav" aria-label="十一、LightGBM模型">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#111-lightgbm" class="md-nav__link">
    <span class="md-ellipsis">
      11.1 LightGBM模型原理
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#112-lightgbm" class="md-nav__link">
    <span class="md-ellipsis">
      11.2 LightGBM模型优缺点
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#113-lightgbm" class="md-nav__link">
    <span class="md-ellipsis">
      11.3 LightGBM模型应用场景
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#114-lightgbm" class="md-nav__link">
    <span class="md-ellipsis">
      11.4 LightGBM模型实现
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#115-lightgbm" class="md-nav__link">
    <span class="md-ellipsis">
      11.5 LightGBM模型调优
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#116-lightgbm" class="md-nav__link">
    <span class="md-ellipsis">
      11.6 LightGBM模型扩展
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#_47" class="md-nav__link">
    <span class="md-ellipsis">
      十二、支持向量机模型
    </span>
  </a>
  
    <nav class="md-nav" aria-label="十二、支持向量机模型">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#121" class="md-nav__link">
    <span class="md-ellipsis">
      12.1 支持向量机模型原理
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#122" class="md-nav__link">
    <span class="md-ellipsis">
      12.2 支持向量机模型优缺点
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#123" class="md-nav__link">
    <span class="md-ellipsis">
      12.3 支持向量机模型应用场景
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#124" class="md-nav__link">
    <span class="md-ellipsis">
      12.4 支持向量机模型实现
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#125" class="md-nav__link">
    <span class="md-ellipsis">
      12.5 支持向量机模型调优
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#126" class="md-nav__link">
    <span class="md-ellipsis">
      12.6 支持向量机模型扩展
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#_50" class="md-nav__link">
    <span class="md-ellipsis">
      十三、聚类算法
    </span>
  </a>
  
    <nav class="md-nav" aria-label="十三、聚类算法">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#131" class="md-nav__link">
    <span class="md-ellipsis">
      13.1 聚类算法原理
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#132" class="md-nav__link">
    <span class="md-ellipsis">
      13.2 聚类算法优缺点
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#133" class="md-nav__link">
    <span class="md-ellipsis">
      13.3 聚类算法应用场景
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#134" class="md-nav__link">
    <span class="md-ellipsis">
      13.4 聚类算法实现
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#135" class="md-nav__link">
    <span class="md-ellipsis">
      13.5 聚类算法调优
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#136" class="md-nav__link">
    <span class="md-ellipsis">
      13.6 聚类算法扩展
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#_53" class="md-nav__link">
    <span class="md-ellipsis">
      十四、降维算法
    </span>
  </a>
  
    <nav class="md-nav" aria-label="十四、降维算法">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#141" class="md-nav__link">
    <span class="md-ellipsis">
      14.1 降维算法原理
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#142" class="md-nav__link">
    <span class="md-ellipsis">
      14.2 降维算法优缺点
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#143" class="md-nav__link">
    <span class="md-ellipsis">
      14.3 降维算法应用场景
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#144" class="md-nav__link">
    <span class="md-ellipsis">
      14.4 降维算法实现
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#145" class="md-nav__link">
    <span class="md-ellipsis">
      14.5 降维算法调优
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#146" class="md-nav__link">
    <span class="md-ellipsis">
      14.6 降维算法扩展
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#_56" class="md-nav__link">
    <span class="md-ellipsis">
      十五、神经网络模型
    </span>
  </a>
  
    <nav class="md-nav" aria-label="十五、神经网络模型">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#151" class="md-nav__link">
    <span class="md-ellipsis">
      15.1 神经网络模型原理
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#152" class="md-nav__link">
    <span class="md-ellipsis">
      15.2 神经网络模型优缺点
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#153" class="md-nav__link">
    <span class="md-ellipsis">
      15.3 神经网络模型应用场景
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#154" class="md-nav__link">
    <span class="md-ellipsis">
      15.4 神经网络模型实现
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#155" class="md-nav__link">
    <span class="md-ellipsis">
      15.5 神经网络模型调优
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#_59" class="md-nav__link">
    <span class="md-ellipsis">
      十六、集成学习
    </span>
  </a>
  
    <nav class="md-nav" aria-label="十六、集成学习">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#1_3" class="md-nav__link">
    <span class="md-ellipsis">
      1. 什么是集成学习（核心思想）
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#2_2" class="md-nav__link">
    <span class="md-ellipsis">
      2. 常见方法与原理（简要）
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#3_2" class="md-nav__link">
    <span class="md-ellipsis">
      3. 优缺点总结
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#4_2" class="md-nav__link">
    <span class="md-ellipsis">
      4. 典型应用场景
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#5-scikit-learn" class="md-nav__link">
    <span class="md-ellipsis">
      5. 实战代码（scikit-learn）
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#6_1" class="md-nav__link">
    <span class="md-ellipsis">
      6. 常用实践建议（工程层面）
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#7" class="md-nav__link">
    <span class="md-ellipsis">
      7. 进阶技巧（小贴士）
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#8" class="md-nav__link">
    <span class="md-ellipsis">
      8. 小结（快速回顾）
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
    </ul>
  
</nav>
                  </div>
                </div>
              </div>
            
          
          
            <div class="md-content" data-md-component="content">
              <article class="md-content__inner md-typeset">
                
                  



<h1 id="_1">机器学习教程<a class="headerlink" href="#_1" title="Permanent link">&para;</a></h1>
<h2 id="_2">一、机器学习基础知识<a class="headerlink" href="#_2" title="Permanent link">&para;</a></h2>
<h3 id="11">1.1 什么是机器学习<a class="headerlink" href="#11" title="Permanent link">&para;</a></h3>
<p>机器学习是一种让计算机通过数据学习并自动改进性能的技术。它通过算法从数据中提取模式和规律，从而进行预测或决策。</p>
<h3 id="12">1.2 机器学习的类型<a class="headerlink" href="#12" title="Permanent link">&para;</a></h3>
<p>机器学习主要分为三种类型：</p>
<ul>
<li>监督学习：通过标注数据进行训练，常用于分类和回归任务</li>
<li>无监督学习：通过未标注数据进行训练，常用于聚类和降维任务</li>
<li>强化学习：通过与环境交互进行学习，常用于游戏和机器人控制</li>
</ul>
<h3 id="13">1.3 机器学习的基本流程<a class="headerlink" href="#13" title="Permanent link">&para;</a></h3>
<ol>
<li>数据收集：获取相关数据</li>
<li>数据预处理：清洗和转换数据</li>
<li>特征工程：选择和提取有用特征</li>
<li>模型选择：选择合适的算法</li>
<li>模型训练：使用训练数据进行模型训练</li>
<li>模型评估：使用测试数据评估模型性能</li>
<li>模型优化：调整模型参数以提高性能</li>
<li>部署与监控：将模型应用于实际场景并持续监控</li>
</ol>
<h2 id="_3">二、模型评估方法与准则<a class="headerlink" href="#_3" title="Permanent link">&para;</a></h2>
<h3 id="21">2.1 评估指标<a class="headerlink" href="#21" title="Permanent link">&para;</a></h3>
<p>评估模型性能的指标有很多，选择合适的指标取决于具体的任务和数据集。</p>
<p>常用的评估指标包括：</p>
<ul>
<li>准确率（Accuracy）</li>
<li>精确率（Precision）</li>
<li>召回率（Recall）</li>
<li>F1分数（F1 Score）</li>
<li>ROC曲线和AUC值</li>
<li>均方误差（Mean Squared Error, MSE）</li>
<li>平均绝对误差（Mean Absolute Error, MAE）  </li>
<li>平均绝对百分误差 MAPE</li>
<li>R²（决定系数）</li>
</ul>
<h4 id="_4">分类任务指标<a class="headerlink" href="#_4" title="Permanent link">&para;</a></h4>
<ul>
<li>准确率（Accuracy）：正确预测的样本数占总样本数的比例。</li>
<li>精确率（Precision）：预测为正类的样本中实际为正类的比例。</li>
<li>召回率（Recall）：实际为正类的样本中被正确预测为正类的比例。</li>
<li>F1分数（F1 Score）：精确率和召回率的调和平均数。</li>
<li>ROC曲线和AUC值：评估分类模型在不同阈值下的性能。</li>
</ul>
<h5 id="confusion-matrix">混淆矩阵（Confusion Matrix）<a class="headerlink" href="#confusion-matrix" title="Permanent link">&para;</a></h5>
<p>混淆矩阵是用于评估分类模型性能的工具，显示了实际类别与预测类别的对比情况。对于二分类问题，混淆矩阵通常包含以下四个部分：</p>
<table>
<thead>
<tr>
<th></th>
<th>预测为正类 (Positive)</th>
<th>预测为负类 (Negative)</th>
</tr>
</thead>
<tbody>
<tr>
<td>实际为正类 (Positive)</td>
<td>True Positive (TP)</td>
<td>False Negative (FN)</td>
</tr>
<tr>
<td>实际为负类 (Negative)</td>
<td>False Positive (FP)</td>
<td>True Negative (TN)</td>
</tr>
</tbody>
</table>
<h5 id="accuracy">准确率（Accuracy）<a class="headerlink" href="#accuracy" title="Permanent link">&para;</a></h5>
<div class="arithmatex">\[
Accuracy = \frac{TP + TN}{TP + TN + FP + FN}
\]</div>
<p>其中，TP（True Positive）表示真正例，TN（True Negative）表示真反例，FP（False Positive）表示假正例，FN（False Negative）表示假反例。    </p>
<h5 id="precision">精确率（Precision）<a class="headerlink" href="#precision" title="Permanent link">&para;</a></h5>
<div class="arithmatex">\[
Precision = \frac{TP}{TP + FP}
\]</div>
<h5 id="recall">召回率（Recall）<a class="headerlink" href="#recall" title="Permanent link">&para;</a></h5>
<div class="arithmatex">\[
Recall = \frac{TP}{TP + FN}
\]</div>
<h5 id="f1f1-score">F1分数（F1 Score）<a class="headerlink" href="#f1f1-score" title="Permanent link">&para;</a></h5>
<div class="arithmatex">\[
F1 = 2 \times \frac{Precision \times Recall}{Precision + Recall}
\]</div>
<h5 id="rocauc">ROC曲线和AUC值<a class="headerlink" href="#rocauc" title="Permanent link">&para;</a></h5>
<p>ROC曲线（Receiver Operating Characteristic Curve）是通过改变分类阈值绘制的真阳性率（TPR）与假阳性率（FPR）之间的关系图。AUC（Area Under the Curve）值表示ROC曲线下的面积，范围在0到1之间，值越大表示模型性能越好。  </p>
<div class="arithmatex">\[
TPR = \frac{TP}{TP + FN}
\]</div>
<div class="arithmatex">\[
FPR = \frac{FP}{FP + TN}
\]</div>
<h4 id="_5">回归任务指标<a class="headerlink" href="#_5" title="Permanent link">&para;</a></h4>
<ul>
<li>均方误差（Mean Squared Error, MSE）：预测值与实际值之间差异的平方的平均值。</li>
<li>平均绝对误差（Mean Absolute Error, MAE）：预测值与实际值之间差异的绝对值的平均值。</li>
<li>平均绝对百分误差 MAPE：预测值与实际值之间差异的绝对值占实际值的百分比的平均值。</li>
<li>R²（决定系数）：衡量模型解释数据变异的能力。 </li>
</ul>
<h5 id="mean-squared-error-mse">均方误差（Mean Squared Error, MSE）<a class="headerlink" href="#mean-squared-error-mse" title="Permanent link">&para;</a></h5>
<div class="arithmatex">\[
MSE = \frac{1}{n} \sum_{i=1}^{n} (y_i - \hat{y}_i)^2
\]</div>
<p>其中，<span class="arithmatex">\(y_i\)</span> 是实际值，<span class="arithmatex">\(\hat{y}_i\)</span> 是预测值，<span class="arithmatex">\(n\)</span> 是样本数量。</p>
<h5 id="mean-absolute-error-mae">平均绝对误差（Mean Absolute Error, MAE）<a class="headerlink" href="#mean-absolute-error-mae" title="Permanent link">&para;</a></h5>
<div class="arithmatex">\[
MAE = \frac{1}{n} \sum_{i=1}^{n} |y_i - \hat{y}_i|
\]</div>
<h5 id="mean-absolute-percentage-error-mape">平均绝对百分误差（Mean Absolute Percentage Error, MAPE）<a class="headerlink" href="#mean-absolute-percentage-error-mape" title="Permanent link">&para;</a></h5>
<div class="arithmatex">\[
MAPE = \frac{1}{n} \sum_{i=1}^{n} \left| \frac{y_i - \hat{y}_i}{y_i} \right| \times 100\%
\]</div>
<h5 id="r2">R²（决定系数）<a class="headerlink" href="#r2" title="Permanent link">&para;</a></h5>
<div class="arithmatex">\[
R^2 = 1 - \frac{\sum_{i=1}^{n} (y_i - \hat{y}_i)^2}{\sum_{i=1}^{n} (y_i - \bar{y})^2}
\]</div>
<p>其中，<span class="arithmatex">\(\bar{y}\)</span> 是实际值的均值。</p>
<h4 id="_6">不平衡数据集处理<a class="headerlink" href="#_6" title="Permanent link">&para;</a></h4>
<p>对于不平衡数据集，单一的准确率可能会误导模型性能评估。此时，精确率、召回率和F1分数等指标更为重要。  </p>
<h3 id="22">2.2 交叉验证<a class="headerlink" href="#22" title="Permanent link">&para;</a></h3>
<p>交叉验证是一种评估模型性能的技术，通过将数据集划分为多个子集，轮流使用其中一个子集作为测试集，其余子集作为训练集。常见的交叉验证方法有：    </p>
<ul>
<li>K折交叉验证（K-Fold Cross-Validation）</li>
<li>留一法交叉验证（Leave-One-Out Cross-Validation）</li>
<li>分层K折交叉验证（Stratified K-Fold Cross-Validation）     </li>
</ul>
<h5 id="kk-fold-cross-validation">K折交叉验证（K-Fold Cross-Validation）<a class="headerlink" href="#kk-fold-cross-validation" title="Permanent link">&para;</a></h5>
<p>K折交叉验证将数据集划分为K个子集，轮流使用每个子集作为测试集，其余子集作为训练集。最终的模型性能是K次评估结果的平均值。</p>
<h5 id="leave-one-out-cross-validation">留一法交叉验证（Leave-One-Out Cross-Validation）<a class="headerlink" href="#leave-one-out-cross-validation" title="Permanent link">&para;</a></h5>
<p>留一法交叉验证是K折交叉验证的特例，其中K等于样本数量。每次使用一个样本作为测试集，其余样本作为训练集。适用于小数据集，但计算成本较高。  </p>
<h5 id="kstratified-k-fold-cross-validation">分层K折交叉验证（Stratified K-Fold Cross-Validation）<a class="headerlink" href="#kstratified-k-fold-cross-validation" title="Permanent link">&para;</a></h5>
<p>分层K折交叉验证在划分数据集时，保持各类样本的比例与原始数据集一致，适用于分类任务中的不平衡数据集。</p>
<h3 id="23">2.3 模型选择与调优<a class="headerlink" href="#23" title="Permanent link">&para;</a></h3>
<p>选择合适的模型和调优模型参数是提高模型性能的关键步骤。常用的方法包括：</p>
<ul>
<li>网格搜索（Grid Search）</li>
<li>随机搜索（Random Search）</li>
<li>贝叶斯优化（Bayesian Optimization）</li>
<li>超参数调优（Hyperparameter Tuning）       </li>
</ul>
<h5 id="grid-search">网格搜索（Grid Search）<a class="headerlink" href="#grid-search" title="Permanent link">&para;</a></h5>
<p>网格搜索通过定义一组超参数的取值范围，遍历所有可能的组合，找到性能最优的参数组合。适用于参数空间较小的情况。</p>
<h5 id="random-search">随机搜索（Random Search）<a class="headerlink" href="#random-search" title="Permanent link">&para;</a></h5>
<p>随机搜索从定义的超参数空间中随机采样一定数量的参数组合，评估其性能。适用于参数空间较大的情况，计算效率较高。</p>
<h5 id="bayesian-optimization">贝叶斯优化（Bayesian Optimization）<a class="headerlink" href="#bayesian-optimization" title="Permanent link">&para;</a></h5>
<p>贝叶斯优化通过构建代理模型，利用已有的评估结果指导下一次的参数选择，逐步逼近最优参数组合。适用于计算成本较高的情况。</p>
<h5 id="hyperparameter-tuning">超参数调优（Hyperparameter Tuning）<a class="headerlink" href="#hyperparameter-tuning" title="Permanent link">&para;</a></h5>
<p>超参数调优是指调整模型的超参数（如学习率、正则化参数等）以优化模型性能。可以结合上述方法进行调优。</p>
<h3 id="24">2.4 模型解释性<a class="headerlink" href="#24" title="Permanent link">&para;</a></h3>
<p>模型解释性是指理解和解释模型的决策过程，帮助用户信任和使用模型。常用的方法包括：</p>
<ul>
<li>特征重要性（Feature Importance）</li>
<li>局部解释模型（LIME）</li>
<li>SHAP值（SHapley Additive exPlanations）       </li>
</ul>
<h5 id="feature-importance">特征重要性（Feature Importance）<a class="headerlink" href="#feature-importance" title="Permanent link">&para;</a></h5>
<p>特征重要性评估每个特征对模型预测的贡献，常用于树模型。可以通过查看特征重要性排名，了解哪些特征对模型影响最大。  </p>
<h5 id="lime">局部解释模型（LIME）<a class="headerlink" href="#lime" title="Permanent link">&para;</a></h5>
<p>LIME通过在局部区域拟合简单模型，解释复杂模型的预测结果。适用于任何类型的模型，帮助理解单个预测的原因。  </p>
<h5 id="shapshapley-additive-explanations">SHAP值（SHapley Additive exPlanations）<a class="headerlink" href="#shapshapley-additive-explanations" title="Permanent link">&para;</a></h5>
<p>SHAP值基于博弈论，量化每个特征对预测结果的贡献。提供全局和局部的解释，适用于各种模型类型。  </p>
<h3 id="25">2.5 模型部署<a class="headerlink" href="#25" title="Permanent link">&para;</a></h3>
<h4 id="_7">什么是模型部署？<a class="headerlink" href="#_7" title="Permanent link">&para;</a></h4>
<ul>
<li><strong>训练阶段</strong>：你在本地用数据训练出模型（比如 sklearn、PyTorch、TensorFlow）。</li>
<li><strong>部署阶段</strong>：让别人能使用模型，通常通过：<ol>
<li>本地调用（Python 脚本或 Notebook）</li>
<li>打包 API 服务（Flask/FastAPI/Triton）</li>
<li>容器化 &amp; 云部署（Docker + Kubernetes + 云服务）</li>
<li>前端/移动端集成（ONNX/TensorRT/TF Lite）</li>
</ol>
</li>
</ul>
<h4 id="1">1、本地部署<a class="headerlink" href="#1" title="Permanent link">&para;</a></h4>
<p>适合学习和小规模测试。</p>
<p><strong>方式</strong>：直接保存模型，再加载调用。</p>
<div class="highlight"><pre><span></span><code><span class="kn">import</span><span class="w"> </span><span class="nn">joblib</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">sklearn.linear_model</span><span class="w"> </span><span class="kn">import</span> <span class="n">LogisticRegression</span>

<span class="c1"># 训练模型</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">LogisticRegression</span><span class="p">()</span>
<span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>

<span class="c1"># 保存模型</span>
<span class="n">joblib</span><span class="o">.</span><span class="n">dump</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="s2">&quot;model.pkl&quot;</span><span class="p">)</span>

<span class="c1"># 加载模型</span>
<span class="n">loaded_model</span> <span class="o">=</span> <span class="n">joblib</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="s2">&quot;model.pkl&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">loaded_model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">))</span>
</code></pre></div>
<h4 id="2api">2、API 服务化部署<a class="headerlink" href="#2api" title="Permanent link">&para;</a></h4>
<p>API 服务化部署.</p>
<h5 id="fastapi">FastAPI 部署<a class="headerlink" href="#fastapi" title="Permanent link">&para;</a></h5>
<p><div class="highlight"><pre><span></span><code><span class="kn">from</span><span class="w"> </span><span class="nn">fastapi</span><span class="w"> </span><span class="kn">import</span> <span class="n">FastAPI</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">joblib</span>

<span class="n">app</span> <span class="o">=</span> <span class="n">FastAPI</span><span class="p">()</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">joblib</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="s2">&quot;model.pkl&quot;</span><span class="p">)</span>

<span class="nd">@app</span><span class="o">.</span><span class="n">post</span><span class="p">(</span><span class="s2">&quot;/predict&quot;</span><span class="p">)</span>
<span class="k">def</span><span class="w"> </span><span class="nf">predict</span><span class="p">(</span><span class="n">features</span><span class="p">:</span> <span class="nb">list</span><span class="p">[</span><span class="nb">float</span><span class="p">]):</span>
    <span class="n">pred</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">predict</span><span class="p">([</span><span class="n">features</span><span class="p">])</span>
    <span class="k">return</span> <span class="p">{</span><span class="s2">&quot;prediction&quot;</span><span class="p">:</span> <span class="nb">int</span><span class="p">(</span><span class="n">pred</span><span class="p">[</span><span class="mi">0</span><span class="p">])}</span>
</code></pre></div>
<strong>启动</strong></p>
<div class="highlight"><pre><span></span><code>uvicorn<span class="w"> </span>app:app<span class="w"> </span>--reload
</code></pre></div>
<h4 id="3">3、容器化部署<a class="headerlink" href="#3" title="Permanent link">&para;</a></h4>
<p>当你需要在不同机器上运行，或部署到云端时，使用 Docker。</p>
<p><strong>Dockerfile 示例</strong>
<div class="highlight"><pre><span></span><code><span class="k">FROM</span><span class="w"> </span><span class="s">python:3.10-slim</span>
<span class="k">WORKDIR</span><span class="w"> </span><span class="s">/app</span>
<span class="k">COPY</span><span class="w"> </span>requirements.txt<span class="w"> </span>.
<span class="k">RUN</span><span class="w"> </span>pip<span class="w"> </span>install<span class="w"> </span>-r<span class="w"> </span>requirements.txt
<span class="k">COPY</span><span class="w"> </span>.<span class="w"> </span>.
<span class="k">CMD</span><span class="w"> </span><span class="p">[</span><span class="s2">&quot;uvicorn&quot;</span><span class="p">,</span><span class="w"> </span><span class="s2">&quot;app:app&quot;</span><span class="p">,</span><span class="w"> </span><span class="s2">&quot;--host&quot;</span><span class="p">,</span><span class="w"> </span><span class="s2">&quot;0.0.0.0&quot;</span><span class="p">,</span><span class="w"> </span><span class="s2">&quot;--port&quot;</span><span class="p">,</span><span class="w"> </span><span class="s2">&quot;8000&quot;</span><span class="p">]</span>
</code></pre></div>
构建镜像并运行：</p>
<div class="highlight"><pre><span></span><code>docker<span class="w"> </span>build<span class="w"> </span>-t<span class="w"> </span>ml-api<span class="w"> </span>.
docker<span class="w"> </span>run<span class="w"> </span>-p<span class="w"> </span><span class="m">8000</span>:8000<span class="w"> </span>ml-api
</code></pre></div>
<h4 id="4">4、云端部署<a class="headerlink" href="#4" title="Permanent link">&para;</a></h4>
<h5 id="_8">常见选择<a class="headerlink" href="#_8" title="Permanent link">&para;</a></h5>
<ul>
<li>AWS Sagemaker：官方托管服务，支持自动伸缩。</li>
<li>Google Vertex AI：适合 TensorFlow、PyTorch。</li>
<li>Azure ML：企业友好。</li>
<li>Hugging Face Spaces：免费快速搭建。</li>
<li>Render/Heroku：快速 Web 服务部署。</li>
</ul>
<h5 id="hugging-face-spaces-gradio">Hugging Face Spaces 示例（Gradio）<a class="headerlink" href="#hugging-face-spaces-gradio" title="Permanent link">&para;</a></h5>
<div class="highlight"><pre><span></span><code><span class="kn">import</span><span class="w"> </span><span class="nn">gradio</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">gr</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">joblib</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">joblib</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="s2">&quot;model.pkl&quot;</span><span class="p">)</span>

<span class="k">def</span><span class="w"> </span><span class="nf">predict</span><span class="p">(</span><span class="n">features</span><span class="p">):</span>
    <span class="k">return</span> <span class="nb">int</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">predict</span><span class="p">([</span><span class="n">features</span><span class="p">])[</span><span class="mi">0</span><span class="p">])</span>

<span class="n">iface</span> <span class="o">=</span> <span class="n">gr</span><span class="o">.</span><span class="n">Interface</span><span class="p">(</span><span class="n">fn</span><span class="o">=</span><span class="n">predict</span><span class="p">,</span> <span class="n">inputs</span><span class="o">=</span><span class="s2">&quot;text&quot;</span><span class="p">,</span> <span class="n">outputs</span><span class="o">=</span><span class="s2">&quot;label&quot;</span><span class="p">)</span>
<span class="n">iface</span><span class="o">.</span><span class="n">launch</span><span class="p">()</span>
</code></pre></div>
<h4 id="5">5、高性能推理<a class="headerlink" href="#5" title="Permanent link">&para;</a></h4>
<p>当模型较大时，需要优化：</p>
<ul>
<li>ONNX Runtime（跨平台推理）</li>
<li>TensorRT（NVIDIA GPU 加速）</li>
<li>Triton Inference Server（大规模部署）</li>
<li>vLLM（大模型推理优化）</li>
</ul>
<h2 id="knn">三、KNN算法<a class="headerlink" href="#knn" title="Permanent link">&para;</a></h2>
<p>KNN（K-Nearest Neighbors）算法是一种基于实例的监督学习算法，常用于分类和回归任务。其基本思想是通过计算样本之间的距离，找到与待预测样本最相似的K个邻居，根据邻居的类别或数值进行预测。</p>
<h3 id="31-knn">3.1 KNN算法原理<a class="headerlink" href="#31-knn" title="Permanent link">&para;</a></h3>
<p>KNN算法的主要步骤包括：</p>
<ol>
<li>选择合适的K值（邻居数量）</li>
<li>计算待预测样本与训练样本之间的距离（常用欧氏距离、曼哈顿距离等）</li>
<li>找到距离最近的K个邻居</li>
<li>根据邻居的类别或数值进行预测（分类任务中采用多数投票法，回归任务中采用平均值）   </li>
</ol>
<h5 id="_9">距离度量方法<a class="headerlink" href="#_9" title="Permanent link">&para;</a></h5>
<ul>
<li>欧氏距离（Euclidean Distance）：</li>
</ul>
<div class="arithmatex">\[
d(p, q) = \sqrt{\sum_{i=1}^{n} (p_i - q_i)^2}
\]</div>
<ul>
<li>曼哈顿距离（Manhattan Distance）：</li>
</ul>
<div class="arithmatex">\[
d(p, q) = \sum_{i=1}^{n} |p_i - q_i|
\]</div>
<ul>
<li>闵可夫斯基距离（Minkowski Distance）：</li>
</ul>
<div class="arithmatex">\[
d(p, q) = \left( \sum_{i=1}^{n} |p_i - q_i|^p \right)^{1/p}
\]</div>
<ul>
<li>余弦相似度（Cosine Similarity）：</li>
</ul>
<div class="arithmatex">\[
\text{similarity}(A, B) = \frac{A \cdot B}{\|A\| \|B\|}
\]</div>
<h3 id="32-knn">3.2 KNN算法优缺点<a class="headerlink" href="#32-knn" title="Permanent link">&para;</a></h3>
<h4 id="_10">优点<a class="headerlink" href="#_10" title="Permanent link">&para;</a></h4>
<ul>
<li>简单易懂，易于实现</li>
<li>无需训练过程，适合小数据集</li>
<li>可以处理多分类问题    </li>
</ul>
<h4 id="_11">缺点<a class="headerlink" href="#_11" title="Permanent link">&para;</a></h4>
<ul>
<li>计算复杂度高，适合小数据集</li>
<li>对噪声和异常值敏感</li>
<li>需要选择合适的K值和距离度量方法</li>
<li>维度灾难问题，随着特征数量增加，距离计算效果下降  </li>
</ul>
<h3 id="33-knn">3.3 KNN算法应用场景<a class="headerlink" href="#33-knn" title="Permanent link">&para;</a></h3>
<p>KNN算法适用于以下场景：</p>
<ul>
<li>分类任务，如文本分类、图像识别等</li>
<li>回归任务，如房价预测、股票价格预测等</li>
<li>推荐系统，如电影推荐、商品推荐等</li>
<li>异常检测，如信用卡欺诈检测、网络入侵检测等    </li>
</ul>
<h3 id="34-knn">3.4 KNN算法实现<a class="headerlink" href="#34-knn" title="Permanent link">&para;</a></h3>
<p>以下是使用Python和Scikit-learn库实现KNN算法的示例代码：</p>
<div class="highlight"><pre><span></span><code><span class="kn">import</span><span class="w"> </span><span class="nn">numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">np</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">sklearn.datasets</span><span class="w"> </span><span class="kn">import</span> <span class="n">load_iris</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">sklearn.model_selection</span><span class="w"> </span><span class="kn">import</span> <span class="n">train_test_split</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">sklearn.neighbors</span><span class="w"> </span><span class="kn">import</span> <span class="n">KNeighborsClassifier</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">sklearn.metrics</span><span class="w"> </span><span class="kn">import</span> <span class="n">classification_report</span><span class="p">,</span><span class="n">confusion_matrix</span><span class="p">,</span><span class="n">ConfusionMatrixDisplay</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">sklearn.preprocessing</span><span class="w"> </span><span class="kn">import</span> <span class="n">StandardScaler</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">matplotlib.pyplot</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">plt</span>

<span class="c1"># 加载数据集</span>
<span class="n">data</span> <span class="o">=</span> <span class="n">load_iris</span><span class="p">()</span>
<span class="n">X</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">data</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">target</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;特征名称：&quot;</span><span class="p">,</span><span class="n">data</span><span class="o">.</span><span class="n">feature_names</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;目标值：&quot;</span><span class="p">,</span><span class="n">data</span><span class="o">.</span><span class="n">target_names</span><span class="p">)</span>
<span class="c1"># 拆分训练数据和测试数据</span>
<span class="n">x_train</span><span class="p">,</span><span class="n">x_test</span><span class="p">,</span><span class="n">y_train</span><span class="p">,</span><span class="n">y_test</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span><span class="n">X</span><span class="p">,</span><span class="n">y</span><span class="p">,</span><span class="n">test_size</span><span class="o">=</span><span class="mf">0.2</span><span class="p">,</span><span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;训练集形状：&quot;</span><span class="p">,</span><span class="n">x_train</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;测试集形状：&quot;</span><span class="p">,</span><span class="n">x_test</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
<span class="c1"># 标准化</span>
<span class="n">scaler</span> <span class="o">=</span> <span class="n">StandardScaler</span><span class="p">()</span>
<span class="n">x_train</span> <span class="o">=</span> <span class="n">scaler</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">x_train</span><span class="p">)</span>
<span class="n">x_test</span> <span class="o">=</span> <span class="n">scaler</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">x_test</span><span class="p">)</span>
<span class="c1"># 训练模型</span>
<span class="n">knn</span> <span class="o">=</span> <span class="n">KNeighborsClassifier</span><span class="p">(</span><span class="n">n_neighbors</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span><span class="n">n_jobs</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
<span class="n">knn</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">x_train</span><span class="p">,</span><span class="n">y_train</span><span class="p">)</span>
<span class="c1"># 模型评估</span>
<span class="n">y_pred</span> <span class="o">=</span> <span class="n">knn</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">x_test</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;混淆矩阵&quot;</span><span class="o">.</span><span class="n">center</span><span class="p">(</span><span class="mi">80</span><span class="p">,</span><span class="s2">&quot;=&quot;</span><span class="p">))</span>
<span class="n">cm</span> <span class="o">=</span> <span class="n">confusion_matrix</span><span class="p">(</span><span class="n">y_true</span><span class="o">=</span><span class="n">y_test</span><span class="p">,</span><span class="n">y_pred</span><span class="o">=</span><span class="n">y_pred</span><span class="p">)</span>
<span class="n">disp</span> <span class="o">=</span> <span class="n">ConfusionMatrixDisplay</span><span class="p">(</span><span class="n">confusion_matrix</span><span class="o">=</span><span class="n">cm</span><span class="p">)</span>
<span class="n">disp</span><span class="o">.</span><span class="n">plot</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;分类报告&quot;</span><span class="o">.</span><span class="n">center</span><span class="p">(</span><span class="mi">80</span><span class="p">,</span><span class="s2">&quot;=&quot;</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="n">classification_report</span><span class="p">(</span><span class="n">y_true</span><span class="o">=</span><span class="n">y_test</span><span class="p">,</span><span class="n">y_pred</span><span class="o">=</span><span class="n">y_pred</span><span class="p">))</span>
</code></pre></div>
<p><code>KNeighborsClassifier</code> 是 scikit-learn 中基于 k-近邻（k-NN）算法的分类模型，通过计算待预测样本与训练集中最近邻样本的距离进行分类。以下是其核心参数的详细说明：</p>
<h4 id="1-n_neighbors"><strong>1. </strong><code>n_neighbors</code><a class="headerlink" href="#1-n_neighbors" title="Permanent link">&para;</a></h4>
<ul>
<li><strong>类型</strong>：<code>int</code>，默认值 <code>5</code></li>
<li><strong>作用</strong>：指定分类时参考的“最近邻”样本数量（k值）。</li>
<li><strong>说明</strong>：<ul>
<li>k值越小，模型对噪声越敏感，可能过拟合；k值越大，模型平滑性增强，但可能忽略局部特征。</li>
<li>通常通过交叉验证（如网格搜索）选择最优k值。</li>
</ul>
</li>
</ul>
<h4 id="2-weights"><strong>2. </strong><code>weights</code><a class="headerlink" href="#2-weights" title="Permanent link">&para;</a></h4>
<ul>
<li><strong>类型</strong>：<code>str</code> 或 <code>callable</code>，可选值 <code>'uniform'</code>（默认）、<code>'distance'</code> 或自定义函数</li>
<li><strong>作用</strong>：指定邻居样本的权重计算方式。</li>
<li><strong>说明</strong>：<ul>
<li><code>'uniform'</code>：所有邻居权重相同，直接按多数投票分类。</li>
<li><code>'distance'</code>：权重与距离成反比（距离越近权重越大），即 <code>weight = 1 / distance</code>。</li>
<li><code>callable</code>：自定义权重函数，输入距离数组，返回对应的权重数组。</li>
</ul>
</li>
</ul>
<h4 id="3-algorithm"><strong>3. </strong><code>algorithm</code><a class="headerlink" href="#3-algorithm" title="Permanent link">&para;</a></h4>
<ul>
<li><strong>类型</strong>：<code>str</code>，可选值 <code>'auto'</code>（默认）、<code>'ball_tree'</code>、<code>'kd_tree'</code>、<code>'brute'</code></li>
<li><strong>作用</strong>：指定计算最近邻的算法。</li>
<li><strong>说明</strong>：<ul>
<li><code>'auto'</code>：根据数据规模和维度自动选择（小数据用 <code>'brute'</code>，高维数据用树结构）。</li>
<li><code>'brute'</code>：暴力搜索（遍历所有样本计算距离），适用于低维小数据集。</li>
<li><code>'kd_tree'</code>/<code>'ball_tree'</code>：基于树结构的高效搜索（KD树适合低维数据，Ball树适合高维数据）。</li>
</ul>
</li>
</ul>
<h4 id="4-leaf_size"><strong>4. </strong><code>leaf_size</code><a class="headerlink" href="#4-leaf_size" title="Permanent link">&para;</a></h4>
<ul>
<li><strong>类型</strong>：<code>int</code>，默认值 <code>30</code></li>
<li><strong>作用</strong>：树结构（<code>kd_tree</code>/<code>ball_tree</code>）的叶节点大小。</li>
<li><strong>说明</strong>：<ul>
<li>叶节点越小，树结构越复杂，查询速度越快但内存占用更高；反之则相反。</li>
<li>仅在 <code>algorithm='kd_tree'</code> 或 <code>'ball_tree'</code> 时生效。</li>
</ul>
</li>
</ul>
<h4 id="5-p"><strong>5. </strong><code>p</code><a class="headerlink" href="#5-p" title="Permanent link">&para;</a></h4>
<ul>
<li><strong>类型</strong>：<code>int</code>，默认值 <code>2</code></li>
<li><strong>作用</strong>：Minkowski距离的幂次参数（仅当 <code>metric='minkowski'</code> 时生效）。</li>
<li><strong>说明</strong>：<ul>
<li><code>p=1</code>：等价于曼哈顿距离（L1距离）：<code>|x1 - x2| + |y1 - y2|</code>。</li>
<li><code>p=2</code>：等价于欧几里得距离（L2距离）：<code>√[(x1-x2)² + (y1-y2)²]</code>。</li>
<li><code>p&gt;2</code>：高阶 Minkowski 距离，如 <code>p=∞</code> 时接近切比雪夫距离。</li>
</ul>
</li>
</ul>
<h4 id="6-metric"><strong>6. </strong><code>metric</code><a class="headerlink" href="#6-metric" title="Permanent link">&para;</a></h4>
<ul>
<li><strong>类型</strong>：<code>str</code> 或 <code>callable</code>，默认值 <code>'minkowski'</code></li>
<li><strong>作用</strong>：指定距离度量方式。</li>
<li><strong>常用取值</strong>：<ul>
<li><code>'euclidean'</code>：欧几里得距离（等价于 <code>metric='minkowski'</code> 且 <code>p=2</code>）。</li>
<li><code>'manhattan'</code>：曼哈顿距离（等价于 <code>metric='minkowski'</code> 且 <code>p=1</code>）。</li>
<li><code>'chebyshev'</code>：切比雪夫距离（<code>max(|x1-x2|, |y1-y2|)</code>）。</li>
<li><code>'cosine'</code>：余弦相似度（常用于文本分类等稀疏数据）。</li>
<li><code>'precomputed'</code>：输入为预计算的距离矩阵（此时 <code>X</code> 需是 <code>n_samples x n_samples</code> 的距离矩阵）。</li>
</ul>
</li>
</ul>
<h4 id="7-metric_params"><strong>7. </strong><code>metric_params</code><a class="headerlink" href="#7-metric_params" title="Permanent link">&para;</a></h4>
<ul>
<li><strong>类型</strong>：<code>dict</code>，可选（默认 <code>None</code>）</li>
<li><strong>作用</strong>：传递给距离度量函数的额外参数（如自定义距离函数的参数）。</li>
</ul>
<h4 id="8-n_jobs"><strong>8. </strong><code>n_jobs</code><a class="headerlink" href="#8-n_jobs" title="Permanent link">&para;</a></h4>
<ul>
<li><strong>类型</strong>：<code>int</code>，可选（默认 <code>None</code>）</li>
<li><strong>作用</strong>：指定并行计算的线程数。</li>
<li><strong>说明</strong>：<ul>
<li><code>None</code>：使用1个线程；<code>-1</code>：使用所有可用CPU核心；<code>n</code>：使用 <code>n</code> 个核心。</li>
<li>加速邻居搜索和预测过程（训练阶段无并行）。</li>
</ul>
</li>
</ul>
<h4 id="_12"><strong>参数使用示例</strong><a class="headerlink" href="#_12" title="Permanent link">&para;</a></h4>
<div class="highlight"><pre><span></span><code>from sklearn.neighbors import KNeighborsClassifier

# 初始化模型：k=5，距离权重，欧几里得距离，并行计算
knn = KNeighborsClassifier(
    n_neighbors=5,
    weights=&#39;distance&#39;,
    metric=&#39;euclidean&#39;,
    n_jobs=-1
)
</code></pre></div>
<h4 id="_13"><strong>关键参数总结</strong><a class="headerlink" href="#_13" title="Permanent link">&para;</a></h4>
<ul>
<li><strong>核心调优参数</strong>：<code>n_neighbors</code>（k值）、<code>weights</code>（权重方式）、<code>metric</code>（距离度量）。</li>
<li><strong>效率相关参数</strong>：<code>algorithm</code>（搜索算法）、<code>leaf_size</code>（树结构参数）、<code>n_jobs</code>（并行）。</li>
</ul>
<p>根据数据规模（样本量、维度）和分布选择合适参数，通常需结合交叉验证优化。</p>
<h4 id="train_test_split">train_test_split  参数详解<a class="headerlink" href="#train_test_split" title="Permanent link">&para;</a></h4>
<p><code>train_test_split</code> 是 scikit-learn 库中用于将数据集分割成训练集和测试集的一个非常有用的函数。以下是该函数的主要参数及其详细说明：</p>
<ol>
<li>arrays: 这是一个位置参数，可以接受一个或多个数组-like 数据结构（如列表、NumPy 数组、Pandas DataFrame 或 Series）。这些数组应该具有相同的长度。</li>
<li>test_size: 测试集所占的比例，通常是介于 0 和 1 之间的浮点数。例如，<code>test_size=0.2</code> 表示 20% 的数据将被用作测试集。也可以指定为整数值，表示具体的样本数量。</li>
<li>train_size: 训练集所占的比例，通常也是介于 0 和 1 之间的浮点数。与 <code>test_size</code> 类似，也可以指定为整数值。注意，<code>train_size</code> 和 <code>test_size</code> 不能同时使用，除非它们的总和等于 1.</li>
<li>random_state: 控制随机种子的整数值，确保每次运行代码时都能得到相同的结果，从而保证结果的可重复性。</li>
<li>shuffle: 布尔值，默认为 True。如果设置为 False，则不打乱数据顺序直接按比例划分。</li>
<li>stratify: 指定分层抽样的依据列。当设置了 stratify 参数后，会按照该列的类别分布来进行数据划分，使得训练集和测试集中各类别的比例保持一致。这在处理不平衡数据集时特别有用。</li>
</ol>
<p>下面是一个简单的例子来演示如何使用 <code>train_test_split</code> 函数：</p>
<p><div class="highlight"><pre><span></span><code><span class="kn">from</span><span class="w"> </span><span class="nn">sklearn.model_selection</span><span class="w"> </span><span class="kn">import</span> <span class="n">train_test_split</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">np</span>
<span class="n">创建一些示例数据</span>
<span class="n">X</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">],</span> <span class="p">[</span><span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">],</span> <span class="p">[</span><span class="mi">5</span><span class="p">,</span> <span class="mi">6</span><span class="p">],</span> <span class="p">[</span><span class="mi">7</span><span class="p">,</span> <span class="mi">8</span><span class="p">]])</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">])</span>
<span class="n">使用</span> <span class="n">train_test_split</span> <span class="n">分割数据集</span>
<span class="n">X_train</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">y_test</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">test_size</span><span class="o">=</span><span class="mf">0.25</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Training features:</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">,</span> <span class="n">X_train</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Testing features:</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">,</span> <span class="n">X_test</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Training labels:</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Testing labels:</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">,</span> <span class="n">y_test</span><span class="p">)</span>
</code></pre></div>
在这个例子中，我们创建了一个简单的特征矩阵 <code>X</code> 和标签向量 <code>y</code>，然后使用 <code>train_test_split</code> 将其分为训练集和测试集，并指定了测试集占 25%，并且通过 <code>random_state</code> 来固定随机种子以获得可重复的结果。</p>
<h3 id="35-knn">3.5 KNN算法调优<a class="headerlink" href="#35-knn" title="Permanent link">&para;</a></h3>
<p>KNN算法的性能受K值和距离度量方法的影响。可以通过交叉验证和网格搜索等方法调优K值，选择最佳的距离度量方法（如欧氏距离、曼哈顿距离等）以提高模型性能。</p>
<div class="highlight"><pre><span></span><code><span class="kn">from</span><span class="w"> </span><span class="nn">sklearn.model_selection</span><span class="w"> </span><span class="kn">import</span> <span class="n">GridSearchCV</span>
<span class="c1"># 定义参数范围</span>
<span class="n">param_grid</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;n_neighbors&#39;</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">20</span><span class="p">)}</span>
<span class="c1"># 创建KNN模型</span>
<span class="n">knn</span> <span class="o">=</span> <span class="n">KNeighborsClassifier</span><span class="p">()</span>
<span class="c1"># 使用网格搜索进行参数调优</span>
<span class="n">grid_search</span> <span class="o">=</span> <span class="n">GridSearchCV</span><span class="p">(</span><span class="n">knn</span><span class="p">,</span> <span class="n">param_grid</span><span class="p">,</span> <span class="n">cv</span><span class="o">=</span><span class="mi">5</span><span class="p">)</span>
<span class="n">grid_search</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
<span class="c1"># 输出最佳参数</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Best parameters:&quot;</span><span class="p">,</span> <span class="n">grid_search</span><span class="o">.</span><span class="n">best_params_</span><span class="p">)</span>
<span class="c1"># 使用最佳参数训练模型</span>
<span class="n">best_knn</span> <span class="o">=</span> <span class="n">grid_search</span><span class="o">.</span><span class="n">best_estimator_</span>
<span class="n">best_knn</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
<span class="c1"># 预测</span>
<span class="n">y_pred</span> <span class="o">=</span> <span class="n">best_knn</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>
<span class="c1"># 评估模型</span>
<span class="nb">print</span><span class="p">(</span><span class="n">confusion_matrix</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="n">classification_report</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">))</span>
</code></pre></div>
<h3 id="36-knn">3.6 KNN算法扩展<a class="headerlink" href="#36-knn" title="Permanent link">&para;</a></h3>
<p>KNN算法可以与其他技术结合使用，如加权KNN（根据距离加权邻居的贡献）、局部敏感哈希（加速高维数据的邻居搜索）等，以提高算法的性能和适用性。    </p>
<h2 id="_14">四、线性回归算法<a class="headerlink" href="#_14" title="Permanent link">&para;</a></h2>
<h3 id="1_1">1. 原理<a class="headerlink" href="#1_1" title="Permanent link">&para;</a></h3>
<h4 id="11_1">1.1 基本概念<a class="headerlink" href="#11_1" title="Permanent link">&para;</a></h4>
<p>线性回归是一种用于建立自变量（特征）与因变量（目标）之间线性关系的统计学习方法。</p>
<h4 id="12_1">1.2 数学模型<a class="headerlink" href="#12_1" title="Permanent link">&para;</a></h4>
<p>简单线性回归公式：
$$ y = \beta_0 + \beta_1x + \epsilon $$</p>
<p>多元线性回归公式：
$$ y = \beta_0 + \beta_1x_1 + \beta_2x_2 + \cdots + \beta_nx_n + \epsilon $$</p>
<p>其中：</p>
<ul>
<li><span class="arithmatex">\(y\)</span> ：因变量（目标）</li>
<li><span class="arithmatex">\(x_i\)</span>：自变量（特征）</li>
<li>$ \beta_0 $：截距项</li>
<li>$\beta_i $：系数</li>
<li><span class="arithmatex">\(\epsilon\)</span>：误差项</li>
</ul>
<h4 id="13_1">1.3 最小二乘法<a class="headerlink" href="#13_1" title="Permanent link">&para;</a></h4>
<p>通过最小化残差平方和来估计参数：</p>
<div class="arithmatex">\[ \min \sum_{i=1}^{n}(y_i - \hat{y}_i)^2 \]</div>
<h3 id="2">2. 优缺点<a class="headerlink" href="#2" title="Permanent link">&para;</a></h3>
<h4 id="21_1">2.1 优点<a class="headerlink" href="#21_1" title="Permanent link">&para;</a></h4>
<ul>
<li><strong>简单易懂</strong>：模型直观，易于解释</li>
<li><strong>计算效率高</strong>：训练和预测速度快</li>
<li><strong>可解释性强</strong>：系数直接反映特征重要性</li>
<li><strong>理论基础扎实</strong>：有完善的统计理论支持</li>
</ul>
<h4 id="22_1">2.2 缺点<a class="headerlink" href="#22_1" title="Permanent link">&para;</a></h4>
<ul>
<li><strong>对非线性关系拟合差</strong>：只能捕捉线性关系</li>
<li><strong>对异常值敏感</strong>：异常值会显著影响模型</li>
<li><strong>假设条件严格</strong>：需要满足线性、独立性、同方差等假设</li>
<li><strong>多重共线性问题</strong>：特征高度相关时模型不稳定</li>
</ul>
<h3 id="3_1">3. 应用场景<a class="headerlink" href="#3_1" title="Permanent link">&para;</a></h3>
<ol>
<li><strong>房价预测</strong>：根据房屋特征预测价格</li>
<li><strong>销售预测</strong>：基于历史数据预测未来销量</li>
<li><strong>经济分析</strong>：分析经济指标之间的关系</li>
<li><strong>医学研究</strong>：研究风险因素与疾病的关系</li>
<li><strong>工业控制</strong>：工艺参数与产品质量的关系</li>
</ol>
<h3 id="4_1">4. 代码实现<a class="headerlink" href="#4_1" title="Permanent link">&para;</a></h3>
<h4 id="41-pythonscikit-learn">4.1 Python实现（使用scikit-learn）<a class="headerlink" href="#41-pythonscikit-learn" title="Permanent link">&para;</a></h4>
<div class="highlight"><pre><span></span><code><span class="kn">import</span><span class="w"> </span><span class="nn">numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">np</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">matplotlib.pyplot</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">plt</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">sklearn.linear_model</span><span class="w"> </span><span class="kn">import</span> <span class="n">LinearRegression</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">sklearn.model_selection</span><span class="w"> </span><span class="kn">import</span> <span class="n">train_test_split</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">sklearn.metrics</span><span class="w"> </span><span class="kn">import</span> <span class="n">mean_squared_error</span><span class="p">,</span> <span class="n">r2_score</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">sklearn.datasets</span><span class="w"> </span><span class="kn">import</span> <span class="n">make_regression</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">sklearn.preprocessing</span><span class="w"> </span><span class="kn">import</span> <span class="n">StandardScaler</span>

<span class="c1"># 生成示例数据</span>
<span class="n">X</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">make_regression</span><span class="p">(</span><span class="n">n_samples</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">n_features</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">noise</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">)</span>

<span class="c1"># 数据标准化</span>
<span class="n">scaler</span> <span class="o">=</span> <span class="n">StandardScaler</span><span class="p">()</span>
<span class="n">X_scaled</span> <span class="o">=</span> <span class="n">scaler</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>

<span class="c1"># 划分训练集和测试集</span>
<span class="n">X_train</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">y_test</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span><span class="n">X_scaled</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">test_size</span><span class="o">=</span><span class="mf">0.2</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">)</span>

<span class="c1"># 创建并训练模型</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">LinearRegression</span><span class="p">()</span>
<span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>

<span class="c1"># 预测</span>
<span class="n">y_pred</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>

<span class="c1"># 评估模型</span>
<span class="n">mse</span> <span class="o">=</span> <span class="n">mean_squared_error</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">)</span>
<span class="n">r2</span> <span class="o">=</span> <span class="n">r2_score</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;均方误差(MSE): </span><span class="si">{</span><span class="n">mse</span><span class="si">:</span><span class="s2">.2f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;R²分数: </span><span class="si">{</span><span class="n">r2</span><span class="si">:</span><span class="s2">.2f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;系数: </span><span class="si">{</span><span class="n">model</span><span class="o">.</span><span class="n">coef_</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;截距: </span><span class="si">{</span><span class="n">model</span><span class="o">.</span><span class="n">intercept_</span><span class="si">:</span><span class="s2">.2f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

<span class="c1"># 可视化结果</span>
<span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">6</span><span class="p">))</span>
<span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">X_test</span><span class="p">,</span> <span class="n">y_test</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;blue&#39;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;实际值&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">X_test</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;red&#39;</span><span class="p">,</span> <span class="n">linewidth</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;预测值&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;特征&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;目标&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39;线性回归结果&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</code></pre></div>
<h4 id="42">4.2 从零实现线性回归<a class="headerlink" href="#42" title="Permanent link">&para;</a></h4>
<div class="highlight"><pre><span></span><code><span class="kn">import</span><span class="w"> </span><span class="nn">numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">np</span>

<span class="k">class</span><span class="w"> </span><span class="nc">SimpleLinearRegression</span><span class="p">:</span>
    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">coef_</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">intercept_</span> <span class="o">=</span> <span class="kc">None</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">fit</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">):</span>
        <span class="c1"># 添加截距项</span>
        <span class="n">X</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">column_stack</span><span class="p">([</span><span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]),</span> <span class="n">X</span><span class="p">])</span>

        <span class="c1"># 使用正规方程求解</span>
        <span class="n">theta</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">inv</span><span class="p">(</span><span class="n">X</span><span class="o">.</span><span class="n">T</span> <span class="o">@</span> <span class="n">X</span><span class="p">)</span> <span class="o">@</span> <span class="n">X</span><span class="o">.</span><span class="n">T</span> <span class="o">@</span> <span class="n">y</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">intercept_</span> <span class="o">=</span> <span class="n">theta</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">coef_</span> <span class="o">=</span> <span class="n">theta</span><span class="p">[</span><span class="mi">1</span><span class="p">:]</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">predict</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">intercept_</span> <span class="o">+</span> <span class="n">X</span> <span class="o">@</span> <span class="bp">self</span><span class="o">.</span><span class="n">coef_</span>

<span class="c1"># 使用示例</span>
<span class="n">X</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="mi">1</span><span class="p">],</span> <span class="p">[</span><span class="mi">2</span><span class="p">],</span> <span class="p">[</span><span class="mi">3</span><span class="p">],</span> <span class="p">[</span><span class="mi">4</span><span class="p">],</span> <span class="p">[</span><span class="mi">5</span><span class="p">]])</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">2</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">6</span><span class="p">,</span> <span class="mi">8</span><span class="p">,</span> <span class="mi">10</span><span class="p">])</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">SimpleLinearRegression</span><span class="p">()</span>
<span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
<span class="n">predictions</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="mi">6</span><span class="p">]]))</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;预测结果: </span><span class="si">{</span><span class="n">predictions</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</code></pre></div>
<h3 id="5_1">5. 算法调优<a class="headerlink" href="#5_1" title="Permanent link">&para;</a></h3>
<h4 id="51">5.1 数据预处理<a class="headerlink" href="#51" title="Permanent link">&para;</a></h4>
<div class="highlight"><pre><span></span><code><span class="kn">from</span><span class="w"> </span><span class="nn">sklearn.preprocessing</span><span class="w"> </span><span class="kn">import</span> <span class="n">PolynomialFeatures</span><span class="p">,</span> <span class="n">StandardScaler</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">sklearn.pipeline</span><span class="w"> </span><span class="kn">import</span> <span class="n">Pipeline</span>

<span class="c1"># 创建数据处理管道</span>
<span class="n">pipeline</span> <span class="o">=</span> <span class="n">Pipeline</span><span class="p">([</span>
    <span class="p">(</span><span class="s1">&#39;scaler&#39;</span><span class="p">,</span> <span class="n">StandardScaler</span><span class="p">()),</span>
    <span class="p">(</span><span class="s1">&#39;poly&#39;</span><span class="p">,</span> <span class="n">PolynomialFeatures</span><span class="p">(</span><span class="n">degree</span><span class="o">=</span><span class="mi">2</span><span class="p">)),</span>  <span class="c1"># 添加多项式特征</span>
    <span class="p">(</span><span class="s1">&#39;model&#39;</span><span class="p">,</span> <span class="n">LinearRegression</span><span class="p">())</span>
<span class="p">])</span>

<span class="n">pipeline</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
</code></pre></div>
<h4 id="52">5.2 正则化方法<a class="headerlink" href="#52" title="Permanent link">&para;</a></h4>
<div class="highlight"><pre><span></span><code><span class="kn">from</span><span class="w"> </span><span class="nn">sklearn.linear_model</span><span class="w"> </span><span class="kn">import</span> <span class="n">Ridge</span><span class="p">,</span> <span class="n">Lasso</span><span class="p">,</span> <span class="n">ElasticNet</span>

<span class="c1"># 岭回归（L2正则化）</span>
<span class="n">ridge</span> <span class="o">=</span> <span class="n">Ridge</span><span class="p">(</span><span class="n">alpha</span><span class="o">=</span><span class="mf">1.0</span><span class="p">)</span>
<span class="n">ridge</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>

<span class="c1"># Lasso回归（L1正则化）</span>
<span class="n">lasso</span> <span class="o">=</span> <span class="n">Lasso</span><span class="p">(</span><span class="n">alpha</span><span class="o">=</span><span class="mf">0.1</span><span class="p">)</span>
<span class="n">lasso</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>

<span class="c1"># 弹性网络（L1+L2正则化）</span>
<span class="n">elastic_net</span> <span class="o">=</span> <span class="n">ElasticNet</span><span class="p">(</span><span class="n">alpha</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span> <span class="n">l1_ratio</span><span class="o">=</span><span class="mf">0.5</span><span class="p">)</span>
<span class="n">elastic_net</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
</code></pre></div>
<h4 id="53">5.3 交叉验证调优<a class="headerlink" href="#53" title="Permanent link">&para;</a></h4>
<div class="highlight"><pre><span></span><code><span class="kn">from</span><span class="w"> </span><span class="nn">sklearn.model_selection</span><span class="w"> </span><span class="kn">import</span> <span class="n">GridSearchCV</span>

<span class="c1"># 参数网格</span>
<span class="n">param_grid</span> <span class="o">=</span> <span class="p">{</span>
    <span class="s1">&#39;alpha&#39;</span><span class="p">:</span> <span class="p">[</span><span class="mf">0.001</span><span class="p">,</span> <span class="mf">0.01</span><span class="p">,</span> <span class="mf">0.1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">10</span><span class="p">,</span> <span class="mi">100</span><span class="p">],</span>
    <span class="s1">&#39;l1_ratio&#39;</span><span class="p">:</span> <span class="p">[</span><span class="mf">0.1</span><span class="p">,</span> <span class="mf">0.3</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">,</span> <span class="mf">0.7</span><span class="p">,</span> <span class="mf">0.9</span><span class="p">]</span>
<span class="p">}</span>

<span class="c1"># 网格搜索</span>
<span class="n">grid_search</span> <span class="o">=</span> <span class="n">GridSearchCV</span><span class="p">(</span><span class="n">ElasticNet</span><span class="p">(),</span> <span class="n">param_grid</span><span class="p">,</span> <span class="n">cv</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">scoring</span><span class="o">=</span><span class="s1">&#39;r2&#39;</span><span class="p">)</span>
<span class="n">grid_search</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;最佳参数: </span><span class="si">{</span><span class="n">grid_search</span><span class="o">.</span><span class="n">best_params_</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;最佳分数: </span><span class="si">{</span><span class="n">grid_search</span><span class="o">.</span><span class="n">best_score_</span><span class="si">:</span><span class="s2">.3f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</code></pre></div>
<h4 id="54">5.4 特征工程技巧<a class="headerlink" href="#54" title="Permanent link">&para;</a></h4>
<div class="highlight"><pre><span></span><code><span class="c1"># 1. 特征选择</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">sklearn.feature_selection</span><span class="w"> </span><span class="kn">import</span> <span class="n">SelectKBest</span><span class="p">,</span> <span class="n">f_regression</span>

<span class="n">selector</span> <span class="o">=</span> <span class="n">SelectKBest</span><span class="p">(</span><span class="n">score_func</span><span class="o">=</span><span class="n">f_regression</span><span class="p">,</span> <span class="n">k</span><span class="o">=</span><span class="mi">5</span><span class="p">)</span>
<span class="n">X_selected</span> <span class="o">=</span> <span class="n">selector</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>

<span class="c1"># 2. 异常值处理</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">scipy</span><span class="w"> </span><span class="kn">import</span> <span class="n">stats</span>
<span class="n">z_scores</span> <span class="o">=</span> <span class="n">stats</span><span class="o">.</span><span class="n">zscore</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
<span class="n">X_clean</span> <span class="o">=</span> <span class="n">X</span><span class="p">[(</span><span class="n">z_scores</span> <span class="o">&lt;</span> <span class="mi">3</span><span class="p">)</span><span class="o">.</span><span class="n">all</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)]</span>

<span class="c1"># 3. 交互特征</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">sklearn.preprocessing</span><span class="w"> </span><span class="kn">import</span> <span class="n">PolynomialFeatures</span>
<span class="n">poly</span> <span class="o">=</span> <span class="n">PolynomialFeatures</span><span class="p">(</span><span class="n">degree</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">interaction_only</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">X_interaction</span> <span class="o">=</span> <span class="n">poly</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
</code></pre></div>
<h4 id="55">5.5 模型诊断<a class="headerlink" href="#55" title="Permanent link">&para;</a></h4>
<div class="highlight"><pre><span></span><code><span class="kn">import</span><span class="w"> </span><span class="nn">seaborn</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">sns</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">scipy</span><span class="w"> </span><span class="kn">import</span> <span class="n">stats</span>

<span class="c1"># 残差分析</span>
<span class="n">residuals</span> <span class="o">=</span> <span class="n">y_test</span> <span class="o">-</span> <span class="n">y_pred</span>

<span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">12</span><span class="p">,</span> <span class="mi">4</span><span class="p">))</span>

<span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">y_pred</span><span class="p">,</span> <span class="n">residuals</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;预测值&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;残差&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39;残差图&#39;</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
<span class="n">stats</span><span class="o">.</span><span class="n">probplot</span><span class="p">(</span><span class="n">residuals</span><span class="p">,</span> <span class="n">dist</span><span class="o">=</span><span class="s2">&quot;norm&quot;</span><span class="p">,</span> <span class="n">plot</span><span class="o">=</span><span class="n">plt</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39;QQ图&#39;</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span>
<span class="n">sns</span><span class="o">.</span><span class="n">histplot</span><span class="p">(</span><span class="n">residuals</span><span class="p">,</span> <span class="n">kde</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39;残差分布&#39;</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">tight_layout</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</code></pre></div>
<h3 id="6">6. 最佳实践建议<a class="headerlink" href="#6" title="Permanent link">&para;</a></h3>
<ol>
<li><strong>数据质量优先</strong>：确保数据清洁，处理缺失值和异常值</li>
<li><strong>特征工程关键</strong>：合适的特征选择和处理能显著提升性能</li>
<li><strong>正则化应用</strong>：特别是当特征数量较多或存在多重共线性时</li>
<li><strong>模型验证</strong>：使用交叉验证确保模型泛化能力</li>
<li><strong>可解释性</strong>：利用线性回归的可解释性进行业务洞察</li>
</ol>
<h2 id="_15">四、逻辑回归算法<a class="headerlink" href="#_15" title="Permanent link">&para;</a></h2>
<p>逻辑回归（Logistic Regression）是一种广泛应用于分类任务的统计模型，特别适用于二分类问题。它通过估计事件发生的概率来进行分类决策。尽管名称中包含“回归”，但逻辑回归实际上是一种分类算法。</p>
<h3 id="41">4.1 逻辑回归算法原理<a class="headerlink" href="#41" title="Permanent link">&para;</a></h3>
<p>逻辑回归是一种广泛应用于二分类问题的监督学习算法，其核心原理包括以下几个关键部分：</p>
<ol>
<li>线性组合与Sigmoid函数<ul>
<li>线性组合：逻辑回归首先将输入特征进行线性组合，形成一个线性方程：<span class="arithmatex">\(z = w_1x_1 + w_2x_2 + \ldots + w_nx_n + b\)</span>，其中<span class="arithmatex">\(w_i\)</span>为权重，<span class="arithmatex">\(b\)</span>为偏置项，<span class="arithmatex">\(x_i\)</span>为输入特征。</li>
<li>Sigmoid函数：将线性组合的结果<span class="arithmatex">\(z\)</span>代入Sigmoid函数，将其映射到0到1之间的概率值：<span class="arithmatex">\(p = \frac{1}{1 + e^{-z}}\)</span>。<span class="arithmatex">\(p\)</span>表示样本属于正类的概率。</li>
</ul>
</li>
<li>决策边界与阈值<ul>
<li>决策边界：通过Sigmoid函数，逻辑回归定义了一个决策边界，通常是一个线性超平面，用于区分不同类别。</li>
<li>阈值设定：设定一个阈值（如0.5），当预测概率<span class="arithmatex">\(p\)</span>大于等于阈值时，判定为正类；否则为负类。</li>
</ul>
</li>
<li>损失函数与优化<ul>
<li>交叉熵损失：逻辑回归使用交叉熵损失函数衡量预测概率与真实标签的差异： $  L(y, \hat{y}) = -\frac{1}{N} \sum_{i=1}^{N} \left[ y_i \log(\hat{y}_i) + (1 - y_i) \log(1 - \hat{y}_i) \right]  $ </li>
<li>优化算法：通过梯度下降、牛顿法等优化算法，最小化损失函数，求解最优的权重<span class="arithmatex">\(w\)</span>和偏置<span class="arithmatex">\(b\)</span>。</li>
</ul>
</li>
<li>概率解释与模型评估<ul>
<li>概率输出：逻辑回归不仅输出类别预测，还提供概率估计，便于理解模型的置信度。</li>
<li>评估指标：使用准确率、精确率、召回率、F1分数、ROC曲线和AUC值等指标评估模型性能。</li>
</ul>
</li>
</ol>
<p>逻辑回归通过最大化似然函数来估计模型参数，常用的优化算法包括梯度下降和牛顿法。分类决策通常基于概率阈值（如0.5），即当 <span class="arithmatex">\(P(Y=1|X) &gt; 0.5\)</span> 时预测为正类，否则为负类。</p>
<h3 id="42_1">4.2 逻辑回归算法优缺点<a class="headerlink" href="#42_1" title="Permanent link">&para;</a></h3>
<h4 id="_16">优点<a class="headerlink" href="#_16" title="Permanent link">&para;</a></h4>
<ul>
<li>简单易懂，易于实现</li>
<li>计算效率高，适合大规模数据集</li>
<li>输出概率值，便于解释和理解</li>
<li>可以处理多分类问题（通过一对多或一对一策略）</li>
</ul>
<h4 id="_17">缺点<a class="headerlink" href="#_17" title="Permanent link">&para;</a></h4>
<ul>
<li>只能处理线性可分问题，非线性关系需特征工程</li>
<li>对异常值敏感，可能影响模型性能</li>
<li>需要较大的样本量以获得稳定的参数估计</li>
</ul>
<h3 id="43">4.3 逻辑回归算法应用场景<a class="headerlink" href="#43" title="Permanent link">&para;</a></h3>
<p>逻辑回归算法适用于以下场景：</p>
<ul>
<li>二分类任务，如垃圾邮件检测、疾病预测等</li>
<li>多分类任务，如手写数字识别、图像分类等</li>
<li>风险评估，如信用评分、欺诈检测等</li>
<li>市场营销，如客户流失预测、用户行为分析等 </li>
</ul>
<h3 id="44">4.4 逻辑回归算法实现<a class="headerlink" href="#44" title="Permanent link">&para;</a></h3>
<p>以下是使用Python和Scikit-learn库实现逻辑回归算法的示例代码：</p>
<div class="highlight"><pre><span></span><code><span class="kn">import</span><span class="w"> </span><span class="nn">numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">np</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">sklearn.model_selection</span><span class="w"> </span><span class="kn">import</span> <span class="n">train_test_split</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">sklearn.preprocessing</span><span class="w"> </span><span class="kn">import</span> <span class="n">StandardScaler</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">sklearn.linear_model</span><span class="w"> </span><span class="kn">import</span> <span class="n">LogisticRegression</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">sklearn.metrics</span><span class="w"> </span><span class="kn">import</span> <span class="n">classification_report</span><span class="p">,</span> <span class="n">confusion_matrix</span> 
<span class="kn">from</span><span class="w"> </span><span class="nn">sklearn.datasets</span><span class="w"> </span><span class="kn">import</span> <span class="n">load_iris</span>
<span class="c1"># 加载数据集</span>
<span class="n">data</span> <span class="o">=</span> <span class="n">load_iris</span><span class="p">()</span>
<span class="n">X</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">data</span>
<span class="n">y</span> <span class="o">=</span> <span class="p">(</span><span class="n">data</span><span class="o">.</span><span class="n">target</span> <span class="o">==</span> <span class="mi">2</span><span class="p">)</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="nb">int</span><span class="p">)</span>  <span class="c1"># 二分类任务，将类别2作为正类</span>
<span class="c1"># 划分训练集和测试集</span>
<span class="n">X_train</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">y_test</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">test_size</span><span class="o">=</span><span class="mf">0.2</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">)</span>
<span class="c1"># 数据标准化</span>
<span class="n">scaler</span> <span class="o">=</span> <span class="n">StandardScaler</span><span class="p">()</span>
<span class="n">X_train</span> <span class="o">=</span> <span class="n">scaler</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">X_train</span><span class="p">)</span>
<span class="n">X_test</span> <span class="o">=</span> <span class="n">scaler</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>
<span class="c1"># 创建逻辑回归模型</span>
<span class="n">log_reg</span> <span class="o">=</span> <span class="n">LogisticRegression</span><span class="p">()</span>
<span class="c1"># 训练模型</span>
<span class="n">log_reg</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
<span class="c1"># 预测</span>
<span class="n">y_pred</span> <span class="o">=</span> <span class="n">log_reg</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>
<span class="c1"># 评估模型</span>
<span class="nb">print</span><span class="p">(</span><span class="n">confusion_matrix</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="n">classification_report</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">))</span>
</code></pre></div>
<h4 id="_18">参数详解<a class="headerlink" href="#_18" title="Permanent link">&para;</a></h4>
<ol>
<li>penalty<ul>
<li>作用：指定正则化类型。</li>
<li>可选值：<code>'l1'</code>（L1正则化）、<code>'l2'</code>（L2正则化，默认值）、<code>'elasticnet'</code>（弹性网正则化）、<code>'none'</code>（无正则化）。</li>
<li>说明：<ul>
<li>L1正则化倾向于产生稀疏权重，适用于特征选择。</li>
<li>L2正则化能防止过拟合，适用于特征间存在相关性的情况。</li>
<li>弹性网正则化结合了L1和L2正则化。</li>
</ul>
</li>
</ul>
</li>
<li>C<ul>
<li>作用：正则化强度的倒数，值越小，正则化强度越大。</li>
<li>默认值：<code>1.0</code>。</li>
<li>取值范围：正浮点数。</li>
</ul>
</li>
<li>dual<ul>
<li>作用：选择求解原始问题还是对偶问题。</li>
<li>可选值：<code>True</code>或<code>False</code>（默认值）。</li>
<li>说明：仅当<code>penalty='l2'</code>且<code>solver='liblinear'</code>时有效。若样本数大于特征数，建议设为<code>False</code>。</li>
</ul>
</li>
<li>solver<ul>
<li>作用：选择优化算法。</li>
<li>可选值：<ul>
<li><code>'newton-cg'</code>：牛顿法。</li>
<li><code>'lbfgs'</code>：拟牛顿法（默认值）。</li>
<li><code>'liblinear'</code>：坐标下降法。</li>
<li><code>'sag'</code>：随机平均梯度下降法。</li>
<li><code>'saga'</code>：SAGA算法。</li>
</ul>
</li>
<li>说明：<ul>
<li><code>'liblinear'</code>适用于小数据集，支持L1正则化。</li>
<li><code>'sag'</code>和<code>'saga'</code>适用于大数据集。</li>
<li><code>'newton-cg'</code>、<code>'lbfgs'</code>仅支持L2正则化。</li>
</ul>
</li>
</ul>
</li>
<li>max_iter<ul>
<li>作用：最大迭代次数。</li>
<li>默认值：<code>100</code>。</li>
<li>说明：若模型未收敛，可适当增大该值。</li>
</ul>
</li>
<li>multi_class<ul>
<li>作用：多分类策略。</li>
<li>可选值：<ul>
<li><code>'ovr'</code>：一对其余（One-vs-Rest）。</li>
<li><code>'multinomial'</code>：多项式回归。</li>
<li><code>'auto'</code>：自动选择。</li>
</ul>
</li>
<li>说明：<code>'multinomial'</code>适用于多分类问题，需<code>solver</code>支持。</li>
</ul>
</li>
<li>class_weight<ul>
<li>作用：类别权重。</li>
<li>可选值：<ul>
<li><code>None</code>：所有类别的权重相同。</li>
<li><code>'balanced'</code>：自动调整权重以平衡类别频率。</li>
<li>字典：手动指定类别权重。</li>
</ul>
</li>
<li>说明：用于处理类别不平衡问题。</li>
</ul>
</li>
<li>fit_intercept<ul>
<li>作用：是否计算截距。</li>
<li>可选值：<code>True</code>（默认值）或<code>False</code>。</li>
<li>说明：若设为<code>False</code>，则模型不包含截距项。</li>
</ul>
</li>
<li>random_state<ul>
<li>作用：随机数生成器的种子。</li>
<li>默认值：<code>None</code>。</li>
<li>说明：用于保证结果的可重复性。</li>
</ul>
</li>
<li>tol<ul>
<li>作用：收敛阈值。</li>
<li>默认值：<code>1e-4</code>。</li>
<li>说明：当损失函数的变化小于该值时，停止迭代。</li>
</ul>
</li>
<li>warm_start<ul>
<li>作用：是否使用前一次训练的结果作为初始化。</li>
<li>可选值：<code>True</code>或<code>False</code>（默认值）。</li>
<li>说明：若设为<code>True</code>，可继续训练模型。</li>
</ul>
</li>
<li>n_jobs<ul>
<li>作用：并行计算的CPU数量。</li>
<li>默认值：<code>None</code>。</li>
<li>说明：若设为<code>-1</code>，则使用所有可用的CPU。
使用示例
<div class="highlight"><pre><span></span><code><span class="kn">from</span><span class="w"> </span><span class="nn">sklearn.linear_model</span><span class="w"> </span><span class="kn">import</span> <span class="n">LogisticRegression</span>
<span class="n">创建模型实例</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">LogisticRegression</span><span class="p">(</span>
    <span class="n">penalty</span><span class="o">=</span><span class="s1">&#39;l2&#39;</span><span class="p">,</span>          <span class="n">使用L2正则化</span>
    <span class="n">C</span><span class="o">=</span><span class="mf">1.0</span><span class="p">,</span>                 <span class="n">正则化强度</span>
    <span class="n">solver</span><span class="o">=</span><span class="s1">&#39;lbfgs&#39;</span><span class="p">,</span>        <span class="n">使用L</span><span class="o">-</span><span class="n">BFGS优化算法</span>
    <span class="n">max_iter</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span>          <span class="n">最大迭代次数</span>
    <span class="n">multi_class</span><span class="o">=</span><span class="s1">&#39;auto&#39;</span><span class="p">,</span>    <span class="n">自动选择多分类策略</span>
    <span class="n">class_weight</span><span class="o">=</span><span class="s1">&#39;balanced&#39;</span> <span class="n">平衡类别权重</span>
<span class="p">)</span>
<span class="n">训练模型</span>
<span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
<span class="n">预测</span>
<span class="n">y_pred</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>
</code></pre></div>
参数选择建议</li>
</ul>
</li>
<li>小数据集：使用<code>solver='liblinear'</code>或<code>'lbfgs'</code>。</li>
<li>大数据集：使用<code>solver='sag'</code>或<code>'saga'</code>。</li>
<li>特征选择：使用<code>penalty='l1'</code>。</li>
<li>类别不平衡：设置<code>class_weight='balanced'</code>或手动指定权重。
通过合理设置这些参数，可以优化模型的性能和泛化能力。</li>
</ol>
<h3 id="45">4.5 逻辑回归算法调优<a class="headerlink" href="#45" title="Permanent link">&para;</a></h3>
<p>逻辑回归算法的性能受正则化参数和特征选择的影响。可以通过交叉验证和网格搜索等方法调优正则化参数（如L1、L2正则化），选择最佳的特征子集以提高模型性能。    </p>
<div class="highlight"><pre><span></span><code><span class="kn">from</span><span class="w"> </span><span class="nn">sklearn.model_selection</span><span class="w"> </span><span class="kn">import</span> <span class="n">GridSearchCV</span>
<span class="c1"># 定义参数范围</span>
<span class="n">param_grid</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;C&#39;</span><span class="p">:</span> <span class="p">[</span><span class="mf">0.01</span><span class="p">,</span> <span class="mf">0.1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">10</span><span class="p">,</span> <span class="mi">100</span><span class="p">],</span> <span class="s1">&#39;penalty&#39;</span><span class="p">:</span> <span class="p">[</span><span class="s1">&#39;l1&#39;</span><span class="p">,</span> <span class="s1">&#39;l2&#39;</span><span class="p">]}</span>
<span class="c1"># 创建逻辑回归模型</span>
<span class="n">log_reg</span> <span class="o">=</span> <span class="n">LogisticRegression</span><span class="p">(</span><span class="n">solver</span><span class="o">=</span><span class="s1">&#39;liblinear&#39;</span><span class="p">)</span>  <span class="c1"># &#39;liblinear&#39; 支持 L1 正则化</span>
<span class="c1"># 使用网格搜索进行参数调优</span>
<span class="n">grid_search</span> <span class="o">=</span> <span class="n">GridSearchCV</span><span class="p">(</span><span class="n">log_reg</span><span class="p">,</span> <span class="n">param_grid</span><span class="p">,</span> <span class="n">cv</span><span class="o">=</span><span class="mi">5</span><span class="p">)</span>
<span class="n">grid_search</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
<span class="c1"># 输出最佳参数</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Best parameters:&quot;</span><span class="p">,</span> <span class="n">grid_search</span><span class="o">.</span><span class="n">best_params_</span><span class="p">)</span>
<span class="c1"># 使用最佳参数训练模型</span>
<span class="n">best_log_reg</span> <span class="o">=</span> <span class="n">grid_search</span><span class="o">.</span><span class="n">best_estimator_</span>
<span class="n">best_log_reg</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
<span class="c1"># 预测</span>
<span class="n">y_pred</span> <span class="o">=</span> <span class="n">best_log_reg</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>
<span class="c1"># 评估模型</span>

<span class="nb">print</span><span class="p">(</span><span class="n">confusion_matrix</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">))</span> 
<span class="nb">print</span><span class="p">(</span><span class="n">classification_report</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">))</span>
</code></pre></div>
<h3 id="46">4.6 逻辑回归算法扩展<a class="headerlink" href="#46" title="Permanent link">&para;</a></h3>
<p>逻辑回归算法可以与其他技术结合使用，如多项式逻辑回归（处理非线性关系）、正则化技术（防止过拟合）等，以提高算法的性能和适用性。</p>
<h2 id="_19">五、朴素贝叶斯算法<a class="headerlink" href="#_19" title="Permanent link">&para;</a></h2>
<p>朴素贝叶斯（Naive Bayes）算法是一种基于贝叶斯定理的概率分类算法，适用于文本分类、垃圾邮件检测等任务。其核心思想是假设特征之间相互独立，从而简化计算过程。</p>
<h3 id="51_1">5.1 朴素贝叶斯算法原理<a class="headerlink" href="#51_1" title="Permanent link">&para;</a></h3>
<p>朴素贝叶斯算法是一种基于贝叶斯定理和特征条件独立假设的分类算法。</p>
<h4 id="_20">贝叶斯定理<a class="headerlink" href="#_20" title="Permanent link">&para;</a></h4>
<p>贝叶斯定理描述了在已知相关证据下，事件发生的概率，公式为：</p>
<div class="arithmatex">\[P(Y|X) = \frac{P(X|Y) \cdot P(Y)}{P(X)}\]</div>
<p>其中：</p>
<ul>
<li><span class="arithmatex">\(P(Y)\)</span>：先验概率，类别<span class="arithmatex">\(Y\)</span>的初始概率。</li>
<li><span class="arithmatex">\(P(X|Y)\)</span>：似然概率，给定类别<span class="arithmatex">\(Y\)</span>时特征<span class="arithmatex">\(X\)</span>出现的概率。</li>
<li><span class="arithmatex">\(P(X)\)</span>：证据概率，特征<span class="arithmatex">\(X\)</span>出现的总概率。</li>
<li><span class="arithmatex">\(P(Y|X)\)</span>：后验概率，给定特征<span class="arithmatex">\(X\)</span>时类别<span class="arithmatex">\(Y\)</span>的概率。</li>
</ul>
<h6 id="1_2">1. 疾病诊断<a class="headerlink" href="#1_2" title="Permanent link">&para;</a></h6>
<p>背景：某罕见疾病的患病率为1%（先验概率<span class="arithmatex">\(P(患病)=0.01\)</span>）。检测方法的准确率为：</p>
<ul>
<li>患病者检测阳性的概率（似然<span class="arithmatex">\(P(阳性|患病)=0.99\)</span>）。</li>
<li>未患病者检测阳性的概率（<span class="arithmatex">\(P(阳性|未患病)=0.05\)</span>）。</li>
</ul>
<p>问题：若某人检测阳性，实际患病的概率是多少（后验概率<span class="arithmatex">\(P(患病|阳性)\)</span>）？</p>
<p>计算：</p>
<ul>
<li>全概率公式计算<span class="arithmatex">\(P(阳性)\)</span>：</li>
</ul>
<div class="arithmatex">\[
P(阳性) = P(阳性|患病) \cdot P(患病) + P(阳性|未患病) \cdot P(未患病) = 0.99 \times 0.01 + 0.05 \times 0.99 = 0.0594
\]</div>
<ul>
<li>应用贝叶斯定理：</li>
</ul>
<div class="arithmatex">\[
P(患病|阳性) = \frac{P(阳性|患病) \cdot P(患病)}{P(阳性)} = \frac{0.99 \times 0.01}{0.0594} \approx 16.7\%
\]</div>
<p>结论：检测阳性后，实际患病概率约为16.7%，说明罕见病的阳性检测可能存在较高误诊率。</p>
<h6 id="2_1">2. 垃圾邮件过滤<a class="headerlink" href="#2_1" title="Permanent link">&para;</a></h6>
<p>背景：已知垃圾邮件占邮件总数的30%（<span class="arithmatex">\(P(垃圾邮件)=0.3\)</span>）。特征词“免费”在垃圾邮件中出现的概率为50%（<span class="arithmatex">\(P(免费|垃圾邮件)=0.5\)</span>），在正常邮件中出现的概率为5%（<span class="arithmatex">\(P(免费|正常邮件)=0.05\)</span>）。
问题：若某邮件包含“免费”，它是垃圾邮件的概率是多少？</p>
<p>计算：</p>
<ul>
<li>计算<span class="arithmatex">\(P(免费)\)</span>：</li>
</ul>
<div class="arithmatex">\[
P(免费) = P(免费|垃圾邮件) \cdot P(垃圾邮件) + P(免费|正常邮件) \cdot P(正常邮件) = 0.5 \times 0.3 + 0.05 \times 0.7 = 0.185
\]</div>
<ul>
<li>应用贝叶斯定理：</li>
</ul>
<div class="arithmatex">\[
P(垃圾邮件|免费) = \frac{P(免费|垃圾邮件) \cdot P(垃圾邮件)}{P(免费)} = \frac{0.5 \times 0.3}{0.185} \approx 81.1\%
\]</div>
<p>结论：包含“免费”的邮件有81.1%的概率是垃圾邮件，有助于分类决策。</p>
<p>通过以上例子，可以看出贝叶斯定理如何通过先验概率和新证据，更新对事件概率的判断，从而在实际问题中做出更准确的决策。</p>
<h5 id="_21">特征条件独立假设<a class="headerlink" href="#_21" title="Permanent link">&para;</a></h5>
<p>算法假设所有特征在给定类别下相互独立，即：</p>
<div class="arithmatex">\[P(X|Y) = P(x_1|Y) \cdot P(x_2|Y) \cdot \ldots \cdot P(x_n|Y)\]</div>
<p>这一假设简化了计算，但现实中特征往往存在依赖关系。</p>
<h5 id="_22">算法步骤<a class="headerlink" href="#_22" title="Permanent link">&para;</a></h5>
<ol>
<li>计算先验概率：统计训练数据中每个类别的频率，得到<span class="arithmatex">\(P(Y)\)</span>。</li>
<li>计算条件概率：对每个类别<span class="arithmatex">\(Y\)</span>，计算每个特征<span class="arithmatex">\(X\)</span>的条件概率<span class="arithmatex">\(P(X|Y)\)</span>。</li>
<li>计算后验概率：利用贝叶斯定理，结合先验概率和条件概率，计算给定特征下每个类别的后验概率<span class="arithmatex">\(P(Y|X)\)</span>。</li>
<li>分类决策：选择后验概率最大的类别作为预测结果。</li>
</ol>
<h3 id="52_1">5.2 朴素贝叶斯算法优缺点<a class="headerlink" href="#52_1" title="Permanent link">&para;</a></h3>
<h4 id="_23">优点<a class="headerlink" href="#_23" title="Permanent link">&para;</a></h4>
<ul>
<li>简单易懂，易于实现</li>
<li>计算效率高，适合大规模数据集</li>
<li>对小样本数据表现良好</li>
<li>能处理多分类问题</li>
</ul>
<h4 id="_24">缺点<a class="headerlink" href="#_24" title="Permanent link">&para;</a></h4>
<ul>
<li>假设特征独立，实际应用中可能不成立</li>
<li>对零概率问题敏感，需使用平滑技术</li>
<li>不能捕捉特征之间的复杂关系</li>
</ul>
<h3 id="53_1">5.3 朴素贝叶斯算法应用场景<a class="headerlink" href="#53_1" title="Permanent link">&para;</a></h3>
<p>朴素贝叶斯算法适用于以下场景：</p>
<ul>
<li>文本分类，如垃圾邮件检测、情感分析等</li>
<li>医疗诊断，如疾病预测等</li>
<li>市场营销，如客户细分、用户行为分析等</li>
<li>推荐系统，如电影推荐、商品推荐等  </li>
</ul>
<h3 id="54_1">5.4 朴素贝叶斯算法实现<a class="headerlink" href="#54_1" title="Permanent link">&para;</a></h3>
<p>以下是使用Python和Scikit-learn库实现朴素贝叶斯算法的示例代码：</p>
<div class="highlight"><pre><span></span><code><span class="kn">import</span><span class="w"> </span><span class="nn">numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">np</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">sklearn.model_selection</span><span class="w"> </span><span class="kn">import</span> <span class="n">train_test_split</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">sklearn.preprocessing</span><span class="w"> </span><span class="kn">import</span> <span class="n">StandardScaler</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">sklearn.naive_bayes</span><span class="w"> </span><span class="kn">import</span> <span class="n">GaussianNB</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">sklearn.metrics</span><span class="w"> </span><span class="kn">import</span> <span class="n">classification_report</span><span class="p">,</span> <span class="n">confusion_matrix</span> 
<span class="kn">from</span><span class="w"> </span><span class="nn">sklearn.datasets</span><span class="w"> </span><span class="kn">import</span> <span class="n">load_iris</span>
<span class="c1"># 加载数据集</span>
<span class="n">data</span> <span class="o">=</span> <span class="n">load_iris</span><span class="p">()</span>
<span class="n">X</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">data</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">target</span>
<span class="c1"># 划分训练集和测试集</span>
<span class="n">X_train</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">y_test</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">test_size</span><span class="o">=</span><span class="mf">0.2</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">)</span>
<span class="c1"># 数据标准化</span>
<span class="n">scaler</span> <span class="o">=</span> <span class="n">StandardScaler</span><span class="p">()</span>
<span class="n">X_train</span> <span class="o">=</span> <span class="n">scaler</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">X_train</span><span class="p">)</span>
<span class="n">X_test</span> <span class="o">=</span> <span class="n">scaler</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>
<span class="c1"># 创建朴素贝叶斯模型</span>
<span class="n">nb</span> <span class="o">=</span> <span class="n">GaussianNB</span><span class="p">()</span>
<span class="c1"># 训练模型</span>
<span class="n">nb</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
<span class="c1"># 预测</span>
<span class="n">y_pred</span> <span class="o">=</span> <span class="n">nb</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>
<span class="c1"># 评估模型</span>
<span class="nb">print</span><span class="p">(</span><span class="n">confusion_matrix</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="n">classification_report</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">))</span>
</code></pre></div>
<h3 id="55_1">5.5 朴素贝叶斯算法调优<a class="headerlink" href="#55_1" title="Permanent link">&para;</a></h3>
<p>朴素贝叶斯算法的性能受特征选择和数据预处理的影响。可以通过选择相关特征、处理缺失值和异常值等方法提高模型性能。</p>
<div class="highlight"><pre><span></span><code><span class="kn">from</span><span class="w"> </span><span class="nn">sklearn.feature_selection</span><span class="w"> </span><span class="kn">import</span> <span class="n">SelectKBest</span><span class="p">,</span> <span class="n">chi2</span>
<span class="c1"># 特征选择</span>
<span class="n">selector</span> <span class="o">=</span> <span class="n">SelectKBest</span><span class="p">(</span><span class="n">chi2</span><span class="p">,</span> <span class="n">k</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>  <span class="c1"># 选择前2个最佳特征</span>
<span class="n">X_train_selected</span> <span class="o">=</span> <span class="n">selector</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
<span class="n">X_test_selected</span> <span class="o">=</span> <span class="n">selector</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>
<span class="c1"># 使用选择的特征训练模型</span>
<span class="n">nb</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train_selected</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
<span class="c1"># 预测</span>
<span class="n">y_pred</span> <span class="o">=</span> <span class="n">nb</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test_selected</span><span class="p">)</span>
<span class="c1"># 评估模型</span>
<span class="nb">print</span><span class="p">(</span><span class="n">confusion_matrix</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="n">classification_report</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">))</span>
</code></pre></div>
<p><code>SelectKBest</code>和<code>chi2</code>是scikit-learn库中用于特征选择的重要工具，主要用于从数据集中选择与目标变量最相关的K个特征。</p>
<h5 id="selectkbest">SelectKBest<a class="headerlink" href="#selectkbest" title="Permanent link">&para;</a></h5>
<ul>
<li>功能：<code>SelectKBest</code>是一个基于统计度量的单变量特征选择类，它选择与目标变量最相关的K个特征。</li>
<li>参数：<ul>
<li><code>score_func</code>：用于评估特征相关性的函数，如卡方检验（<code>chi2</code>）、F检验（<code>f_classif</code>）、互信息（<code>mutual_info_classif</code>）等。</li>
<li><code>k</code>：要选择的特征数量。</li>
</ul>
</li>
<li>用法：
    <div class="highlight"><pre><span></span><code><span class="kn">from</span><span class="w"> </span><span class="nn">sklearn.feature_selection</span><span class="w"> </span><span class="kn">import</span> <span class="n">SelectKBest</span>
<span class="n">使用卡方检验作为评估函数</span><span class="err">，</span><span class="n">选择前K个最佳特征</span>
<span class="n">selector</span> <span class="o">=</span> <span class="n">SelectKBest</span><span class="p">(</span><span class="n">score_func</span><span class="o">=</span><span class="n">chi2</span><span class="p">,</span> <span class="n">k</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>
<span class="n">X_new</span> <span class="o">=</span> <span class="n">selector</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
</code></pre></div></li>
</ul>
<h5 id="chi2">chi2<a class="headerlink" href="#chi2" title="Permanent link">&para;</a></h5>
<ul>
<li>功能：<code>chi2</code>函数用于计算特征与目标变量之间的卡方统计量和p值，适用于分类问题，要求特征值为非负数。</li>
<li>输出：返回每个特征的卡方统计量和p值，卡方统计量越大，表示特征与目标变量的相关性越强。</li>
<li>用法：
    <div class="highlight"><pre><span></span><code><span class="kn">from</span><span class="w"> </span><span class="nn">sklearn.feature_selection</span><span class="w"> </span><span class="kn">import</span> <span class="n">chi2</span>
<span class="n">scores</span><span class="p">,</span> <span class="n">pvalues</span> <span class="o">=</span> <span class="n">chi2</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
</code></pre></div></li>
</ul>
<h5 id="_25">示例<a class="headerlink" href="#_25" title="Permanent link">&para;</a></h5>
<div class="highlight"><pre><span></span><code><span class="kn">from</span><span class="w"> </span><span class="nn">sklearn.datasets</span><span class="w"> </span><span class="kn">import</span> <span class="n">load_iris</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">sklearn.feature_selection</span><span class="w"> </span><span class="kn">import</span> <span class="n">SelectKBest</span><span class="p">,</span> <span class="n">chi2</span>
<span class="n">加载数据</span>
<span class="n">iris</span> <span class="o">=</span> <span class="n">load_iris</span><span class="p">()</span>
<span class="n">X</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">iris</span><span class="o">.</span><span class="n">data</span><span class="p">,</span> <span class="n">iris</span><span class="o">.</span><span class="n">target</span>
<span class="n">使用SelectKBest和chi2选择前2个最佳特征</span>
<span class="n">selector</span> <span class="o">=</span> <span class="n">SelectKBest</span><span class="p">(</span><span class="n">score_func</span><span class="o">=</span><span class="n">chi2</span><span class="p">,</span> <span class="n">k</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
<span class="n">X_new</span> <span class="o">=</span> <span class="n">selector</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
<span class="n">输出所选特征的索引</span>
<span class="n">selected_features</span> <span class="o">=</span> <span class="n">selector</span><span class="o">.</span><span class="n">get_support</span><span class="p">(</span><span class="n">indices</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Selected features indices:&quot;</span><span class="p">,</span> <span class="n">selected_features</span><span class="p">)</span>
</code></pre></div>
<h6 id="_26">注意事项<a class="headerlink" href="#_26" title="Permanent link">&para;</a></h6>
<ul>
<li>数据预处理：在使用<code>chi2</code>之前，确保特征值为非负数，可能需要进行标准化或离散化处理。</li>
<li>特征相关性：<code>SelectKBest</code>基于单变量统计度量，可能忽略特征之间的交互作用。</li>
<li>K值选择：通过交叉验证或可视化得分曲线确定最佳的K值。</li>
</ul>
<p>通过合理使用<code>SelectKBest</code>和<code>chi2</code>，可以有效降低数据维度，提高模型训练效率和预测性能。</p>
<h3 id="56">5.6 朴素贝叶斯算法扩展<a class="headerlink" href="#56" title="Permanent link">&para;</a></h3>
<p>朴素贝叶斯算法可以与其他技术结合使用，如多项式朴素贝叶斯（处理文本数据）、贝叶斯网络（捕捉特征之间的关系）等，以提高算法的性能和适用性。      </p>
<h2 id="_27">六、决策树模型<a class="headerlink" href="#_27" title="Permanent link">&para;</a></h2>
<p>决策树（Decision Tree）是一种基于树形结构的监督学习算法，适用于分类和回归任务。其核心思想是通过一系列的决策规则将数据划分为不同的类别或数值范围。</p>
<h3 id="61">6.1 决策树模型原理<a class="headerlink" href="#61" title="Permanent link">&para;</a></h3>
<p>决策树模型是一种基于树状结构的监督学习算法，用于分类和回归任务。其原理主要包括以下步骤：</p>
<h5 id="_28">模型结构<a class="headerlink" href="#_28" title="Permanent link">&para;</a></h5>
<ul>
<li>根节点：树的起点，包含所有样本数据，是第一个特征判断的起点。</li>
<li>内部节点：表示对某个特征的判断条件，每个内部节点会根据特征值分裂为多个子节点。</li>
<li>分支：连接节点的线段，代表特征判断的结果。</li>
<li>叶子节点：树的终点，输出最终的预测结果。</li>
</ul>
<h5 id="_29">特征选择<a class="headerlink" href="#_29" title="Permanent link">&para;</a></h5>
<ul>
<li>目标：选择最优特征进行节点分裂，以提高子节点的纯度。</li>
<li>衡量指标：<ul>
<li>信息熵：度量数据集的不确定性，熵值越低，纯度越高。</li>
<li>信息增益：基于熵的计算，选择信息增益最大的特征进行分裂。</li>
<li>基尼指数：衡量数据集的不纯度，基尼指数越小，纯度越高。</li>
</ul>
</li>
</ul>
<h6 id="entropy">信息熵（Entropy）<a class="headerlink" href="#entropy" title="Permanent link">&para;</a></h6>
<ul>
<li>定义：信息熵是度量样本集合纯度的指标，表示数据的混乱程度。熵值越小，数据纯度越高。</li>
<li>公式：<ul>
<li><span class="arithmatex">\(Ent(D) = -\sum_{k=1}^{|y|} p_k \log_2 p_k\)</span></li>
<li>其中，<span class="arithmatex">\(p_k\)</span>是样本集合<span class="arithmatex">\(D\)</span>中第<span class="arithmatex">\(k\)</span>类样本所占的比例。</li>
</ul>
</li>
<li>作用：在决策树算法中，信息熵用于计算节点的纯度，选择最优特征进行划分。</li>
</ul>
<h6 id="information-gain">信息增益（Information Gain）<a class="headerlink" href="#information-gain" title="Permanent link">&para;</a></h6>
<ul>
<li>定义：信息增益是使用某个特征对数据集进行划分后，信息熵的减少量。信息增益越大，说明该特征对分类的贡献越大。</li>
<li>公式：<ul>
<li><span class="arithmatex">\(Gain(D, a) = Ent(D) - \sum_{v=1}^{V} \frac{|D^v|}{|D|} Ent(D^v)\)</span></li>
<li>其中，<span class="arithmatex">\(a\)</span>是特征，<span class="arithmatex">\(V\)</span>是特征<span class="arithmatex">\(a\)</span>的可能取值个数，<span class="arithmatex">\(D^v\)</span>是特征<span class="arithmatex">\(a\)</span>取值为<span class="arithmatex">\(v\)</span>的样本子集。</li>
</ul>
</li>
<li>作用：在ID3决策树算法中，选择信息增益最大的特征作为划分依据。</li>
</ul>
<h6 id="gini-index">基尼指数（Gini Index）<a class="headerlink" href="#gini-index" title="Permanent link">&para;</a></h6>
<ul>
<li>定义：基尼指数是度量数据集不纯度的指标，表示从数据集中随机抽取两个样本类别标记不一致的概率。基尼指数越小，数据纯度越高。</li>
<li>公式：<ul>
<li><span class="arithmatex">\(Gini(D) = 1 - \sum_{k=1}^{|y|} p_k^2\)</span></li>
<li>其中，<span class="arithmatex">\(p_k\)</span>是样本集合<span class="arithmatex">\(D\)</span>中第<span class="arithmatex">\(k\)</span>类样本所占的比例。</li>
</ul>
</li>
<li>作用：在CART（分类与回归树）决策树算法中，选择基尼指数最小的特征进行划分。</li>
</ul>
<h6 id="_30">总结<a class="headerlink" href="#_30" title="Permanent link">&para;</a></h6>
<ul>
<li>信息熵和基尼指数：都是衡量数据纯度的指标，值越小，纯度越高<dfn seq=source_group_web_10 type=source_group_pro>8。</li>
<li>信息增益：用于衡量特征划分对纯度提升的效果，值越大，特征的分类能力越强。</li>
<li>应用场景：<ul>
<li>ID3算法：使用信息增益选择特征。</li>
<li>C4.5算法：使用信息增益率（信息增益与特征固有值的比值）选择特征。</li>
<li>CART算法：使用基尼指数选择特征。</li>
</ul>
</li>
</ul>
<h5 id="_31">树的生成<a class="headerlink" href="#_31" title="Permanent link">&para;</a></h5>
<ol>
<li>初始节点：将所有样本视为初始节点。</li>
<li>最优分割：计算每个特征的最优分割点，选择提升纯度最大的分割方式。</li>
<li>递归分裂：根据最优分割点将数据集划分为子集，递归地对子集重复上述过程。</li>
<li>停止条件：当子节点足够“纯”或满足预设条件（如达到最大深度、样本数小于阈值）时停止分裂。</li>
</ol>
<h5 id="_32">剪枝处理<a class="headerlink" href="#_32" title="Permanent link">&para;</a></h5>
<ul>
<li>目的：防止过拟合，提高模型泛化能力。</li>
<li>方法：<ul>
<li>预剪枝：在树的生长过程中设定指标，达到指标时停止生长。</li>
<li>后剪枝：先充分生长，再合并相邻叶节点，减少树的复杂度。</li>
</ul>
</li>
</ul>
<p>决策树模型通过递归地选择最优特征进行分裂，构建树状结构，实现对数据的分类或回归。其优点是易于理解和解释，但对连续字段和时间序列数据处理能力较弱。</p>
<h3 id="62">6.2 决策树模型优缺点<a class="headerlink" href="#62" title="Permanent link">&para;</a></h3>
<h4 id="_33">优点<a class="headerlink" href="#_33" title="Permanent link">&para;</a></h4>
<ul>
<li>易于理解和解释，直观展示决策过程</li>
<li>计算效率高，适合大规模数据集</li>
<li>能处理多分类问题</li>
<li>能处理缺失值和异常值</li>
<li>可处理数值型和类别型特征</li>
</ul>
<h4 id="_34">缺点<a class="headerlink" href="#_34" title="Permanent link">&para;</a></h4>
<ul>
<li>容易过拟合，需剪枝等技术防止</li>
<li>对噪声敏感，可能影响模型性能</li>
<li>不能捕捉特征之间的复杂关系</li>
<li>决策边界为轴平行，可能不适合某些数据分布</li>
</ul>
<h3 id="63">6.3 决策树模型应用场景<a class="headerlink" href="#63" title="Permanent link">&para;</a></h3>
<p>决策树模型适用于以下场景：</p>
<ul>
<li>分类任务，如客户细分、信用评分等</li>
<li>回归任务，如房价预测、销售预测等</li>
<li>风险评估，如欺诈检测、信用风险评估等</li>
<li>医疗诊断，如疾病预测等</li>
<li>市场营销，如用户行为分析、客户流失预测等  </li>
</ul>
<h3 id="64">6.4 决策树模型实现<a class="headerlink" href="#64" title="Permanent link">&para;</a></h3>
<p>以下是使用Python和Scikit-learn库实现决策树模型的示例代码：
<div class="highlight"><pre><span></span><code><span class="kn">import</span><span class="w"> </span><span class="nn">numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">np</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">sklearn.model_selection</span><span class="w"> </span><span class="kn">import</span> <span class="n">train_test_split</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">sklearn.preprocessing</span><span class="w"> </span><span class="kn">import</span> <span class="n">StandardScaler</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">sklearn.tree</span><span class="w"> </span><span class="kn">import</span> <span class="n">DecisionTreeClassifier</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">sklearn.metrics</span><span class="w"> </span><span class="kn">import</span> <span class="n">classification_report</span><span class="p">,</span> <span class="n">confusion_matrix</span> 
<span class="kn">from</span><span class="w"> </span><span class="nn">sklearn.datasets</span><span class="w"> </span><span class="kn">import</span> <span class="n">load_iris</span>
<span class="c1"># 加载数据集</span>
<span class="n">data</span> <span class="o">=</span> <span class="n">load_iris</span><span class="p">()</span>
<span class="n">X</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">data</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">target</span>
<span class="c1"># 划分训练集和测试集</span>
<span class="n">X_train</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">y_test</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">test_size</span><span class="o">=</span><span class="mf">0.2</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">)</span>
<span class="c1"># 数据标准化</span>
<span class="n">scaler</span> <span class="o">=</span> <span class="n">StandardScaler</span><span class="p">()</span>  
<span class="n">X_train</span> <span class="o">=</span> <span class="n">scaler</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">X_train</span><span class="p">)</span>
<span class="n">X_test</span> <span class="o">=</span> <span class="n">scaler</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>   
<span class="c1"># 创建决策树模型</span>
<span class="n">dt</span> <span class="o">=</span> <span class="n">DecisionTreeClassifier</span><span class="p">()</span>
<span class="c1"># 训练模型</span>
<span class="n">dt</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
<span class="c1"># 预测</span>
<span class="n">y_pred</span> <span class="o">=</span> <span class="n">dt</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>
<span class="c1"># 评估模型</span>
<span class="nb">print</span><span class="p">(</span><span class="n">confusion_matrix</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="n">classification_report</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">))</span>
</code></pre></div></p>
<h3 id="65">6.5 决策树模型调优<a class="headerlink" href="#65" title="Permanent link">&para;</a></h3>
<p>决策树模型的性能受树的深度和划分标准的影响。可以通过交叉验证和网格搜索等方法调优树的深度、最小样本分裂数等参数，以提高模型性能。
<div class="highlight"><pre><span></span><code><span class="kn">from</span><span class="w"> </span><span class="nn">sklearn.model_selection</span><span class="w"> </span><span class="kn">import</span> <span class="n">GridSearchCV</span>
<span class="c1"># 定义参数范围</span>
<span class="n">param_grid</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;max_depth&#39;</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">10</span><span class="p">),</span> <span class="s1">&#39;min_samples_split&#39;</span><span class="p">:</span> <span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">10</span><span class="p">]}</span>
<span class="c1"># 创建决策树模型    </span>
<span class="n">dt</span> <span class="o">=</span> <span class="n">DecisionTreeClassifier</span><span class="p">()</span>
<span class="c1"># 使用网格搜索进行参数调优</span>
<span class="n">grid_search</span> <span class="o">=</span> <span class="n">GridSearchCV</span><span class="p">(</span><span class="n">dt</span><span class="p">,</span> <span class="n">param_grid</span><span class="p">,</span> <span class="n">cv</span><span class="o">=</span><span class="mi">5</span><span class="p">)</span>
<span class="n">grid_search</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
<span class="c1"># 输出最佳参数</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Best parameters:&quot;</span><span class="p">,</span> <span class="n">grid_search</span><span class="o">.</span><span class="n">best_params_</span><span class="p">)</span>
<span class="c1"># 使用最佳参数训练模型</span>
<span class="n">best_dt</span> <span class="o">=</span> <span class="n">grid_search</span><span class="o">.</span><span class="n">best_estimator_</span>
<span class="n">best_dt</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
<span class="c1"># 预测</span>
<span class="n">y_pred</span> <span class="o">=</span> <span class="n">best_dt</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>
<span class="c1"># 评估模型</span>
<span class="nb">print</span><span class="p">(</span><span class="n">confusion_matrix</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="n">classification_report</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">))</span>
</code></pre></div></p>
<h3 id="66">6.6 决策树模型扩展<a class="headerlink" href="#66" title="Permanent link">&para;</a></h3>
<p>决策树模型可以与其他技术结合使用，如随机森林（集成多棵决策树）、梯度提升树（提升弱分类器）等，以提高算法的性能和适用性。</p>
<h2 id="_35">七、随机森林分类模型<a class="headerlink" href="#_35" title="Permanent link">&para;</a></h2>
<p>随机森林（Random Forest）是一种集成学习算法，通过构建多棵决策树并结合其预测结果来提高模型的性能和稳定性。随机森林适用于分类和回归任务，具有较强的抗过拟合能力。</p>
<h3 id="71">7.1 随机森林分类模型原理<a class="headerlink" href="#71" title="Permanent link">&para;</a></h3>
<p>随机森林通过以下步骤构建模型：</p>
<ol>
<li>从原始数据集中有放回地抽取多个子样本集（Bootstrap采样）。</li>
<li>对每个子样本集训练一棵决策树，在每个节点划分时随机选择部分特征进行分裂。</li>
<li>对于分类任务，通过多数投票法结合所有决策树的预测结果；对于回归任务，通过平均值结合预测结果。</li>
</ol>
<h3 id="72">7.2 随机森林分类模型优缺点<a class="headerlink" href="#72" title="Permanent link">&para;</a></h3>
<h4 id="_36">优点<a class="headerlink" href="#_36" title="Permanent link">&para;</a></h4>
<ul>
<li>抗过拟合能力强，适合高维数据</li>
<li>计算效率高，适合大规模数据集</li>
<li>能处理多分类问题</li>
<li>能处理缺失值和异常值</li>
<li>提供特征重要性评估</li>
</ul>
<h4 id="_37">缺点<a class="headerlink" href="#_37" title="Permanent link">&para;</a></h4>
<ul>
<li>模型复杂，难以解释</li>
<li>训练时间较长，尤其是树的数量较多时</li>
<li>对于某些数据分布，可能不如单棵决策树表现  </li>
</ul>
<h3 id="73">7.3 随机森林分类模型应用场景<a class="headerlink" href="#73" title="Permanent link">&para;</a></h3>
<p>随机森林分类模型适用于以下场景：</p>
<ul>
<li>分类任务，如客户细分、信用评分等</li>
<li>回归任务，如房价预测、销售预测等</li>
<li>风险评估，如欺诈检测、信用风险评估等</li>
<li>医疗诊断，如疾病预测等</li>
<li>市场营销，如用户行为分析、客户流失预测等</li>
<li>图像分类，如手写数字识别、物体检测等</li>
<li>文本分类，如垃圾邮件检测、情感分析等</li>
</ul>
<h3 id="74">7.4 随机森林分类模型实现<a class="headerlink" href="#74" title="Permanent link">&para;</a></h3>
<p>以下是使用Python和Scikit-learn库实现随机森林分类模型的示例代码
<div class="highlight"><pre><span></span><code><span class="kn">import</span><span class="w"> </span><span class="nn">numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">np</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">sklearn.model_selection</span><span class="w"> </span><span class="kn">import</span> <span class="n">train_test_split</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">sklearn.preprocessing</span><span class="w"> </span><span class="kn">import</span> <span class="n">StandardScaler</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">sklearn.ensemble</span><span class="w"> </span><span class="kn">import</span> <span class="n">RandomForestClassifier</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">sklearn.metrics</span><span class="w"> </span><span class="kn">import</span> <span class="n">classification_report</span><span class="p">,</span> <span class="n">confusion_matrix</span> 
<span class="kn">from</span><span class="w"> </span><span class="nn">sklearn.datasets</span><span class="w"> </span><span class="kn">import</span> <span class="n">load_iris</span>
<span class="c1"># 加载数据集</span>
<span class="n">data</span> <span class="o">=</span> <span class="n">load_iris</span><span class="p">()</span>
<span class="n">X</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">data</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">target</span>
<span class="c1"># 划分训练集和测试集</span>
<span class="n">X_train</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">y_test</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">test_size</span><span class="o">=</span><span class="mf">0.2</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">)</span>
<span class="c1"># 数据标准化</span>
<span class="n">scaler</span> <span class="o">=</span> <span class="n">StandardScaler</span><span class="p">()</span>
<span class="n">X_train</span> <span class="o">=</span> <span class="n">scaler</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">X_train</span><span class="p">)</span>
<span class="n">X_test</span> <span class="o">=</span> <span class="n">scaler</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>
<span class="c1"># 创建随机森林模型</span>
<span class="n">rf</span> <span class="o">=</span> <span class="n">RandomForestClassifier</span><span class="p">(</span><span class="n">n_estimators</span><span class="o">=</span><span class="mi">100</span><span class="p">)</span>  <span class="c1"># 使用100棵树</span>
<span class="c1"># 训练模型</span>
<span class="n">rf</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
<span class="c1"># 预测</span>
<span class="n">y_pred</span> <span class="o">=</span> <span class="n">rf</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>
<span class="c1"># 评估模型</span>
<span class="nb">print</span><span class="p">(</span><span class="n">confusion_matrix</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="n">classification_report</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">))</span>
</code></pre></div></p>
<h3 id="75">7.5 随机森林分类模型调优<a class="headerlink" href="#75" title="Permanent link">&para;</a></h3>
<p>随机森林分类模型的性能受树的数量和深度等参数的影响。可以通过交叉验证和网格搜索等方法调优树的数量、最大深度、最小样本分裂数等参数，以提高模型性能。
<div class="highlight"><pre><span></span><code><span class="kn">from</span><span class="w"> </span><span class="nn">sklearn.model_selection</span><span class="w"> </span><span class="kn">import</span> <span class="n">GridSearchCV</span>
<span class="c1"># 定义参数范围</span>
<span class="n">param_grid</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;n_estimators&#39;</span><span class="p">:</span> <span class="p">[</span><span class="mi">50</span><span class="p">,</span> <span class="mi">100</span><span class="p">,</span> <span class="mi">200</span><span class="p">],</span> <span class="s1">&#39;max_depth&#39;</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">10</span><span class="p">),</span> <span class="s1">&#39;min_samples_split&#39;</span><span class="p">:</span> <span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">10</span><span class="p">]}</span>
<span class="c1"># 创建随机森林模型</span>
<span class="n">rf</span> <span class="o">=</span> <span class="n">RandomForestClassifier</span><span class="p">()</span>
<span class="c1"># 使用网格搜索进行参数调优</span>
<span class="n">grid_search</span> <span class="o">=</span> <span class="n">GridSearchCV</span><span class="p">(</span><span class="n">rf</span><span class="p">,</span> <span class="n">param_grid</span><span class="p">,</span> <span class="n">cv</span><span class="o">=</span><span class="mi">5</span><span class="p">)</span>
<span class="n">grid_search</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
<span class="c1"># 输出最佳参数</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Best parameters:&quot;</span><span class="p">,</span> <span class="n">grid_search</span><span class="o">.</span><span class="n">best_params_</span><span class="p">)</span>
<span class="c1"># 使用最佳参数训练模型</span>
<span class="n">best_rf</span> <span class="o">=</span> <span class="n">grid_search</span><span class="o">.</span><span class="n">best_estimator_</span>
<span class="n">best_rf</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
<span class="c1"># 预测</span>
<span class="n">y_pred</span> <span class="o">=</span> <span class="n">best_rf</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>
<span class="c1"># 评估模型</span>
<span class="nb">print</span><span class="p">(</span><span class="n">confusion_matrix</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="n">classification_report</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">))</span>
</code></pre></div></p>
<h3 id="76">7.6 随机森林分类模型扩展<a class="headerlink" href="#76" title="Permanent link">&para;</a></h3>
<p>随机森林分类模型可以与其他技术结合使用，如梯度提升树（提升弱分类器）、极端随机树（增加随机性）等，以提高算法的性能和适用性。</p>
<h2 id="_38">八、回归树模型<a class="headerlink" href="#_38" title="Permanent link">&para;</a></h2>
<p>回归树（Regression Tree）是一种基于树形结构的监督学习算法，适用于回归任务。其核心思想是通过一系列的决策规则将数据划分为不同的数值范围，从而进行数值预测。</p>
<h3 id="81">8.1 回归树模型原理<a class="headerlink" href="#81" title="Permanent link">&para;</a></h3>
<p>回归树通过递归地选择最优特征进行数据划分，构建一棵树形结构。每个节点表示一个特征，每个分支表示该特征的取值范围，每个叶节点表示一个数值预测结果。常用的划分标准包括均方误差（Mean Squared Error, MSE）和平均绝对误差（Mean Absolute Error, MAE）。</p>
<h3 id="82">8.2 回归树模型优缺点<a class="headerlink" href="#82" title="Permanent link">&para;</a></h3>
<h4 id="_39">优点<a class="headerlink" href="#_39" title="Permanent link">&para;</a></h4>
<ul>
<li>易于理解和解释，直观展示决策过程</li>
<li>计算效率高，适合大规模数据集</li>
<li>能处理缺失值和异常值</li>
<li>可处理数值型和类别型特征</li>
</ul>
<h4 id="_40">缺点<a class="headerlink" href="#_40" title="Permanent link">&para;</a></h4>
<ul>
<li>容易过拟合，需剪枝等技术防止</li>
<li>对噪声敏感，可能影响模型性能</li>
<li>不能捕捉特征之间的复杂关系</li>
<li>决策边界为轴平行，可能不适合某些数据分布</li>
</ul>
<h3 id="83">8.3 回归树模型应用场景<a class="headerlink" href="#83" title="Permanent link">&para;</a></h3>
<p>回归树模型适用于以下场景：
- 回归任务，如房价预测、销售预测等
- 风险评估，如信用风险评估等
- 医疗诊断，如疾病严重程度预测等
- 市场营销，如用户行为分析、客户流失预测等  </p>
<h3 id="84">8.4 回归树模型实现<a class="headerlink" href="#84" title="Permanent link">&para;</a></h3>
<p>以下是使用Python和Scikit-learn库实现回归树模型的示例代码
<div class="highlight"><pre><span></span><code><span class="kn">import</span><span class="w"> </span><span class="nn">numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">np</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">sklearn.model_selection</span><span class="w"> </span><span class="kn">import</span> <span class="n">train_test_split</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">sklearn.preprocessing</span><span class="w"> </span><span class="kn">import</span> <span class="n">StandardScaler</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">sklearn.tree</span><span class="w"> </span><span class="kn">import</span> <span class="n">DecisionTreeRegressor</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">sklearn.metrics</span><span class="w"> </span><span class="kn">import</span> <span class="n">mean_squared_error</span><span class="p">,</span> <span class="n">mean_absolute_error</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">sklearn.datasets</span><span class="w"> </span><span class="kn">import</span> <span class="n">load_boston</span>
<span class="c1"># 加载数据集</span>
<span class="n">data</span> <span class="o">=</span> <span class="n">load_boston</span><span class="p">()</span>
<span class="n">X</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">data</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">target</span>
<span class="c1"># 划分训练集和测试集</span>
<span class="n">X_train</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">y_test</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">test_size</span><span class="o">=</span><span class="mf">0.2</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">)</span>
<span class="c1"># 数据标准化</span>
<span class="n">scaler</span> <span class="o">=</span> <span class="n">StandardScaler</span><span class="p">()</span>
<span class="n">X_train</span> <span class="o">=</span> <span class="n">scaler</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">X_train</span><span class="p">)</span>
<span class="n">X_test</span> <span class="o">=</span> <span class="n">scaler</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>
<span class="c1"># 创建回归树模型</span>
<span class="n">rt</span> <span class="o">=</span> <span class="n">DecisionTreeRegressor</span><span class="p">()</span>
<span class="c1"># 训练模型</span>
<span class="n">rt</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
<span class="c1"># 预测</span>
<span class="n">y_pred</span> <span class="o">=</span> <span class="n">rt</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>
<span class="c1"># 评估模型</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Mean Squared Error:&quot;</span><span class="p">,</span> <span class="n">mean_squared_error</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Mean Absolute Error:&quot;</span><span class="p">,</span> <span class="n">mean_absolute_error</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">))</span>
</code></pre></div></p>
<h3 id="85">8.5 回归树模型调优<a class="headerlink" href="#85" title="Permanent link">&para;</a></h3>
<p>回归树模型的性能受树的深度和划分标准的影响。可以通过交叉验证和网格搜索等方法调优树的深度、最小样本分裂数等参数，以提高模型性能。
<div class="highlight"><pre><span></span><code><span class="kn">from</span><span class="w"> </span><span class="nn">sklearn.model_selection</span><span class="w"> </span><span class="kn">import</span> <span class="n">GridSearchCV</span>
<span class="c1"># 定义参数范围</span>
<span class="n">param_grid</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;max_depth&#39;</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">10</span><span class="p">),</span> <span class="s1">&#39;min_samples_split&#39;</span><span class="p">:</span> <span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">10</span><span class="p">]}</span>
<span class="c1"># 创建回归树模型</span>
<span class="n">rt</span> <span class="o">=</span> <span class="n">DecisionTreeRegressor</span><span class="p">()</span>
<span class="c1"># 使用网格搜索进行参数调优</span>
<span class="n">grid_search</span> <span class="o">=</span> <span class="n">GridSearchCV</span><span class="p">(</span><span class="n">rt</span><span class="p">,</span> <span class="n">param_grid</span><span class="p">,</span> <span class="n">cv</span><span class="o">=</span><span class="mi">5</span><span class="p">)</span>
<span class="n">grid_search</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
<span class="c1"># 输出最佳参数</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Best parameters:&quot;</span><span class="p">,</span> <span class="n">grid_search</span><span class="o">.</span><span class="n">best_params_</span><span class="p">)</span>
<span class="c1"># 使用最佳参数训练模型</span>
<span class="n">best_rt</span> <span class="o">=</span> <span class="n">grid_search</span><span class="o">.</span><span class="n">best_estimator_</span>
<span class="n">best_rt</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
<span class="c1"># 预测</span>
<span class="n">y_pred</span> <span class="o">=</span> <span class="n">best_rt</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>
<span class="c1"># 评估模型</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Mean Squared Error:&quot;</span><span class="p">,</span> <span class="n">mean_squared_error</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Mean Absolute Error:&quot;</span><span class="p">,</span> <span class="n">mean_absolute_error</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">))</span>
</code></pre></div></p>
<h3 id="86">8.6 回归树模型扩展<a class="headerlink" href="#86" title="Permanent link">&para;</a></h3>
<p>回归树模型可以与其他技术结合使用，如随机森林回归（集成多棵回归树）、梯度提升回归（提升弱回归器）等，以提高算法的性能和适用性。  </p>
<h2 id="gbdt">九、GBDT模型<a class="headerlink" href="#gbdt" title="Permanent link">&para;</a></h2>
<p>GBDT（Gradient Boosting Decision Tree）是一种集成学习算法，通过构建多棵决策树并结合其预测结果来提高模型的性能和稳定性。GBDT适用于分类和回归任务，具有较强的抗过拟合能力。   </p>
<h3 id="91-gbdt">9.1 GBDT模型原理<a class="headerlink" href="#91-gbdt" title="Permanent link">&para;</a></h3>
<p>GBDT通过以下步骤构建模型：</p>
<ol>
<li>初始化模型，通常使用常数值（如均值）作为初始预测值。</li>
<li>计算当前模型的残差（真实值与预测值之差）。</li>
<li>训练一棵决策树拟合残差，得到新的弱学习器。</li>
<li>将新弱学习器的预测结果加权累加到当前模型中。</li>
<li>重复步骤2-4，直到达到预定的树数量或其他停止条件。    </li>
</ol>
<h3 id="92-gbdt">9.2 GBDT模型优缺点<a class="headerlink" href="#92-gbdt" title="Permanent link">&para;</a></h3>
<h4 id="_41">优点<a class="headerlink" href="#_41" title="Permanent link">&para;</a></h4>
<ul>
<li>抗过拟合能力强，适合高维数据</li>
<li>计算效率高，适合大规模数据集</li>
<li>能处理多分类问题</li>
<li>能处理缺失值和异常值</li>
<li>提供特征重要性评估</li>
</ul>
<h4 id="_42">缺点<a class="headerlink" href="#_42" title="Permanent link">&para;</a></h4>
<ul>
<li>模型复杂，难以解释</li>
<li>训练时间较长，尤其是树的数量较多时</li>
<li>对于某些数据分布，可能不如单棵决策树表现  </li>
</ul>
<h3 id="93-gbdt">9.3 GBDT模型应用场景<a class="headerlink" href="#93-gbdt" title="Permanent link">&para;</a></h3>
<p>GBDT模型适用于以下场景：</p>
<ul>
<li>分类任务，如客户细分、信用评分等</li>
<li>回归任务，如房价预测、销售预测等</li>
<li>风险评估，如欺诈检测、信用风险评估等</li>
<li>医疗诊断，如疾病预测等</li>
<li>市场营销，如用户行为分析、客户流失预测等</li>
<li>图像分类，如手写数字识别、物体检测等</li>
<li>文本分类，如垃圾邮件检测、情感分析等</li>
</ul>
<h3 id="94-gbdt">9.4 GBDT模型实现<a class="headerlink" href="#94-gbdt" title="Permanent link">&para;</a></h3>
<p>以下是使用Python和Scikit-learn库实现GBDT模型的示例代码
<div class="highlight"><pre><span></span><code><span class="kn">import</span><span class="w"> </span><span class="nn">numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">np</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">sklearn.model_selection</span><span class="w"> </span><span class="kn">import</span> <span class="n">train_test_split</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">sklearn.preprocessing</span><span class="w"> </span><span class="kn">import</span> <span class="n">StandardScaler</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">sklearn.ensemble</span><span class="w"> </span><span class="kn">import</span> <span class="n">GradientBoostingClassifier</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">sklearn.metrics</span><span class="w"> </span><span class="kn">import</span> <span class="n">classification_report</span><span class="p">,</span> <span class="n">confusion_matrix</span> 
<span class="kn">from</span><span class="w"> </span><span class="nn">sklearn.datasets</span><span class="w"> </span><span class="kn">import</span> <span class="n">load_iris</span>
<span class="c1"># 加载数据集</span>
<span class="n">data</span> <span class="o">=</span> <span class="n">load_iris</span><span class="p">()</span>
<span class="n">X</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">data</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">target</span>
<span class="c1"># 划分训练集和测试集</span>
<span class="n">X_train</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">y_test</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">test_size</span><span class="o">=</span><span class="mf">0.2</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">)</span>
<span class="c1"># 数据标准化</span>
<span class="n">scaler</span> <span class="o">=</span> <span class="n">StandardScaler</span><span class="p">()</span>
<span class="n">X_train</span> <span class="o">=</span> <span class="n">scaler</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">X_train</span><span class="p">)</span>
<span class="n">X_test</span> <span class="o">=</span> <span class="n">scaler</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>
<span class="c1"># 创建GBDT模型</span>
<span class="n">gbdt</span> <span class="o">=</span> <span class="n">GradientBoostingClassifier</span><span class="p">(</span><span class="n">n_estimators</span><span class="o">=</span><span class="mi">100</span><span class="p">)</span>  <span class="c1"># 使用100棵树</span>
<span class="c1"># 训练模型</span>
<span class="n">gbdt</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
<span class="c1"># 预测</span>
<span class="n">y_pred</span> <span class="o">=</span> <span class="n">gbdt</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>
<span class="c1"># 评估模型</span>
<span class="nb">print</span><span class="p">(</span><span class="n">confusion_matrix</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="n">classification_report</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">))</span>
</code></pre></div></p>
<h3 id="95-gbdt">9.5 GBDT模型调优<a class="headerlink" href="#95-gbdt" title="Permanent link">&para;</a></h3>
<p>GBDT模型的性能受树的数量和深度等参数的影响。可以通过交叉验证和网格搜索等方法调优树的数量、最大深度、最小样本分裂数等参数，以提高模型性能。
<div class="highlight"><pre><span></span><code><span class="kn">from</span><span class="w"> </span><span class="nn">sklearn.model_selection</span><span class="w"> </span><span class="kn">import</span> <span class="n">GridSearchCV</span>
<span class="c1"># 定义参数范围</span>
<span class="n">param_grid</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;n_estimators&#39;</span><span class="p">:</span> <span class="p">[</span><span class="mi">50</span><span class="p">,</span> <span class="mi">100</span><span class="p">,</span> <span class="mi">200</span><span class="p">],</span> <span class="s1">&#39;max_depth&#39;</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">10</span><span class="p">),</span> <span class="s1">&#39;min_samples_split&#39;</span><span class="p">:</span> <span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">10</span><span class="p">]}</span>
<span class="c1"># 创建GBDT模型</span>
<span class="n">gbdt</span> <span class="o">=</span> <span class="n">GradientBoostingClassifier</span><span class="p">()</span>
<span class="c1"># 使用网格搜索进行参数调优</span>
<span class="n">grid_search</span> <span class="o">=</span> <span class="n">GridSearchCV</span><span class="p">(</span><span class="n">gbdt</span><span class="p">,</span> <span class="n">param_grid</span><span class="p">,</span> <span class="n">cv</span><span class="o">=</span><span class="mi">5</span><span class="p">)</span>
<span class="n">grid_search</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
<span class="c1"># 输出最佳参数</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Best parameters:&quot;</span><span class="p">,</span> <span class="n">grid_search</span><span class="o">.</span><span class="n">best_params_</span><span class="p">)</span>
<span class="c1"># 使用最佳参数训练模型</span>
<span class="n">best_gbdt</span> <span class="o">=</span> <span class="n">grid_search</span><span class="o">.</span><span class="n">best_estimator_</span>
<span class="n">best_gbdt</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
<span class="c1"># 预测</span>
<span class="n">y_pred</span> <span class="o">=</span> <span class="n">best_gbdt</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>
<span class="c1"># 评估模型</span>
<span class="nb">print</span><span class="p">(</span><span class="n">confusion_matrix</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="n">classification_report</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">))</span>
</code></pre></div></p>
<h3 id="96-gbdt">9.6 GBDT模型扩展<a class="headerlink" href="#96-gbdt" title="Permanent link">&para;</a></h3>
<p>GBDT模型可以与其他技术结合使用，如XGBoost（极端梯度提升）、LightGBM（轻量级梯度提升）等，以提高算法的性能和适用性。 </p>
<h2 id="xgboost">十、XGBoost模型<a class="headerlink" href="#xgboost" title="Permanent link">&para;</a></h2>
<p>XGBoost（Extreme Gradient Boosting）是一种高效的梯度提升决策树（GBDT）实现，广泛应用于分类和回归任务。它通过优化计算效率和模型性能，成为许多机器学习竞赛中的首选算法。</p>
<h3 id="101-xgboost">10.1 XGBoost模型原理<a class="headerlink" href="#101-xgboost" title="Permanent link">&para;</a></h3>
<p>XGBoost基于GBDT的原理，通过以下步骤构建模型：</p>
<ol>
<li>初始化模型，通常使用常数值（如均值）作为初始预测值。</li>
<li>计算当前模型的残差（真实值与预测值之差）。</li>
<li>训练一棵决策树拟合残差，得到新的弱学习器。</li>
<li>将新弱学习器的预测结果加权累加到当前模型中。</li>
<li>重复步骤2-4，直到达到预定的树数量或其他停止条件。    </li>
</ol>
<h3 id="102-xgboost">10.2 XGBoost模型优缺点<a class="headerlink" href="#102-xgboost" title="Permanent link">&para;</a></h3>
<h4 id="_43">优点<a class="headerlink" href="#_43" title="Permanent link">&para;</a></h4>
<ul>
<li>高效的计算性能，适合大规模数据集</li>
<li>抗过拟合能力强，适合高维数据</li>
<li>能处理多分类问题</li>
<li>能处理缺失值和异常值</li>
<li>提供特征重要性评估</li>
<li>支持并行计算和分布式计算</li>
</ul>
<h4 id="_44">缺点<a class="headerlink" href="#_44" title="Permanent link">&para;</a></h4>
<ul>
<li>模型复杂，难以解释</li>
<li>训练时间较长，尤其是树的数量较多时</li>
<li>对于某些数据分布，可能不如单棵决策树表现  </li>
</ul>
<h3 id="103-xgboost">10.3 XGBoost模型应用场景<a class="headerlink" href="#103-xgboost" title="Permanent link">&para;</a></h3>
<p>XGBoost模型适用于以下场景：</p>
<ul>
<li>分类任务，如客户细分、信用评分等</li>
<li>回归任务，如房价预测、销售预测等</li>
<li>风险评估，如欺诈检测、信用风险评估等</li>
<li>医疗诊断，如疾病预测等</li>
<li>市场营销，如用户行为分析、客户流失预测等</li>
<li>图像分类，如手写数字识别、物体检测等</li>
<li>文本分类，如垃圾邮件检测、情感分析等</li>
</ul>
<h3 id="104-xgboost">10.4 XGBoost模型实现<a class="headerlink" href="#104-xgboost" title="Permanent link">&para;</a></h3>
<p>以下是使用Python和XGBoost库实现XGBoost模型的示例代码
<div class="highlight"><pre><span></span><code><span class="kn">import</span><span class="w"> </span><span class="nn">numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">np</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">sklearn.model_selection</span><span class="w"> </span><span class="kn">import</span> <span class="n">train_test_split</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">sklearn.preprocessing</span><span class="w"> </span><span class="kn">import</span> <span class="n">StandardScaler</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">xgboost</span><span class="w"> </span><span class="kn">import</span> <span class="n">XGBClassifier</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">sklearn.metrics</span><span class="w"> </span><span class="kn">import</span> <span class="n">classification_report</span><span class="p">,</span> <span class="n">confusion_matrix</span> 
<span class="kn">from</span><span class="w"> </span><span class="nn">sklearn.datasets</span><span class="w"> </span><span class="kn">import</span> <span class="n">load_iris</span>
<span class="c1"># 加载数据集</span>
<span class="n">data</span> <span class="o">=</span> <span class="n">load_iris</span><span class="p">()</span>
<span class="n">X</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">data</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">target</span>
<span class="c1"># 划分训练集和测试集</span>
<span class="n">X_train</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">y_test</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">test_size</span><span class="o">=</span><span class="mf">0.2</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">)</span>
<span class="c1"># 数据标准化</span>
<span class="n">scaler</span> <span class="o">=</span> <span class="n">StandardScaler</span><span class="p">()</span>
<span class="n">X_train</span> <span class="o">=</span> <span class="n">scaler</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">X_train</span><span class="p">)</span>
<span class="n">X_test</span> <span class="o">=</span> <span class="n">scaler</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>
<span class="c1"># 创建XGBoost模型</span>
<span class="n">xgb</span> <span class="o">=</span> <span class="n">XGBClassifier</span><span class="p">(</span><span class="n">n_estimators</span><span class="o">=</span><span class="mi">100</span><span class="p">)</span>  <span class="c1"># 使用100棵树</span>
<span class="c1"># 训练模型</span>
<span class="n">xgb</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
<span class="c1"># 预测</span>
<span class="n">y_pred</span> <span class="o">=</span> <span class="n">xgb</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>
<span class="c1"># 评估模型</span>
<span class="nb">print</span><span class="p">(</span><span class="n">confusion_matrix</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="n">classification_report</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">))</span>
</code></pre></div></p>
<h3 id="105-xgboost">10.5 XGBoost模型调优<a class="headerlink" href="#105-xgboost" title="Permanent link">&para;</a></h3>
<p>XGBoost模型的性能受树的数量和深度等参数的影响。可以通过交叉验证和网格搜索等方法调优树的数量、最大深度、最小样本分裂数等参数，以提高模型性能。
<div class="highlight"><pre><span></span><code><span class="kn">from</span><span class="w"> </span><span class="nn">sklearn.model_selection</span><span class="w"> </span><span class="kn">import</span> <span class="n">GridSearchCV</span>
<span class="c1"># 定义参数范围</span>
<span class="n">param_grid</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;n_estimators&#39;</span><span class="p">:</span> <span class="p">[</span><span class="mi">50</span><span class="p">,</span> <span class="mi">100</span><span class="p">,</span> <span class="mi">200</span><span class="p">],</span> <span class="s1">&#39;max_depth&#39;</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">10</span><span class="p">),</span> <span class="s1">&#39;learning_rate&#39;</span><span class="p">:</span> <span class="p">[</span><span class="mf">0.01</span><span class="p">,</span> <span class="mf">0.1</span><span class="p">,</span> <span class="mf">0.2</span><span class="p">],</span> <span class="s1">&#39;subsample&#39;</span><span class="p">:</span> <span class="p">[</span><span class="mf">0.6</span><span class="p">,</span> <span class="mf">0.8</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">]}</span>
<span class="c1"># 创建XGBoost模型</span>
<span class="n">xgb</span> <span class="o">=</span> <span class="n">XGBClassifier</span><span class="p">()</span>
<span class="c1"># 使用网格搜索进行参数调优</span>
<span class="n">grid_search</span> <span class="o">=</span> <span class="n">GridSearchCV</span><span class="p">(</span><span class="n">xgb</span><span class="p">,</span> <span class="n">param_grid</span><span class="p">,</span> <span class="n">cv</span><span class="o">=</span><span class="mi">5</span><span class="p">)</span>
<span class="n">grid_search</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
<span class="c1"># 输出最佳参数</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Best parameters:&quot;</span><span class="p">,</span> <span class="n">grid_search</span><span class="o">.</span><span class="n">best_params_</span><span class="p">)</span>
<span class="c1"># 使用最佳参数训练模型</span>
<span class="n">best_xgb</span> <span class="o">=</span> <span class="n">grid_search</span><span class="o">.</span><span class="n">best_estimator_</span>
<span class="n">best_xgb</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
<span class="c1"># 预测</span>
<span class="n">y_pred</span> <span class="o">=</span> <span class="n">best_xgb</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>
<span class="c1"># 评估模型</span>
<span class="nb">print</span><span class="p">(</span><span class="n">confusion_matrix</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="n">classification_report</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">))</span>
</code></pre></div></p>
<h3 id="106-xgboost">10.6 XGBoost模型扩展<a class="headerlink" href="#106-xgboost" title="Permanent link">&para;</a></h3>
<p>XGBoost模型可以与其他技术结合使用，如LightGBM（轻量级梯度提升）、CatBoost（处理类别特征）等，以提高算法的性能和适用性。    - <code>'minkowski'</code>：闵可夫斯基距离（默认值，</p>
<h2 id="lightgbm">十一、LightGBM模型<a class="headerlink" href="#lightgbm" title="Permanent link">&para;</a></h2>
<p>LightGBM（Light Gradient Boosting Machine）是一种高效的梯度提升决策树（GBDT）实现，广泛应用于分类和回归任务。它通过优化计算效率和模型性能，成为许多机器学习竞赛中的首选算法。</p>
<h3 id="111-lightgbm">11.1 LightGBM模型原理<a class="headerlink" href="#111-lightgbm" title="Permanent link">&para;</a></h3>
<p>LightGBM基于GBDT的原理，通过以下步骤构建模型：</p>
<ol>
<li>初始化模型，通常使用常数值（如均值）作为初始预测值。</li>
<li>计算当前模型的残差（真实值与预测值之差）。</li>
<li>训练一棵决策树拟合残差，得到新的弱学习器。</li>
<li>将新弱学习器的预测结果加权累加到当前模型中。</li>
<li>重复步骤2-4，直到达到预定的树数量或其他停止条件。</li>
</ol>
<h3 id="112-lightgbm">11.2 LightGBM模型优缺点<a class="headerlink" href="#112-lightgbm" title="Permanent link">&para;</a></h3>
<h4 id="_45">优点<a class="headerlink" href="#_45" title="Permanent link">&para;</a></h4>
<ul>
<li>高效的计算性能，适合大规模数据集</li>
<li>抗过拟合能力强，适合高维数据</li>
<li>能处理多分类问题</li>
<li>能处理缺失值和异常值</li>
<li>提供特征重要性评估</li>
<li>支持并行计算和分布式计算</li>
<li>采用基于直方图的决策树算法，减少内存使用</li>
<li>支持类别特征，减少预处理工作</li>
</ul>
<h4 id="_46">缺点<a class="headerlink" href="#_46" title="Permanent link">&para;</a></h4>
<ul>
<li>模型复杂，难以解释</li>
<li>训练时间较长，尤其是树的数量较多时</li>
<li>对于某些数据分布，可能不如单棵决策树表现  </li>
</ul>
<h3 id="113-lightgbm">11.3 LightGBM模型应用场景<a class="headerlink" href="#113-lightgbm" title="Permanent link">&para;</a></h3>
<p>LightGBM模型适用于以下场景：</p>
<ul>
<li>分类任务，如客户细分、信用评分等</li>
<li>回归任务，如房价预测、销售预测等</li>
<li>风险评估，如欺诈检测、信用风险评估等</li>
<li>医疗诊断，如疾病预测等</li>
<li>市场营销，如用户行为分析、客户流失预测等</li>
<li>图像分类，如手写数字识别、物体检测等</li>
<li>文本分类，如垃圾邮件检测、情感分析等</li>
</ul>
<h3 id="114-lightgbm">11.4 LightGBM模型实现<a class="headerlink" href="#114-lightgbm" title="Permanent link">&para;</a></h3>
<p>以下是使用Python和LightGBM库实现LightGBM模型的示例代码
<div class="highlight"><pre><span></span><code><span class="kn">import</span><span class="w"> </span><span class="nn">numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">np</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">sklearn.model_selection</span><span class="w"> </span><span class="kn">import</span> <span class="n">train_test_split</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">sklearn.preprocessing</span><span class="w"> </span><span class="kn">import</span> <span class="n">StandardScaler</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">lightgbm</span><span class="w"> </span><span class="kn">import</span> <span class="n">LGBMClassifier</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">sklearn.metrics</span><span class="w"> </span><span class="kn">import</span> <span class="n">classification_report</span><span class="p">,</span> <span class="n">confusion_matrix</span> 
<span class="kn">from</span><span class="w"> </span><span class="nn">sklearn.datasets</span><span class="w"> </span><span class="kn">import</span> <span class="n">load_iris</span>
<span class="c1"># 加载数据集</span>
<span class="n">data</span> <span class="o">=</span> <span class="n">load_iris</span><span class="p">()</span>
<span class="n">X</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">data</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">target</span>
<span class="c1"># 划分训练集和测试集</span>
<span class="n">X_train</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">y_test</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">test_size</span><span class="o">=</span><span class="mf">0.2</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">)</span>
<span class="c1"># 数据标准化</span>
<span class="n">scaler</span> <span class="o">=</span> <span class="n">StandardScaler</span><span class="p">()</span>
<span class="n">X_train</span> <span class="o">=</span> <span class="n">scaler</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">X_train</span><span class="p">)</span>
<span class="n">X_test</span> <span class="o">=</span> <span class="n">scaler</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>
<span class="c1"># 创建LightGBM模型</span>
<span class="n">lgbm</span> <span class="o">=</span> <span class="n">LGBMClassifier</span><span class="p">(</span><span class="n">n_estimators</span><span class="o">=</span><span class="mi">100</span><span class="p">)</span>  <span class="c1"># 使用100棵树</span>
<span class="c1"># 训练模型</span>
<span class="n">lgbm</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
<span class="c1"># 预测</span>
<span class="n">y_pred</span> <span class="o">=</span> <span class="n">lgbm</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>
<span class="c1"># 评估模型</span>
<span class="nb">print</span><span class="p">(</span><span class="n">confusion_matrix</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="n">classification_report</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">))</span>
</code></pre></div></p>
<h3 id="115-lightgbm">11.5 LightGBM模型调优<a class="headerlink" href="#115-lightgbm" title="Permanent link">&para;</a></h3>
<p>LightGBM模型的性能受树的数量和深度等参数的影响。可以通过交叉验证和网格搜索等方法调优树的数量、最大深度、最小样本分裂数等参数，以提高模型性能。
<div class="highlight"><pre><span></span><code><span class="kn">from</span><span class="w"> </span><span class="nn">sklearn.model_selection</span><span class="w"> </span><span class="kn">import</span> <span class="n">GridSearchCV</span>
<span class="c1"># 定义参数范围</span>
<span class="n">param_grid</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;n_estimators&#39;</span><span class="p">:</span> <span class="p">[</span><span class="mi">50</span><span class="p">,</span> <span class="mi">100</span><span class="p">,</span> <span class="mi">200</span><span class="p">],</span> <span class="s1">&#39;max_depth&#39;</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">10</span><span class="p">),</span> <span class="s1">&#39;learning_rate&#39;</span><span class="p">:</span> <span class="p">[</span><span class="mf">0.01</span><span class="p">,</span> <span class="mf">0.1</span><span class="p">,</span> <span class="mf">0.2</span><span class="p">],</span> <span class="s1">&#39;subsample&#39;</span><span class="p">:</span> <span class="p">[</span><span class="mf">0.6</span><span class="p">,</span> <span class="mf">0.8</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">]}</span>
<span class="c1"># 创建LightGBM模型</span>
<span class="n">lgbm</span> <span class="o">=</span> <span class="n">LGBMClassifier</span><span class="p">()</span>
<span class="c1"># 使用网格搜索进行参数调优</span>
<span class="n">grid_search</span> <span class="o">=</span> <span class="n">GridSearchCV</span><span class="p">(</span><span class="n">lgbm</span><span class="p">,</span> <span class="n">param_grid</span><span class="p">,</span> <span class="n">cv</span><span class="o">=</span><span class="mi">5</span><span class="p">)</span>
<span class="n">grid_search</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
<span class="c1"># 输出最佳参数</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Best parameters:&quot;</span><span class="p">,</span> <span class="n">grid_search</span><span class="o">.</span><span class="n">best_params_</span><span class="p">)</span>
<span class="c1"># 使用最佳参数训练模型</span>
<span class="n">best_lgbm</span> <span class="o">=</span> <span class="n">grid_search</span><span class="o">.</span><span class="n">best_estimator_</span>
<span class="n">best_lgbm</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
<span class="c1"># 预测</span>
<span class="n">y_pred</span> <span class="o">=</span> <span class="n">best_lgbm</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>
<span class="c1"># 评估模型</span>
<span class="nb">print</span><span class="p">(</span><span class="n">confusion_matrix</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="n">classification_report</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">))</span>
</code></pre></div></p>
<h3 id="116-lightgbm">11.6 LightGBM模型扩展<a class="headerlink" href="#116-lightgbm" title="Permanent link">&para;</a></h3>
<p>LightGBM模型可以与其他技术结合使用，如XGBoost（极端梯度提升）、CatBoost（处理类别特征）等，以提高算法的性能和适用性。    其计算公式为：(d(p, q) = \left( \sum_{i=1}^{n} |p_i - q_i|^r \right)^{1</p>
<h2 id="_47">十二、支持向量机模型<a class="headerlink" href="#_47" title="Permanent link">&para;</a></h2>
<p>支持向量机（Support Vector Machine, SVM）是一种强大的监督学习算法，广泛应用于分类和回归任务。其核心思想是通过寻找最优超平面，将不同类别的数据点分开，从而实现分类。</p>
<h3 id="121">12.1 支持向量机模型原理<a class="headerlink" href="#121" title="Permanent link">&para;</a></h3>
<p>支持向量机通过以下步骤构建模型：</p>
<ol>
<li>选择一个合适的核函数，将数据映射到高维空间，以便在该空间中找到线性可分的超平面。</li>
<li>通过最大化类别间的间隔（Margin），找到最优超平面。</li>
<li>使用支持向量（距离超平面最近的样本点）来确定超平面的位置。</li>
<li>对于非线性可分的数据，使用软间隔（Soft Margin）技术，允许部分样本点位于错误的一侧。  </li>
</ol>
<h3 id="122">12.2 支持向量机模型优缺点<a class="headerlink" href="#122" title="Permanent link">&para;</a></h3>
<h4 id="_48">优点<a class="headerlink" href="#_48" title="Permanent link">&para;</a></h4>
<ul>
<li>在高维空间中表现良好，适合复杂数据</li>
<li>能处理非线性分类问题</li>
<li>对小样本数据表现良好</li>
<li>具有较强的泛化能力</li>
</ul>
<h4 id="_49">缺点<a class="headerlink" href="#_49" title="Permanent link">&para;</a></h4>
<ul>
<li>计算复杂度高，训练时间较长</li>
<li>对参数选择和核函数敏感</li>
<li>对噪声和异常值敏感</li>
<li>不能直接处理多分类问题，需使用一对多或一对一策略</li>
</ul>
<h3 id="123">12.3 支持向量机模型应用场景<a class="headerlink" href="#123" title="Permanent link">&para;</a></h3>
<p>支持向量机模型适用于以下场景：</p>
<ul>
<li>分类任务，如文本分类、图像识别等</li>
<li>回归任务，如房价预测、股票价格预测等</li>
<li>风险评估，如信用风险评估等</li>
<li>医疗诊断，如疾病预测等</li>
<li>市场营销，如用户行为分析、客户流失预测等</li>
<li>生物信息学，如基因表达数据分析等</li>
</ul>
<h3 id="124">12.4 支持向量机模型实现<a class="headerlink" href="#124" title="Permanent link">&para;</a></h3>
<p>以下是使用Python和Scikit-learn库实现支持向量机模型的示例代码
<div class="highlight"><pre><span></span><code><span class="kn">import</span><span class="w"> </span><span class="nn">numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">np</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">sklearn.model_selection</span><span class="w"> </span><span class="kn">import</span> <span class="n">train_test_split</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">sklearn.preprocessing</span><span class="w"> </span><span class="kn">import</span> <span class="n">StandardScaler</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">sklearn.svm</span><span class="w"> </span><span class="kn">import</span> <span class="n">SVC</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">sklearn.metrics</span><span class="w"> </span><span class="kn">import</span> <span class="n">classification_report</span><span class="p">,</span> <span class="n">confusion_matrix</span> 
<span class="kn">from</span><span class="w"> </span><span class="nn">sklearn.datasets</span><span class="w"> </span><span class="kn">import</span> <span class="n">load_iris</span>
<span class="c1"># 加载数据集</span>
<span class="n">data</span> <span class="o">=</span> <span class="n">load_iris</span><span class="p">()</span>
<span class="n">X</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">data</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">target</span>
<span class="c1"># 划分训练集和测试集</span>
<span class="n">X_train</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">y_test</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">test_size</span><span class="o">=</span><span class="mf">0.2</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">)</span>
<span class="c1"># 数据标准化</span>
<span class="n">scaler</span> <span class="o">=</span> <span class="n">StandardScaler</span><span class="p">()</span>
<span class="n">X_train</span> <span class="o">=</span> <span class="n">scaler</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">X_train</span><span class="p">)</span>
<span class="n">X_test</span> <span class="o">=</span> <span class="n">scaler</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>
<span class="c1"># 创建支持向量机模型</span>
<span class="n">svm</span> <span class="o">=</span> <span class="n">SVC</span><span class="p">(</span><span class="n">kernel</span><span class="o">=</span><span class="s1">&#39;rbf&#39;</span><span class="p">)</span>  <span class="c1"># 使用径向基函数（RBF）核</span>
<span class="c1"># 训练模型</span>
<span class="n">svm</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
<span class="c1"># 预测</span>
<span class="n">y_pred</span> <span class="o">=</span> <span class="n">svm</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>
<span class="c1"># 评估模型</span>
<span class="nb">print</span><span class="p">(</span><span class="n">confusion_matrix</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="n">classification_report</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">))</span>
</code></pre></div></p>
<h3 id="125">12.5 支持向量机模型调优<a class="headerlink" href="#125" title="Permanent link">&para;</a></h3>
<p>支持向量机模型的性能受核函数和参数选择的影响。可以通过交叉验证和网格搜索等方法调优核函数类型、正则化参数C和核函数参数gamma等，以提高模型性能。
<div class="highlight"><pre><span></span><code><span class="kn">from</span><span class="w"> </span><span class="nn">sklearn.model_selection</span><span class="w"> </span><span class="kn">import</span> <span class="n">GridSearchCV</span>
<span class="c1"># 定义参数范围</span>
<span class="n">param_grid</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;C&#39;</span><span class="p">:</span> <span class="p">[</span><span class="mf">0.1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">10</span><span class="p">],</span> <span class="s1">&#39;gamma&#39;</span><span class="p">:</span> <span class="p">[</span><span class="mf">0.01</span><span class="p">,</span> <span class="mf">0.1</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="s1">&#39;kernel&#39;</span><span class="p">:</span> <span class="p">[</span><span class="s1">&#39;linear&#39;</span><span class="p">,</span> <span class="s1">&#39;rbf&#39;</span><span class="p">,</span> <span class="s1">&#39;poly&#39;</span><span class="p">]}</span>
<span class="c1"># 创建支持向量机模型</span>
<span class="n">svm</span> <span class="o">=</span> <span class="n">SVC</span><span class="p">()</span>
<span class="c1"># 使用网格搜索进行参数调优</span>
<span class="n">grid_search</span> <span class="o">=</span> <span class="n">GridSearchCV</span><span class="p">(</span><span class="n">svm</span><span class="p">,</span> <span class="n">param_grid</span><span class="p">,</span> <span class="n">cv</span><span class="o">=</span><span class="mi">5</span><span class="p">)</span>
<span class="n">grid_search</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
<span class="c1"># 输出最佳参数</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Best parameters:&quot;</span><span class="p">,</span> <span class="n">grid_search</span><span class="o">.</span><span class="n">best_params_</span><span class="p">)</span>
<span class="c1"># 使用最佳参数训练模型</span>
<span class="n">best_svm</span> <span class="o">=</span> <span class="n">grid_search</span><span class="o">.</span><span class="n">best_estimator_</span>
<span class="n">best_svm</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
<span class="c1"># 预测</span>
<span class="n">y_pred</span> <span class="o">=</span> <span class="n">best_svm</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>
<span class="c1"># 评估模型</span>
<span class="nb">print</span><span class="p">(</span><span class="n">confusion_matrix</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="n">classification_report</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">))</span>
</code></pre></div></p>
<h3 id="126">12.6 支持向量机模型扩展<a class="headerlink" href="#126" title="Permanent link">&para;</a></h3>
<p>支持向量机模型可以与其他技术结合使用，如核方法（如多项式核、径向基函数核等）、集成学习（如Bagging、Boosting等）等，以提高算法的性能和适用性。</p>
<h2 id="_50">十三、聚类算法<a class="headerlink" href="#_50" title="Permanent link">&para;</a></h2>
<p>聚类（Clustering）是一种无监督学习方法，用于将数据集划分为若干个簇，使得同一簇内的数据点相似度较高，而不同簇之间的数据点相似度较低。常见的聚类算法包括K均值（K-Means）、层次聚类（Hierarchical Clustering）和DBSCAN等。</p>
<h3 id="131">13.1 聚类算法原理<a class="headerlink" href="#131" title="Permanent link">&para;</a></h3>
<ul>
<li>K均值算法通过迭代优化簇中心位置，将数据点分配到最近的簇中心，直到簇中心不再变化。</li>
<li>层次聚类通过构建树形结构（树状图）来表示数据点之间的层次关系，可以是自底向上（凝聚型）或自顶向下（分裂型）。</li>
<li>DBSCAN通过密度连接的方式识别簇，能够发现任意形状的簇，并能处理噪声点。</li>
</ul>
<h3 id="132">13.2 聚类算法优缺点<a class="headerlink" href="#132" title="Permanent link">&para;</a></h3>
<h4 id="_51">优点<a class="headerlink" href="#_51" title="Permanent link">&para;</a></h4>
<ul>
<li>能发现数据中的潜在结构和模式</li>
<li>不需要预先标注数据，适用于无监督学习</li>
<li>适用于大规模数据集</li>
</ul>
<h4 id="_52">缺点<a class="headerlink" href="#_52" title="Permanent link">&para;</a></h4>
<ul>
<li>聚类结果受初始参数和算法选择影响较大</li>
<li>可能难以解释聚类结果</li>
<li>对噪声和异常值敏感</li>
<li>需要预先指定簇的数量（如K均值）   </li>
</ul>
<h3 id="133">13.3 聚类算法应用场景<a class="headerlink" href="#133" title="Permanent link">&para;</a></h3>
<p>聚类算法适用于以下场景：
- 客户细分，如市场营销中的客户分类
- 图像分割，如医学图像处理中的组织分割
- 文本挖掘，如文档分类和主题发现
- 异常检测，如网络安全中的入侵检测
- 社交网络分析，如社区发现
- 生物信息学，如基因表达数据分析    </p>
<h3 id="134">13.4 聚类算法实现<a class="headerlink" href="#134" title="Permanent link">&para;</a></h3>
<p>以下是使用Python和Scikit-learn库实现K均值聚类算法的示例代码
<div class="highlight"><pre><span></span><code><span class="kn">import</span><span class="w"> </span><span class="nn">numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">np</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">sklearn.cluster</span><span class="w"> </span><span class="kn">import</span> <span class="n">KMeans</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">sklearn.datasets</span><span class="w"> </span><span class="kn">import</span> <span class="n">load_iris</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">matplotlib.pyplot</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">plt</span>
<span class="c1"># 加载数据集</span>
<span class="n">data</span> <span class="o">=</span> <span class="n">load_iris</span><span class="p">()</span>
<span class="n">X</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">data</span>
<span class="c1"># 创建K均值模型</span>
<span class="n">kmeans</span> <span class="o">=</span> <span class="n">KMeans</span><span class="p">(</span><span class="n">n_clusters</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">)</span>
<span class="c1"># 训练模型</span>
<span class="n">kmeans</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
<span class="c1"># 预测簇标签</span>
<span class="n">y_kmeans</span> <span class="o">=</span> <span class="n">kmeans</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
<span class="c1"># 可视化聚类结果</span>
<span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">X</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">X</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">c</span><span class="o">=</span><span class="n">y_kmeans</span><span class="p">,</span> <span class="n">s</span><span class="o">=</span><span class="mi">50</span><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="s1">&#39;viridis&#39;</span><span class="p">)</span>
<span class="n">centers</span> <span class="o">=</span> <span class="n">kmeans</span><span class="o">.</span><span class="n">cluster_centers_</span>
<span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">centers</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">centers</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">c</span><span class="o">=</span><span class="s1">&#39;red&#39;</span><span class="p">,</span> <span class="n">s</span><span class="o">=</span><span class="mi">200</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.75</span><span class="p">,</span> <span class="n">marker</span><span class="o">=</span><span class="s1">&#39;X&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;Feature 1&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;Feature 2&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39;K-Means Clustering&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</code></pre></div></p>
<h3 id="135">13.5 聚类算法调优<a class="headerlink" href="#135" title="Permanent link">&para;</a></h3>
<p>聚类算法的性能受初始参数和算法选择的影响。可以通过调整簇的数量（如K均值中的K值）、距离度量方式（如欧氏距离、曼哈顿距离等）和算法参数（如DBSCAN中的eps和min_samples）等，以提高聚类效果。
<div class="highlight"><pre><span></span><code><span class="kn">from</span><span class="w"> </span><span class="nn">sklearn.metrics</span><span class="w"> </span><span class="kn">import</span> <span class="n">silhouette_score</span>
<span class="c1"># 计算轮廓系数评估聚类效果</span>
<span class="n">silhouette_avg</span> <span class="o">=</span> <span class="n">silhouette_score</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y_kmeans</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Silhouette Score:&quot;</span><span class="p">,</span> <span class="n">silhouette_avg</span><span class="p">)</span>
</code></pre></div></p>
<h3 id="136">13.6 聚类算法扩展<a class="headerlink" href="#136" title="Permanent link">&para;</a></h3>
<p>聚类算法可以与其他技术结合使用，如降维（如PCA、t-SNE等）以提高聚类效果，或与分类算法结合进行半监督学习等。</p>
<h2 id="_53">十四、降维算法<a class="headerlink" href="#_53" title="Permanent link">&para;</a></h2>
<p>降维（Dimensionality Reduction）是一种数据预处理技术，用于减少数据集的特征数量，同时尽可能保留数据的主要信息。常见的降维算法包括主成分分析（PCA）、线性判别分析（LDA）和t-SNE等。</p>
<h3 id="141">14.1 降维算法原理<a class="headerlink" href="#141" title="Permanent link">&para;</a></h3>
<ul>
<li>主成分分析（PCA）通过线性变换将数据投影到新的坐标系中，使得投影后的数据方差最大化，从而实现降维。</li>
<li>线性判别分析（LDA）通过寻找能够最大化类间距离和最小化类内距离的投影方向，实现降维和分类。</li>
<li>t-SNE通过非线性映射将高维数据嵌入到低维空间，保留数据的局部结构，适用于可视化高维数据。</li>
</ul>
<h3 id="142">14.2 降维算法优缺点<a class="headerlink" href="#142" title="Permanent link">&para;</a></h3>
<h4 id="_54">优点<a class="headerlink" href="#_54" title="Permanent link">&para;</a></h4>
<ul>
<li>减少数据维度，降低计算复杂度</li>
<li>去除冗余和噪声，提高模型性能</li>
<li>便于数据可视化和解释</li>
</ul>
<h4 id="_55">缺点<a class="headerlink" href="#_55" title="Permanent link">&para;</a></h4>
<ul>
<li>可能丢失部分信息，影响模型性能</li>
<li>需要选择合适的降维方法和参数</li>
<li>对数据分布和结构敏感，可能不适用于所有数据集</li>
</ul>
<h3 id="143">14.3 降维算法应用场景<a class="headerlink" href="#143" title="Permanent link">&para;</a></h3>
<p>降维算法适用于以下场景：
- 数据预处理，如特征选择和特征提取
- 数据可视化，如高维数据的二维或三维展示
- 噪声过滤，如去除数据中的冗余信息
- 提高模型性能，如减少过拟合风险
- 图像处理，如图像压缩和特征提取
- 自然语言处理，如文本表示和主题建模</p>
<h3 id="144">14.4 降维算法实现<a class="headerlink" href="#144" title="Permanent link">&para;</a></h3>
<p>以下是使用Python和Scikit-learn库实现主成分分析（PCA）的示例代码
<div class="highlight"><pre><span></span><code><span class="kn">import</span><span class="w"> </span><span class="nn">numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">np</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">sklearn.model_selection</span><span class="w"> </span><span class="kn">import</span> <span class="n">train_test_split</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">sklearn.preprocessing</span><span class="w"> </span><span class="kn">import</span> <span class="n">StandardScaler</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">sklearn.decomposition</span><span class="w"> </span><span class="kn">import</span> <span class="n">PCA</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">sklearn.datasets</span><span class="w"> </span><span class="kn">import</span> <span class="n">load_iris</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">matplotlib.pyplot</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">plt</span>
<span class="c1"># 加载数据集</span>
<span class="n">data</span> <span class="o">=</span> <span class="n">load_iris</span><span class="p">()</span>
<span class="n">X</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">data</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">target</span>
<span class="c1"># 划分训练集和测试集</span>
<span class="n">X_train</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">y_test</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">test_size</span><span class="o">=</span><span class="mf">0.2</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">)</span>
<span class="c1"># 数据标准化</span>
<span class="n">scaler</span> <span class="o">=</span> <span class="n">StandardScaler</span><span class="p">()</span>
<span class="n">X_train</span> <span class="o">=</span> <span class="n">scaler</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">X_train</span><span class="p">)</span>
<span class="n">X_test</span> <span class="o">=</span> <span class="n">scaler</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>
<span class="c1"># 创建PCA模型，降至2维</span>
<span class="n">pca</span> <span class="o">=</span> <span class="n">PCA</span><span class="p">(</span><span class="n">n_components</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
<span class="c1"># 训练模型</span>
<span class="n">X_train_pca</span> <span class="o">=</span> <span class="n">pca</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">X_train</span><span class="p">)</span>
<span class="n">X_test_pca</span> <span class="o">=</span> <span class="n">pca</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>
<span class="c1"># 可视化降维结果</span>
<span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">X_train_pca</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">X_train_pca</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">c</span><span class="o">=</span><span class="n">y_train</span><span class="p">,</span> <span class="n">s</span><span class="o">=</span><span class="mi">50</span><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="s1">&#39;viridis&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;Principal Component 1&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;Principal Component 2&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39;PCA Result&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</code></pre></div></p>
<h3 id="145">14.5 降维算法调优<a class="headerlink" href="#145" title="Permanent link">&para;</a></h3>
<p>降维算法的性能受方法选择和参数设置的影响。可以通过调整降维后的维度数量、选择不同的降维方法（如PCA、LDA、t-SNE等）和参数（如t-SNE中的perplexity和learning_rate）等，以提高降维效果。
<div class="highlight"><pre><span></span><code><span class="c1"># 输出PCA解释的方差比例</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Explained variance ratio:&quot;</span><span class="p">,</span> <span class="n">pca</span><span class="o">.</span><span class="n">explained_variance_ratio_</span><span class="p">)</span>
</code></pre></div></p>
<h3 id="146">14.6 降维算法扩展<a class="headerlink" href="#146" title="Permanent link">&para;</a></h3>
<p>降维算法可以与其他技术结合使用，如聚类（如K均值、DBSCAN等）以提高聚类效果，或与分类算法结合进行特征选择等。</p>
<h2 id="_56">十五、神经网络模型<a class="headerlink" href="#_56" title="Permanent link">&para;</a></h2>
<p>神经网络（Neural Network）是一种模拟生物神经系统结构和功能的机器学习算法，广泛应用于分类、回归和生成任务。其核心思想是通过多层神经元的连接和非线性激活函数，实现复杂的函数映射和模式识别。</p>
<h3 id="151">15.1 神经网络模型原理<a class="headerlink" href="#151" title="Permanent link">&para;</a></h3>
<p>神经网络通过以下步骤构建模型：</p>
<ol>
<li>构建网络结构，包括输入层、隐藏层和输出层，每层由若干神经元组成。</li>
<li>初始化权重和偏置，通常使用随机值。</li>
<li>前向传播：将输入数据通过网络传递，计算每个神经元的激活值，最终得到输出结果。</li>
<li>计算损失函数，衡量预测结果与真实值之间的差异。</li>
<li>反向传播：通过链式法则计算损失函数对权重和偏置的梯度，并使用优化算法（如梯度下降）更新权重和偏置。</li>
<li>重复步骤3-5，直到达到预定的迭代次数或损失函数收敛。</li>
</ol>
<h3 id="152">15.2 神经网络模型优缺点<a class="headerlink" href="#152" title="Permanent link">&para;</a></h3>
<h4 id="_57">优点<a class="headerlink" href="#_57" title="Permanent link">&para;</a></h4>
<ul>
<li>能处理复杂的非线性关系，适合高维数据</li>
<li>具有较强的泛化能力，适合大规模数据集</li>
<li>可通过增加层数和神经元数量提高模型容量</li>
<li>支持多种任务，如分类、回归和生成</li>
</ul>
<h4 id="_58">缺点<a class="headerlink" href="#_58" title="Permanent link">&para;</a></h4>
<ul>
<li>训练时间较长，计算资源需求高</li>
<li>需要大量标注数据，易过拟合</li>
<li>模型复杂，难以解释</li>
<li>对超参数选择敏感，如学习率、层数等</li>
</ul>
<h3 id="153">15.3 神经网络模型应用场景<a class="headerlink" href="#153" title="Permanent link">&para;</a></h3>
<p>神经网络模型适用于以下场景：</p>
<ul>
<li>图像识别，如手写数字识别、物体检测等</li>
<li>自然语言处理，如文本分类、机器翻译等</li>
<li>语音识别，如语音转文字、语音合成等</li>
<li>推荐系统，如个性化推荐、广告投放等</li>
<li>游戏AI，如围棋、扑克等游戏中的智能决策</li>
<li>医疗诊断，如疾病预测、医学图像分析等</li>
<li>金融预测，如股票价格预测、信用评分等</li>
</ul>
<h3 id="154">15.4 神经网络模型实现<a class="headerlink" href="#154" title="Permanent link">&para;</a></h3>
<div class="highlight"><pre><span></span><code><span class="kn">import</span><span class="w"> </span><span class="nn">numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">np</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">torch</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">torch.nn</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">nn</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">torch.optim</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">optim</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">sklearn.model_selection</span><span class="w"> </span><span class="kn">import</span> <span class="n">train_test_split</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">sklearn.preprocessing</span><span class="w"> </span><span class="kn">import</span> <span class="n">StandardScaler</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">sklearn.datasets</span><span class="w"> </span><span class="kn">import</span> <span class="n">load_iris</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">sklearn.metrics</span><span class="w"> </span><span class="kn">import</span> <span class="n">classification_report</span><span class="p">,</span> <span class="n">confusion_matrix</span>

<span class="c1"># 加载数据集</span>
<span class="n">data</span> <span class="o">=</span> <span class="n">load_iris</span><span class="p">()</span>
<span class="n">X</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">data</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">target</span>

<span class="c1"># 划分训练集和测试集</span>
<span class="n">X_train</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">y_test</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">test_size</span><span class="o">=</span><span class="mf">0.2</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">)</span>

<span class="c1"># 数据标准化</span>
<span class="n">scaler</span> <span class="o">=</span> <span class="n">StandardScaler</span><span class="p">()</span>
<span class="n">X_train</span> <span class="o">=</span> <span class="n">scaler</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">X_train</span><span class="p">)</span>
<span class="n">X_test</span> <span class="o">=</span> <span class="n">scaler</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>

<span class="c1"># 转换为Tensor</span>
<span class="n">X_train_tensor</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="n">X_test_tensor</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">X_test</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="n">y_train_tensor</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">y_train</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">long</span><span class="p">)</span>
<span class="n">y_test_tensor</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">long</span><span class="p">)</span>

<span class="c1"># 定义神经网络模型</span>
<span class="k">class</span><span class="w"> </span><span class="nc">SimpleNN</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">input_dim</span><span class="p">,</span> <span class="n">hidden_dim</span><span class="p">,</span> <span class="n">output_dim</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">SimpleNN</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">fc1</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">input_dim</span><span class="p">,</span> <span class="n">hidden_dim</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">relu</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">fc2</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">hidden_dim</span><span class="p">,</span> <span class="n">output_dim</span><span class="p">)</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="n">out</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">fc1</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">out</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">relu</span><span class="p">(</span><span class="n">out</span><span class="p">)</span>
        <span class="n">out</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">fc2</span><span class="p">(</span><span class="n">out</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">out</span>

<span class="n">input_dim</span> <span class="o">=</span> <span class="n">X_train</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
<span class="n">hidden_dim</span> <span class="o">=</span> <span class="mi">16</span>
<span class="n">output_dim</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">unique</span><span class="p">(</span><span class="n">y</span><span class="p">))</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">SimpleNN</span><span class="p">(</span><span class="n">input_dim</span><span class="p">,</span> <span class="n">hidden_dim</span><span class="p">,</span> <span class="n">output_dim</span><span class="p">)</span>

<span class="c1"># 定义损失函数和优化器</span>
<span class="n">criterion</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">CrossEntropyLoss</span><span class="p">()</span>
<span class="n">optimizer</span> <span class="o">=</span> <span class="n">optim</span><span class="o">.</span><span class="n">Adam</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="mf">0.01</span><span class="p">)</span>

<span class="c1"># 训练模型</span>
<span class="n">epochs</span> <span class="o">=</span> <span class="mi">100</span>
<span class="k">for</span> <span class="n">epoch</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">epochs</span><span class="p">):</span>
    <span class="n">model</span><span class="o">.</span><span class="n">train</span><span class="p">()</span>
    <span class="n">optimizer</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>
    <span class="n">outputs</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">X_train_tensor</span><span class="p">)</span>
    <span class="n">loss</span> <span class="o">=</span> <span class="n">criterion</span><span class="p">(</span><span class="n">outputs</span><span class="p">,</span> <span class="n">y_train_tensor</span><span class="p">)</span>
    <span class="n">loss</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>
    <span class="n">optimizer</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>
    <span class="k">if</span> <span class="p">(</span><span class="n">epoch</span><span class="o">+</span><span class="mi">1</span><span class="p">)</span> <span class="o">%</span> <span class="mi">20</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Epoch [</span><span class="si">{</span><span class="n">epoch</span><span class="o">+</span><span class="mi">1</span><span class="si">}</span><span class="s2">/</span><span class="si">{</span><span class="n">epochs</span><span class="si">}</span><span class="s2">], Loss: </span><span class="si">{</span><span class="n">loss</span><span class="o">.</span><span class="n">item</span><span class="p">()</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

<span class="c1"># 评估模型</span>
<span class="n">model</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>
<span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
    <span class="n">outputs</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">X_test_tensor</span><span class="p">)</span>
    <span class="n">_</span><span class="p">,</span> <span class="n">predicted</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">max</span><span class="p">(</span><span class="n">outputs</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
    <span class="n">y_pred</span> <span class="o">=</span> <span class="n">predicted</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">confusion_matrix</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">))</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">classification_report</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">))</span>
</code></pre></div>
<h3 id="155">15.5 神经网络模型调优<a class="headerlink" href="#155" title="Permanent link">&para;</a></h3>
<p>神经网络模型的性能受网络结构和超参数选择的影响。可以通过调整层数、神经元数量、学习率、批量大小等参数，以及使用正则化技术（如Dropout、L2正则化）和优化算法（如Adam、RMSprop）等，以提高模型性能。
```python# 示例：调整学习率和批量大小
learning_rates = [0.001, 0.01, 0.1]
batch_sizes = [16, 32, 64]
for lr in learning_rates:
    for batch_size in batch_sizes:
        # 重新定义优化器
        optimizer = optim.Adam(model.parameters(), lr=lr)
        # 训练模型（省略具体训练代码）
        # 评估模型（省略具体评估代码）
        print(f"Learning Rate: {lr}, Batch Size: {batch_size}, Evaluation Metrics: ...")
<div class="highlight"><pre><span></span><code>### 15.6 神经网络模型扩展

神经网络模型可以与其他技术结合使用，如卷积神经网络（CNN）用于图像处理，循环神经网络（RNN）用于序列数据处理，生成对抗网络（GAN）用于数据生成等，以提高算法的性能和适用性。
```python
# 示例：使用卷积神经网络（CNN）处理图像数据
class SimpleCNN(nn.Module):
    def __init__(self, input_channels, num_classes):
        super(SimpleCNN, self).__init__()
        self.conv1 = nn.Conv2d(input_channels, 32, kernel_size=3, stride=1, padding=1)
        self.pool = nn.MaxPool2d(kernel_size=2, stride=2, padding=0)
        self.fc1 = nn.Linear(32 * 16 * 16, num_classes)  # 假设输入图像大小为32x32
    def forward(self, x):
        x = self.pool(F.relu(self.conv1(x)))
        x = x.view(-1, 32 * 16 * 16)
        x = self.fc1(x)
        return x
</code></pre></div></p>
<h2 id="_59">十六、集成学习<a class="headerlink" href="#_59" title="Permanent link">&para;</a></h2>
<h3 id="1_3">1. 什么是集成学习（核心思想）<a class="headerlink" href="#1_3" title="Permanent link">&para;</a></h3>
<p>集成学习通过把多个基学习器（base learners）组合起来形成一个更强的“集成模型”。直观理由：多个弱学习器的预测会有差异，把它们合理结合（投票、加权、堆叠等）可以降低方差、降低偏差或提高鲁棒性。</p>
<p>常见组合方式：投票（Voting）/平均、Bagging、Boosting、Stacking（堆叠）。</p>
<h3 id="2_2">2. 常见方法与原理（简要）<a class="headerlink" href="#2_2" title="Permanent link">&para;</a></h3>
<h4 id="1-baggingbootstrap-aggregating">1.    Bagging（Bootstrap Aggregating）<a class="headerlink" href="#1-baggingbootstrap-aggregating" title="Permanent link">&para;</a></h4>
<ul>
<li>方法：对训练集做有放回抽样（bootstrap），在不同样本子集上训练多个同类基学习器（常用决策树），最后平均/投票。</li>
<li>优点：降低方差、抗过拟合，适合高方差模型（如深树）。</li>
<li>代表：RandomForest（在 Bagging 基础上额外随机选特征）。</li>
</ul>
<h4 id="2-boosting">2.    Boosting<a class="headerlink" href="#2-boosting" title="Permanent link">&para;</a></h4>
<ul>
<li>方法：序列化训练弱学习器，每个新模型重点纠正前一轮的错误（通过加权样本或拟合残差）。通常用弱学习器（浅树）。</li>
<li>优点：能显著降低偏差并提升准确率，适合提升弱模型性能。</li>
<li>代表：AdaBoost、Gradient Boosting（GradientBoosting、HistGradientBoosting）、XGBoost、LightGBM、CatBoost。</li>
</ul>
<h4 id="3-stacking">3.    Stacking（堆叠）<a class="headerlink" href="#3-stacking" title="Permanent link">&para;</a></h4>
<ul>
<li>方法：在一层训练若干不同模型，然后把这些模型的预测（通常是概率或预测值）作为“元特征”再训练一个元学习器（meta-learner），处理模型间互补。</li>
<li>优点：有能力整合多种模型优势，提升效果（但需注意过拟合与数据泄露）。</li>
<li>实践：使用交叉验证产生第一层的 out-of-fold 预测作为训练数据给第二层。</li>
</ul>
<h4 id="4-voting-averaging">4.    Voting / Averaging<a class="headerlink" href="#4-voting-averaging" title="Permanent link">&para;</a></h4>
<ul>
<li>简单直接：对多个不同模型的预测投票（分类）或平均（回归）。常用于 baseline 或少量模型融合。</li>
</ul>
<h3 id="3_2">3. 优缺点总结<a class="headerlink" href="#3_2" title="Permanent link">&para;</a></h3>
<h4 id="_60">优点：<a class="headerlink" href="#_60" title="Permanent link">&para;</a></h4>
<ul>
<li>提升性能（准确率、稳定性）</li>
<li>降低过拟合（Bagging）或偏差（Boosting）</li>
<li>能结合不同模型的优势（Stacking）</li>
</ul>
<h4 id="_61">缺点 / 注意点：<a class="headerlink" href="#_61" title="Permanent link">&para;</a></h4>
<ul>
<li>训练与推断成本高（多模型）</li>
<li>复杂度与可解释性下降</li>
<li>Boosting 容易过拟合（需要正则化、早停）</li>
<li>Stacking 若处理不当会导致数据泄露（需使用 out-of-fold 预测）</li>
<li>超参数多，需调参</li>
</ul>
<h3 id="4_2">4. 典型应用场景<a class="headerlink" href="#4_2" title="Permanent link">&para;</a></h3>
<ul>
<li>结构化/表格数据的建模（金融风控、信贷评分）</li>
<li>排序 / 点击率预估（用 GBDT 与 LR 混合）</li>
<li>竞赛（Kaggle 等）常用融合（Stacking / Blending）</li>
<li>特征重要性分析（如 RandomForest）</li>
<li>回归与分类通用场景</li>
</ul>
<h3 id="5-scikit-learn">5. 实战代码（scikit-learn）<a class="headerlink" href="#5-scikit-learn" title="Permanent link">&para;</a></h3>
<p>下面给出分类与回归的完整示例，含数据加载、训练、评估与 stacking。代码可直接在 Python 环境运行（需安装 scikit-learn、numpy、pandas）。</p>
<h4 id="iris-randomforestadaboostgradientboostingstacking">分类示例：Iris（演示 RandomForest、AdaBoost、GradientBoosting、Stacking）<a class="headerlink" href="#iris-randomforestadaboostgradientboostingstacking" title="Permanent link">&para;</a></h4>
<div class="highlight"><pre><span></span><code><span class="c1"># 分类示例：Iris 数据集</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">np</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">pandas</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">pd</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">sklearn.datasets</span><span class="w"> </span><span class="kn">import</span> <span class="n">load_iris</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">sklearn.model_selection</span><span class="w"> </span><span class="kn">import</span> <span class="n">train_test_split</span><span class="p">,</span> <span class="n">cross_val_score</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">sklearn.ensemble</span><span class="w"> </span><span class="kn">import</span> <span class="n">RandomForestClassifier</span><span class="p">,</span> <span class="n">AdaBoostClassifier</span><span class="p">,</span> <span class="n">GradientBoostingClassifier</span><span class="p">,</span> <span class="n">StackingClassifier</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">sklearn.linear_model</span><span class="w"> </span><span class="kn">import</span> <span class="n">LogisticRegression</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">sklearn.metrics</span><span class="w"> </span><span class="kn">import</span> <span class="n">accuracy_score</span><span class="p">,</span> <span class="n">classification_report</span><span class="p">,</span> <span class="n">confusion_matrix</span>

<span class="c1"># 1. 数据</span>
<span class="n">data</span> <span class="o">=</span> <span class="n">load_iris</span><span class="p">()</span>
<span class="n">X</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">data</span><span class="p">,</span> <span class="n">data</span><span class="o">.</span><span class="n">target</span>
<span class="n">X_train</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">y_test</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">test_size</span><span class="o">=</span><span class="mf">0.2</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">,</span> <span class="n">stratify</span><span class="o">=</span><span class="n">y</span><span class="p">)</span>

<span class="c1"># 2. 基础模型</span>
<span class="n">rf</span> <span class="o">=</span> <span class="n">RandomForestClassifier</span><span class="p">(</span><span class="n">n_estimators</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">)</span>
<span class="n">adb</span> <span class="o">=</span> <span class="n">AdaBoostClassifier</span><span class="p">(</span><span class="n">n_estimators</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">)</span>
<span class="n">gb</span> <span class="o">=</span> <span class="n">GradientBoostingClassifier</span><span class="p">(</span><span class="n">n_estimators</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">)</span>

<span class="c1"># 3. 训练并评估单模型</span>
<span class="k">for</span> <span class="n">name</span><span class="p">,</span> <span class="n">model</span> <span class="ow">in</span> <span class="p">[(</span><span class="s2">&quot;RandomForest&quot;</span><span class="p">,</span> <span class="n">rf</span><span class="p">),</span> <span class="p">(</span><span class="s2">&quot;AdaBoost&quot;</span><span class="p">,</span> <span class="n">adb</span><span class="p">),</span> <span class="p">(</span><span class="s2">&quot;GBDT&quot;</span><span class="p">,</span> <span class="n">gb</span><span class="p">)]:</span>
    <span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
    <span class="n">pred</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;=== </span><span class="si">{</span><span class="n">name</span><span class="si">}</span><span class="s2"> ===&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Accuracy:&quot;</span><span class="p">,</span> <span class="n">accuracy_score</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">pred</span><span class="p">))</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">classification_report</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">pred</span><span class="p">))</span>

<span class="c1"># 4. Stacking（堆叠）</span>
<span class="n">estimators</span> <span class="o">=</span> <span class="p">[</span>
    <span class="p">(</span><span class="s1">&#39;rf&#39;</span><span class="p">,</span> <span class="n">RandomForestClassifier</span><span class="p">(</span><span class="n">n_estimators</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">)),</span>
    <span class="p">(</span><span class="s1">&#39;gb&#39;</span><span class="p">,</span> <span class="n">GradientBoostingClassifier</span><span class="p">(</span><span class="n">n_estimators</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">)),</span>
    <span class="p">(</span><span class="s1">&#39;adb&#39;</span><span class="p">,</span> <span class="n">AdaBoostClassifier</span><span class="p">(</span><span class="n">n_estimators</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">))</span>
<span class="p">]</span>
<span class="n">stack</span> <span class="o">=</span> <span class="n">StackingClassifier</span><span class="p">(</span><span class="n">estimators</span><span class="o">=</span><span class="n">estimators</span><span class="p">,</span>
                           <span class="n">final_estimator</span><span class="o">=</span><span class="n">LogisticRegression</span><span class="p">(</span><span class="n">max_iter</span><span class="o">=</span><span class="mi">1000</span><span class="p">),</span>
                           <span class="n">cv</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">passthrough</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>  <span class="c1"># passthrough=True 会将原始特征与一级预测一并传给元学习器</span>

<span class="n">stack</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
<span class="n">pred_stack</span> <span class="o">=</span> <span class="n">stack</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;=== Stacking ===&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Accuracy:&quot;</span><span class="p">,</span> <span class="n">accuracy_score</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">pred_stack</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="n">classification_report</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">pred_stack</span><span class="p">))</span>
</code></pre></div>
<h5 id="_62">说明<a class="headerlink" href="#_62" title="Permanent link">&para;</a></h5>
<ul>
<li>StackingClassifier 内部自动做交叉验证来获得 out-of-fold 预测，避免泄露（scikit-learn 的实现能帮你处理）。</li>
<li>对真实业务数据常需做更多预处理、特征工程、调参（GridSearch/RandomizedSearch）。</li>
</ul>
<h4 id="california-housing-randomforestregressorgradientboostingregressorstackingregressor">回归示例：California housing（演示 RandomForestRegressor、GradientBoostingRegressor、StackingRegressor）<a class="headerlink" href="#california-housing-randomforestregressorgradientboostingregressorstackingregressor" title="Permanent link">&para;</a></h4>
<div class="highlight"><pre><span></span><code><span class="c1"># 回归示例：California housing</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">np</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">pandas</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">pd</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">sklearn.datasets</span><span class="w"> </span><span class="kn">import</span> <span class="n">fetch_california_housing</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">sklearn.model_selection</span><span class="w"> </span><span class="kn">import</span> <span class="n">train_test_split</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">sklearn.ensemble</span><span class="w"> </span><span class="kn">import</span> <span class="n">RandomForestRegressor</span><span class="p">,</span> <span class="n">GradientBoostingRegressor</span><span class="p">,</span> <span class="n">StackingRegressor</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">sklearn.linear_model</span><span class="w"> </span><span class="kn">import</span> <span class="n">LinearRegression</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">sklearn.metrics</span><span class="w"> </span><span class="kn">import</span> <span class="n">mean_squared_error</span><span class="p">,</span> <span class="n">r2_score</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">sklearn.preprocessing</span><span class="w"> </span><span class="kn">import</span> <span class="n">StandardScaler</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">sklearn.pipeline</span><span class="w"> </span><span class="kn">import</span> <span class="n">make_pipeline</span>

<span class="n">data</span> <span class="o">=</span> <span class="n">fetch_california_housing</span><span class="p">()</span>
<span class="n">X</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">data</span><span class="p">,</span> <span class="n">data</span><span class="o">.</span><span class="n">target</span>
<span class="n">X_train</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">y_test</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">test_size</span><span class="o">=</span><span class="mf">0.2</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">)</span>

<span class="c1"># 使用 pipeline 来对需要的模型做标准化（某些模型不需要）</span>
<span class="n">rf</span> <span class="o">=</span> <span class="n">RandomForestRegressor</span><span class="p">(</span><span class="n">n_estimators</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">)</span>
<span class="n">gbr</span> <span class="o">=</span> <span class="n">GradientBoostingRegressor</span><span class="p">(</span><span class="n">n_estimators</span><span class="o">=</span><span class="mi">200</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">)</span>

<span class="c1"># Stacking 回归：使用线性回归作为元学习器</span>
<span class="n">estimators</span> <span class="o">=</span> <span class="p">[(</span><span class="s1">&#39;rf&#39;</span><span class="p">,</span> <span class="n">rf</span><span class="p">),</span> <span class="p">(</span><span class="s1">&#39;gbr&#39;</span><span class="p">,</span> <span class="n">gbr</span><span class="p">)]</span>
<span class="n">stack</span> <span class="o">=</span> <span class="n">StackingRegressor</span><span class="p">(</span><span class="n">estimators</span><span class="o">=</span><span class="n">estimators</span><span class="p">,</span> <span class="n">final_estimator</span><span class="o">=</span><span class="n">LinearRegression</span><span class="p">(),</span> <span class="n">cv</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">passthrough</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>

<span class="c1"># 训练</span>
<span class="n">stack</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
<span class="n">pred</span> <span class="o">=</span> <span class="n">stack</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;MSE:&quot;</span><span class="p">,</span> <span class="n">mean_squared_error</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">pred</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;R2:&quot;</span><span class="p">,</span> <span class="n">r2_score</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">pred</span><span class="p">))</span>
</code></pre></div>
<h3 id="6_1">6. 常用实践建议（工程层面）<a class="headerlink" href="#6_1" title="Permanent link">&para;</a></h3>
<ol>
<li>选择基学习器<ul>
<li>Bagging：用高方差模型（深树）效果好。</li>
<li>Boosting：用弱学习器（浅树）逐步拟合残差。</li>
<li>Stacking：选互补性强的模型（例如 tree + linear + knn）。</li>
</ul>
</li>
<li>特征工程很重要：尤其 stacking 时，不同模型对特征预处理敏感（例如线性模型需要缩放，树模型不用）。</li>
<li>验证策略：使用交叉验证（k-fold）评估，stacking 要注意 out-of-fold 预测避免泄露。</li>
<li>调参：<ul>
<li>RandomForest：n_estimators, max_depth, max_features。</li>
<li>Boosting：学习率（learning_rate），n_estimators，max_depth，subsample（随机采样可降低过拟合）。</li>
<li>使用 RandomizedSearchCV 或 Bayesian 调参（如 Optuna）。</li>
</ul>
</li>
<li>早停（early stopping）：Boosting（如 GradientBoosting、HistGradientBoosting、LightGBM）支持早停，用验证集防止过拟合。</li>
<li>特征重要性与解释性：随机森林 / GBDT 可给特征重要性；也可以用 SHAP 做更细致解释。</li>
<li>模型融合的成本：线上部署要考虑推断延迟与成本，可把多模型融合压缩为单模型（如 distillation/knowledge distillation）。</li>
</ol>
<h3 id="7">7. 进阶技巧（小贴士）<a class="headerlink" href="#7" title="Permanent link">&para;</a></h3>
<ul>
<li>Blending：用 hold-out 集合分别训练底层模型并对验证集预测，再用这些预测训练元模型（简单版 stacking）。</li>
<li>模型序列化：保存多个模型与元模型（joblib.dump），部署时按需加载。</li>
<li>融合权重搜索：对于简单平均/加权平均，用贝叶斯优化或网格搜索找最优权重。</li>
<li>Ensemble pruning：若模型太多，可能有冗余，通过贪心选择子集提升效率。</li>
<li>Calibrate 概率：对于分类概率输出，可能需要 CalibratedClassifierCV 做概率校准（尤其 stacking 的概率输入给元模型时）。</li>
</ul>
<h3 id="8">8. 小结（快速回顾）<a class="headerlink" href="#8" title="Permanent link">&para;</a></h3>
<ul>
<li>集成学习通过组合多个模型提升性能和稳定性。</li>
<li>Bagging 降方差、Boosting 降偏差、Stacking 整合互补信息。</li>
<li>使用时注意验证、数据泄露、性能/成本折中和调参。</li>
</ul>












                
              </article>
            </div>
          
          
  <script>var tabs=__md_get("__tabs");if(Array.isArray(tabs))e:for(var set of document.querySelectorAll(".tabbed-set")){var labels=set.querySelector(".tabbed-labels");for(var tab of tabs)for(var label of labels.getElementsByTagName("label"))if(label.innerText.trim()===tab){var input=document.getElementById(label.htmlFor);input.checked=!0;continue e}}</script>

<script>var target=document.getElementById(location.hash.slice(1));target&&target.name&&(target.checked=target.name.startsWith("__tabbed_"))</script>
        </div>
        
      </main>
      
        <footer class="md-footer">
  
  <div class="md-footer-meta md-typeset">
    <div class="md-footer-meta__inner md-grid">
      <div class="md-copyright">
  
  
    Made with
    <a href="https://squidfunk.github.io/mkdocs-material/" target="_blank" rel="noopener">
      Material for MkDocs
    </a>
  
</div>
      
    </div>
  </div>
</footer>
      
    </div>
    <div class="md-dialog" data-md-component="dialog">
      <div class="md-dialog__inner md-typeset"></div>
    </div>
    
    
    
      
      <script id="__config" type="application/json">{"base": "../..", "features": ["navigation.section", "navigation.expand", "navigation.tabs", "navigation.sections", "navigation.indexes", "content.code.copy", "content.tabs.link", "content.code.annotate", "math"], "search": "../../assets/javascripts/workers/search.973d3a69.min.js", "tags": null, "translations": {"clipboard.copied": "\u5df2\u590d\u5236", "clipboard.copy": "\u590d\u5236", "search.result.more.one": "\u5728\u8be5\u9875\u4e0a\u8fd8\u6709 1 \u4e2a\u7b26\u5408\u6761\u4ef6\u7684\u7ed3\u679c", "search.result.more.other": "\u5728\u8be5\u9875\u4e0a\u8fd8\u6709 # \u4e2a\u7b26\u5408\u6761\u4ef6\u7684\u7ed3\u679c", "search.result.none": "\u6ca1\u6709\u627e\u5230\u7b26\u5408\u6761\u4ef6\u7684\u7ed3\u679c", "search.result.one": "\u627e\u5230 1 \u4e2a\u7b26\u5408\u6761\u4ef6\u7684\u7ed3\u679c", "search.result.other": "# \u4e2a\u7b26\u5408\u6761\u4ef6\u7684\u7ed3\u679c", "search.result.placeholder": "\u952e\u5165\u4ee5\u5f00\u59cb\u641c\u7d22", "search.result.term.missing": "\u7f3a\u5c11", "select.version": "\u9009\u62e9\u5f53\u524d\u7248\u672c"}, "version": null}</script>
    
    
      <script src="../../assets/javascripts/bundle.f55a23d4.min.js"></script>
      
        <script src="../../styles/javascripts/config.js"></script>
      
        <script src="https://cdn.jsdelivr.net/npm/katex@0.16.4/dist/katex.min.js"></script>
      
        <script src="https://cdn.jsdelivr.net/npm/katex@0.16.4/dist/contrib/auto-render.min.js"></script>
      
        <script src="../../styles/javascripts/katex.js"></script>
      
    
  </body>
</html>